---
title: MoonLnader Trajectory Optimization
author: G.N.V.A Sai Chaitanya
date: 18th december
---
Q) should we need to give du/dt as a neural network? and if so why?
ans)                                 points to be noted:

      1. We have only 2 equations ḣ and v̇ and the boundary conditions for them are also known.
      2. ḣ = f(v); v̇ = f(u); which is unknown. So we are experimenting u as a linear model to a non linear model
         which could fit the corresponding boundary conditions.
      3. suppose we took a linear model u(t) = a + bt; then we need to find params of a,b which could satisfy the
         defined equations ḣ and v̇. But we also have the control constraints such as 0 <= u <= 3.

Q2) Again a question araises how do we add constraints in our model? when we dont define u as a seperate neural network?
ans) we tried adding the penality loss function that could always make the u constraint > 0 and < 3.
      problem with this model is,
       1. {
                  since our model has  a loss function which is sum of the PDE + BC loss function, we need to precisely know
                  how much effect our BC and PDE losses are effecting the solution parameters. Suppose if we add another
                  loss function such as additional loss, it may happen that; the effect of additional loss is >> combined
                  PDE +BC loss; which makes our optimizer to only minimize the additional loss function, i.e. the constraint
                  0 < u < 3.

                  example : eqn = [Dt(h(t)) ~ v(t),
                            Dt(v(t)) ~ -1.5 + (a+b*t),

                        {Our assumption is u = a+ b*t }

                  Boundary:  bcs = [h(0.) ~ 10.,
                           v(0.) ~ -2.,
                           h(tf) ~ 0.,
                           v(tf) ~ 0.]

                  additional loss = {
                        upred = [p[1]+ p[2]*t for t in t_ ]
                        {
                            Imposing Hard constraint
                            u21 =  [(upred[i] >=0.0 && upred[i] <= 3.) ? upred[i] : (upred[i] > 3.) ? 3 : upred[i].^2  for i in 1:length(t_)]
                        }
                        {
                            Imposing soft constraint which is chosen based on intuition

                            if U > 3
                                  U - log(U)
                            elseif U < 0
                                  U+ exp(-U)
                            elseif U >0. && U <3.
                                  U
                            end

                            u21 =  [(upred[i] >=0.0 && upred[i] <= 3.) ? upred[i] : (upred[i] > 3.) ? upred[i] - log(upred[i]) : upred[i] + exp(-upred[i])  for i in 1:length(t_)]
                            sumofall = u21[1] + 2 * sum(u21[2:end-1]) + u21[end]
                        }


                        we can give a vector of penality and try to run the code for different penalities from 0.0001 to 0.005
                        penalty = 0.005
                        J = (δt/2) * sumofall * penalty
                        }

                  So we need to randomly keep on trying different weights for the additional loss function until we get the
                  required analytical result.
                  However, in real life we dont know the actual trajectory of the system, so we cant completely relay
                  on trail and error base of solution.

       }

       2. {
            One more way to do this is to assume du/dt as a neural network and approximate it to a function of our choice
            and impose the constraints u(0) and u(tf) as BC's. and let the model train the parameters w.r.t the BC's such as
            eqn = [Dt(h(t)) ~ v(t),
                      Dt(v(t)) ~ -1.5 + (a+b*t),
                      Dt(u(t)) ~ b]

                      bcs = [h(0.) ~ 10.,
                              v(0.) ~ -2., # its decelerating
                              u(0.) ~ 0.,
                              u(tf) ~ 3.,
                              h(tf) ~ 0.,
                              v(tf) ~ 0.,
                              ]

            But the caveats with this method is, NN will train params a,b w.r.t the approximated equation on the RHS. So
            if we have an initial idea of how our Trajectory of the Model looks like we can build an approximate RHS function
            and train the NN(θ,λ) and hyperparameters a,b respectively.

      3. {
            So far we have assumed that the final trajectory time is known, however, the time and path of actual case will be
            unknown.
            }

       }

       4. Instead of approximating RHS of a Neural Network as a polynomial function or Chebeshev polynomials, can we approximate
          it as another NN? if so how do we give a neural network in ModelingToolkit ?
