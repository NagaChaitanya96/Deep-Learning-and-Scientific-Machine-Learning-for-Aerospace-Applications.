{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ad1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcca65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/saichaitanya/Chaitanya/CSV files/1000 points per trajectory/May8rd10percent_RLV_data 1000 points_from86 .csv',header = None,names = ['h','v','s','omega','gamma','m','theta','Thrust','beta','time'])\n",
    "df2 = pd.read_csv('/home/saichaitanya/Chaitanya/CSV files/1000 points per trajectory/May8rd10percent_RLV_data 1000 points2 .csv',header = None,names = ['h','v','s','omega','gamma','m','theta','Thrust','beta','time'])\n",
    "df = pd.concat([df1,df2],ignore_index=False)\n",
    "input = output =df.values\n",
    "X = input[:,0:7]\n",
    "y = output[:,7:9]\n",
    "# Individual Data\n",
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.minmax_scale(X)\n",
    "y_norm = preprocessing.minmax_scale(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.1, random_state=42)\n",
    "cross_validation_number = int(X.shape[0]*0.1)\n",
    "X_val = X_train[-cross_validation_number:]\n",
    "y_val = y_train[-cross_validation_number:]\n",
    "X_train = X_train[:-cross_validation_number]\n",
    "y_train = y_train[:-cross_validation_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5380fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(n):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n,input_shape=(7,),kernel_initializer='uniform'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu')) # since tanh has more nonlinearity we add it here, it also gives -ve values so , some layers which are not necessary will lead to 0 in next layer\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(2,kernel_initializer='uniform',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25af639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 19:44:15.933323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-13 19:44:15.933379: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-13 19:44:15.934399: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "i = 7;\n",
    "model = create_model2(2**i)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def lr_sch3(epoch,lr):\n",
    "    if (epoch >0) &(epoch<100):\n",
    "      if epoch%30==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>100):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_sch3,verbose = 1)\n",
    "bs = 256;\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / bs\n",
    "save_period = 20\n",
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')\n",
    "iter1 = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00429466",
   "metadata": {},
   "source": [
    "hist = model.fit(X_train,y_train,epochs = iter1,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5f1385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4e4dd6a260>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e5df9",
   "metadata": {},
   "source": [
    "model.save(f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68ce641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05342954, 0.6702719 ],\n",
       "       [0.05446598, 0.5860089 ],\n",
       "       [0.5321479 , 0.49459007],\n",
       "       ...,\n",
       "       [0.05198124, 0.6522221 ],\n",
       "       [0.2029373 , 0.62137926],\n",
       "       [0.31623423, 0.47534943]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b7fb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05210304, 0.67865059],\n",
       "       [0.05867656, 0.61604185],\n",
       "       [0.55106001, 0.49590121],\n",
       "       ...,\n",
       "       [0.05159365, 0.65077814],\n",
       "       [0.20756319, 0.62336328],\n",
       "       [0.31121137, 0.48170023]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8bade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6848/6848 [==============================] - 13s 2ms/step - loss: 2.0550e-04 - accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00020550069166347384, 0.9904481172561646]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b992910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54780/54780 [==============================] - 102s 2ms/step - loss: 1.9943e-04 - accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0001994267076952383, 0.9908913373947144]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5226f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    }
   ],
   "source": [
    "lr = 0.000187344\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "iter2 = 150\n",
    "def lr_sch(epoch,lr):\n",
    "    if (epoch >0) &(epoch<25):\n",
    "      if epoch%5==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>25):\n",
    "        if epoch%5==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler2 = tf.keras.callbacks.LearningRateScheduler(lr_sch,verbose = 1)\n",
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\"\n",
    "bs2 = 1024\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / bs\n",
    "save_period = 20\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761206ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.000187344.\n",
      "Epoch 1/150\n",
      "1712/1712 [==============================] - 13s 7ms/step - loss: 2.1427e-04 - accuracy: 0.9902 - val_loss: 2.0843e-04 - val_accuracy: 0.9899 - lr: 1.8734e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0001873.\n",
      "Epoch 2/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 2.1413e-04 - accuracy: 0.9902 - val_loss: 2.7373e-04 - val_accuracy: 0.9853 - lr: 1.8730e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0001873.\n",
      "Epoch 3/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 2.1483e-04 - accuracy: 0.9902 - val_loss: 2.1713e-04 - val_accuracy: 0.9910 - lr: 1.8730e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0001873.\n",
      "Epoch 4/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 2.1197e-04 - accuracy: 0.9904 - val_loss: 1.9758e-04 - val_accuracy: 0.9915 - lr: 1.8730e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0001873.\n",
      "Epoch 5/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 2.1172e-04 - accuracy: 0.9902 - val_loss: 2.1243e-04 - val_accuracy: 0.9893 - lr: 1.8730e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0001194.\n",
      "Epoch 6/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.9894e-04 - accuracy: 0.9909 - val_loss: 2.5052e-04 - val_accuracy: 0.9895 - lr: 1.1940e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0001194.\n",
      "Epoch 7/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.9777e-04 - accuracy: 0.9910 - val_loss: 1.9415e-04 - val_accuracy: 0.9914 - lr: 1.1940e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0001194.\n",
      "Epoch 8/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 2.0035e-04 - accuracy: 0.9908 - val_loss: 1.9996e-04 - val_accuracy: 0.9899 - lr: 1.1940e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0001194.\n",
      "Epoch 9/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.9557e-04 - accuracy: 0.9910 - val_loss: 2.5178e-04 - val_accuracy: 0.9873 - lr: 1.1940e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0001194.\n",
      "Epoch 10/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.9515e-04 - accuracy: 0.9912 - val_loss: 1.9026e-04 - val_accuracy: 0.9917 - lr: 1.1940e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 7.61e-05.\n",
      "Epoch 11/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.8400e-04 - accuracy: 0.9916 - val_loss: 1.8852e-04 - val_accuracy: 0.9905 - lr: 7.6100e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 7.61e-05.\n",
      "Epoch 12/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.8513e-04 - accuracy: 0.9916 - val_loss: 1.8496e-04 - val_accuracy: 0.9910 - lr: 7.6100e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 7.61e-05.\n",
      "Epoch 13/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.8456e-04 - accuracy: 0.9916 - val_loss: 1.9024e-04 - val_accuracy: 0.9908 - lr: 7.6100e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 7.61e-05.\n",
      "Epoch 14/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.8558e-04 - accuracy: 0.9915 - val_loss: 1.7373e-04 - val_accuracy: 0.9922 - lr: 7.6100e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 7.61e-05.\n",
      "Epoch 15/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.8436e-04 - accuracy: 0.9916 - val_loss: 1.7684e-04 - val_accuracy: 0.9922 - lr: 7.6100e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 4.85e-05.\n",
      "Epoch 16/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7800e-04 - accuracy: 0.9919 - val_loss: 1.7448e-04 - val_accuracy: 0.9921 - lr: 4.8500e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 4.85e-05.\n",
      "Epoch 17/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7705e-04 - accuracy: 0.9919 - val_loss: 1.9464e-04 - val_accuracy: 0.9916 - lr: 4.8500e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 4.85e-05.\n",
      "Epoch 18/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7782e-04 - accuracy: 0.9919 - val_loss: 1.8886e-04 - val_accuracy: 0.9918 - lr: 4.8500e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 4.85e-05.\n",
      "Epoch 19/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7685e-04 - accuracy: 0.9919 - val_loss: 1.7581e-04 - val_accuracy: 0.9918 - lr: 4.8500e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 4.85e-05.\n",
      "Epoch 20/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7740e-04 - accuracy: 0.9919 - val_loss: 1.7418e-04 - val_accuracy: 0.9918 - lr: 4.8500e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 21/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7189e-04 - accuracy: 0.9922 - val_loss: 1.7350e-04 - val_accuracy: 0.9920 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 22/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7237e-04 - accuracy: 0.9922 - val_loss: 1.6963e-04 - val_accuracy: 0.9926 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 23/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7207e-04 - accuracy: 0.9922 - val_loss: 1.9199e-04 - val_accuracy: 0.9904 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 24/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7244e-04 - accuracy: 0.9922 - val_loss: 1.6982e-04 - val_accuracy: 0.9924 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 25/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7188e-04 - accuracy: 0.9921 - val_loss: 1.7014e-04 - val_accuracy: 0.9927 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 26/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7165e-04 - accuracy: 0.9922 - val_loss: 1.7495e-04 - val_accuracy: 0.9925 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 27/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7098e-04 - accuracy: 0.9922 - val_loss: 1.8015e-04 - val_accuracy: 0.9925 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 28/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7099e-04 - accuracy: 0.9922 - val_loss: 1.7322e-04 - val_accuracy: 0.9916 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 29/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7098e-04 - accuracy: 0.9922 - val_loss: 1.6773e-04 - val_accuracy: 0.9926 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 3.09e-05.\n",
      "Epoch 30/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.7071e-04 - accuracy: 0.9923 - val_loss: 1.7146e-04 - val_accuracy: 0.9927 - lr: 3.0900e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 2.6265e-05.\n",
      "Epoch 31/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6971e-04 - accuracy: 0.9923 - val_loss: 2.2801e-04 - val_accuracy: 0.9898 - lr: 2.6265e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 2.6265e-05.\n",
      "Epoch 32/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6948e-04 - accuracy: 0.9923 - val_loss: 1.6891e-04 - val_accuracy: 0.9920 - lr: 2.6265e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 2.6265e-05.\n",
      "Epoch 33/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6873e-04 - accuracy: 0.9924 - val_loss: 1.6901e-04 - val_accuracy: 0.9924 - lr: 2.6265e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 2.6265e-05.\n",
      "Epoch 34/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6884e-04 - accuracy: 0.9924 - val_loss: 1.6821e-04 - val_accuracy: 0.9926 - lr: 2.6265e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 2.6265e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6911e-04 - accuracy: 0.9923 - val_loss: 1.7338e-04 - val_accuracy: 0.9925 - lr: 2.6265e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 2.2325e-05.\n",
      "Epoch 36/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6812e-04 - accuracy: 0.9924 - val_loss: 1.6696e-04 - val_accuracy: 0.9927 - lr: 2.2325e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 2.2325e-05.\n",
      "Epoch 37/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6881e-04 - accuracy: 0.9923 - val_loss: 1.6699e-04 - val_accuracy: 0.9923 - lr: 2.2325e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 2.2325e-05.\n",
      "Epoch 38/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6733e-04 - accuracy: 0.9925 - val_loss: 1.6848e-04 - val_accuracy: 0.9923 - lr: 2.2325e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 2.2325e-05.\n",
      "Epoch 39/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6747e-04 - accuracy: 0.9925 - val_loss: 1.8686e-04 - val_accuracy: 0.9907 - lr: 2.2325e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 2.2325e-05.\n",
      "Epoch 40/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6800e-04 - accuracy: 0.9924 - val_loss: 1.6604e-04 - val_accuracy: 0.9928 - lr: 2.2325e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.8976e-05.\n",
      "Epoch 41/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6652e-04 - accuracy: 0.9925 - val_loss: 1.6521e-04 - val_accuracy: 0.9928 - lr: 1.8976e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.8976e-05.\n",
      "Epoch 42/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6619e-04 - accuracy: 0.9925 - val_loss: 1.7238e-04 - val_accuracy: 0.9916 - lr: 1.8976e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.8976e-05.\n",
      "Epoch 43/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6588e-04 - accuracy: 0.9925 - val_loss: 1.6641e-04 - val_accuracy: 0.9927 - lr: 1.8976e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.8976e-05.\n",
      "Epoch 44/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6585e-04 - accuracy: 0.9925 - val_loss: 1.8594e-04 - val_accuracy: 0.9918 - lr: 1.8976e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.8976e-05.\n",
      "Epoch 45/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6570e-04 - accuracy: 0.9926 - val_loss: 1.6486e-04 - val_accuracy: 0.9928 - lr: 1.8976e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.613e-05.\n",
      "Epoch 46/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6433e-04 - accuracy: 0.9926 - val_loss: 1.7563e-04 - val_accuracy: 0.9914 - lr: 1.6130e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.613e-05.\n",
      "Epoch 47/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6459e-04 - accuracy: 0.9926 - val_loss: 1.6792e-04 - val_accuracy: 0.9922 - lr: 1.6130e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.613e-05.\n",
      "Epoch 48/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6485e-04 - accuracy: 0.9926 - val_loss: 1.7741e-04 - val_accuracy: 0.9915 - lr: 1.6130e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.613e-05.\n",
      "Epoch 49/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6461e-04 - accuracy: 0.9926 - val_loss: 1.7157e-04 - val_accuracy: 0.9915 - lr: 1.6130e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.613e-05.\n",
      "Epoch 50/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6476e-04 - accuracy: 0.9926 - val_loss: 1.6602e-04 - val_accuracy: 0.9927 - lr: 1.6130e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.371e-05.\n",
      "Epoch 51/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6374e-04 - accuracy: 0.9926 - val_loss: 1.7036e-04 - val_accuracy: 0.9918 - lr: 1.3710e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.371e-05.\n",
      "Epoch 52/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6397e-04 - accuracy: 0.9926 - val_loss: 1.6345e-04 - val_accuracy: 0.9928 - lr: 1.3710e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.371e-05.\n",
      "Epoch 53/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6352e-04 - accuracy: 0.9926 - val_loss: 1.6541e-04 - val_accuracy: 0.9925 - lr: 1.3710e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.371e-05.\n",
      "Epoch 54/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6396e-04 - accuracy: 0.9926 - val_loss: 1.6323e-04 - val_accuracy: 0.9928 - lr: 1.3710e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.371e-05.\n",
      "Epoch 55/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6356e-04 - accuracy: 0.9926 - val_loss: 1.6499e-04 - val_accuracy: 0.9928 - lr: 1.3710e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.1653e-05.\n",
      "Epoch 56/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6311e-04 - accuracy: 0.9927 - val_loss: 1.6364e-04 - val_accuracy: 0.9929 - lr: 1.1653e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.1653e-05.\n",
      "Epoch 57/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6280e-04 - accuracy: 0.9927 - val_loss: 1.6328e-04 - val_accuracy: 0.9927 - lr: 1.1653e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.1653e-05.\n",
      "Epoch 58/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6290e-04 - accuracy: 0.9927 - val_loss: 1.6304e-04 - val_accuracy: 0.9929 - lr: 1.1653e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.1653e-05.\n",
      "Epoch 59/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6274e-04 - accuracy: 0.9927 - val_loss: 1.6288e-04 - val_accuracy: 0.9928 - lr: 1.1653e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.1653e-05.\n",
      "Epoch 60/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6332e-04 - accuracy: 0.9926 - val_loss: 1.6366e-04 - val_accuracy: 0.9926 - lr: 1.1653e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 9.905e-06.\n",
      "Epoch 61/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6232e-04 - accuracy: 0.9927 - val_loss: 1.6391e-04 - val_accuracy: 0.9928 - lr: 9.9050e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 9.905e-06.\n",
      "Epoch 62/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6242e-04 - accuracy: 0.9927 - val_loss: 1.6405e-04 - val_accuracy: 0.9927 - lr: 9.9050e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 9.905e-06.\n",
      "Epoch 63/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6230e-04 - accuracy: 0.9927 - val_loss: 1.6274e-04 - val_accuracy: 0.9929 - lr: 9.9050e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.905e-06.\n",
      "Epoch 64/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6190e-04 - accuracy: 0.9927 - val_loss: 1.6340e-04 - val_accuracy: 0.9928 - lr: 9.9050e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 9.905e-06.\n",
      "Epoch 65/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6209e-04 - accuracy: 0.9927 - val_loss: 1.6409e-04 - val_accuracy: 0.9927 - lr: 9.9050e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 8.419e-06.\n",
      "Epoch 66/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6161e-04 - accuracy: 0.9927 - val_loss: 1.6240e-04 - val_accuracy: 0.9928 - lr: 8.4190e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 8.419e-06.\n",
      "Epoch 67/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6186e-04 - accuracy: 0.9927 - val_loss: 1.6256e-04 - val_accuracy: 0.9927 - lr: 8.4190e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 8.419e-06.\n",
      "Epoch 68/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6146e-04 - accuracy: 0.9928 - val_loss: 1.6903e-04 - val_accuracy: 0.9919 - lr: 8.4190e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 8.419e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6134e-04 - accuracy: 0.9927 - val_loss: 1.6200e-04 - val_accuracy: 0.9930 - lr: 8.4190e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 8.419e-06.\n",
      "Epoch 70/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6163e-04 - accuracy: 0.9927 - val_loss: 1.6733e-04 - val_accuracy: 0.9922 - lr: 8.4190e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 7.156e-06.\n",
      "Epoch 71/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6125e-04 - accuracy: 0.9927 - val_loss: 1.6254e-04 - val_accuracy: 0.9929 - lr: 7.1560e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 7.156e-06.\n",
      "Epoch 72/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6095e-04 - accuracy: 0.9928 - val_loss: 1.6181e-04 - val_accuracy: 0.9929 - lr: 7.1560e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 7.156e-06.\n",
      "Epoch 73/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6124e-04 - accuracy: 0.9927 - val_loss: 1.6437e-04 - val_accuracy: 0.9925 - lr: 7.1560e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 7.156e-06.\n",
      "Epoch 74/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6096e-04 - accuracy: 0.9927 - val_loss: 1.6183e-04 - val_accuracy: 0.9930 - lr: 7.1560e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 7.156e-06.\n",
      "Epoch 75/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6090e-04 - accuracy: 0.9928 - val_loss: 1.6170e-04 - val_accuracy: 0.9929 - lr: 7.1560e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 6.083e-06.\n",
      "Epoch 76/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6062e-04 - accuracy: 0.9927 - val_loss: 1.6379e-04 - val_accuracy: 0.9929 - lr: 6.0830e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 6.083e-06.\n",
      "Epoch 77/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6061e-04 - accuracy: 0.9928 - val_loss: 1.6157e-04 - val_accuracy: 0.9929 - lr: 6.0830e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 6.083e-06.\n",
      "Epoch 78/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6071e-04 - accuracy: 0.9928 - val_loss: 1.6408e-04 - val_accuracy: 0.9929 - lr: 6.0830e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 6.083e-06.\n",
      "Epoch 79/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6067e-04 - accuracy: 0.9928 - val_loss: 1.6278e-04 - val_accuracy: 0.9929 - lr: 6.0830e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 6.083e-06.\n",
      "Epoch 80/150\n",
      "1693/1712 [============================>.] - ETA: 0s - loss: 1.6044e-04 - accuracy: 0.9928\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6050e-04 - accuracy: 0.9928 - val_loss: 1.6163e-04 - val_accuracy: 0.9929 - lr: 6.0830e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 5.171e-06.\n",
      "Epoch 81/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6010e-04 - accuracy: 0.9928 - val_loss: 1.6134e-04 - val_accuracy: 0.9929 - lr: 5.1710e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 5.171e-06.\n",
      "Epoch 82/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6011e-04 - accuracy: 0.9928 - val_loss: 1.6149e-04 - val_accuracy: 0.9929 - lr: 5.1710e-06\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 5.171e-06.\n",
      "Epoch 83/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6021e-04 - accuracy: 0.9928 - val_loss: 1.6126e-04 - val_accuracy: 0.9929 - lr: 5.1710e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 5.171e-06.\n",
      "Epoch 84/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6009e-04 - accuracy: 0.9928 - val_loss: 1.6204e-04 - val_accuracy: 0.9928 - lr: 5.1710e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 5.171e-06.\n",
      "Epoch 85/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.6017e-04 - accuracy: 0.9928 - val_loss: 1.6227e-04 - val_accuracy: 0.9929 - lr: 5.1710e-06\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 4.395e-06.\n",
      "Epoch 86/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5993e-04 - accuracy: 0.9928 - val_loss: 1.6835e-04 - val_accuracy: 0.9927 - lr: 4.3950e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.395e-06.\n",
      "Epoch 87/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5990e-04 - accuracy: 0.9928 - val_loss: 1.6115e-04 - val_accuracy: 0.9929 - lr: 4.3950e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 4.395e-06.\n",
      "Epoch 88/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5975e-04 - accuracy: 0.9928 - val_loss: 1.6158e-04 - val_accuracy: 0.9929 - lr: 4.3950e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 4.395e-06.\n",
      "Epoch 89/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5983e-04 - accuracy: 0.9928 - val_loss: 1.6155e-04 - val_accuracy: 0.9929 - lr: 4.3950e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 4.395e-06.\n",
      "Epoch 90/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5979e-04 - accuracy: 0.9928 - val_loss: 1.6129e-04 - val_accuracy: 0.9930 - lr: 4.3950e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 3.736e-06.\n",
      "Epoch 91/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5961e-04 - accuracy: 0.9928 - val_loss: 1.6101e-04 - val_accuracy: 0.9929 - lr: 3.7360e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 3.736e-06.\n",
      "Epoch 92/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5979e-04 - accuracy: 0.9928 - val_loss: 1.6180e-04 - val_accuracy: 0.9928 - lr: 3.7360e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.736e-06.\n",
      "Epoch 93/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5950e-04 - accuracy: 0.9928 - val_loss: 1.6079e-04 - val_accuracy: 0.9929 - lr: 3.7360e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 3.736e-06.\n",
      "Epoch 94/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5957e-04 - accuracy: 0.9928 - val_loss: 1.6166e-04 - val_accuracy: 0.9929 - lr: 3.7360e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.736e-06.\n",
      "Epoch 95/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5954e-04 - accuracy: 0.9928 - val_loss: 1.6121e-04 - val_accuracy: 0.9930 - lr: 3.7360e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.176e-06.\n",
      "Epoch 96/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5935e-04 - accuracy: 0.9928 - val_loss: 1.6107e-04 - val_accuracy: 0.9929 - lr: 3.1760e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.176e-06.\n",
      "Epoch 97/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5922e-04 - accuracy: 0.9928 - val_loss: 1.6091e-04 - val_accuracy: 0.9929 - lr: 3.1760e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.176e-06.\n",
      "Epoch 98/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5919e-04 - accuracy: 0.9928 - val_loss: 1.6174e-04 - val_accuracy: 0.9928 - lr: 3.1760e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.176e-06.\n",
      "Epoch 99/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5922e-04 - accuracy: 0.9928 - val_loss: 1.6062e-04 - val_accuracy: 0.9930 - lr: 3.1760e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 3.176e-06.\n",
      "Epoch 100/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5916e-04 - accuracy: 0.9929 - val_loss: 1.6209e-04 - val_accuracy: 0.9929 - lr: 3.1760e-06\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 2.7e-06.\n",
      "Epoch 101/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5904e-04 - accuracy: 0.9929 - val_loss: 1.6175e-04 - val_accuracy: 0.9928 - lr: 2.7000e-06\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 2.7e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5907e-04 - accuracy: 0.9928 - val_loss: 1.6055e-04 - val_accuracy: 0.9930 - lr: 2.7000e-06\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.7e-06.\n",
      "Epoch 103/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5904e-04 - accuracy: 0.9928 - val_loss: 1.6075e-04 - val_accuracy: 0.9929 - lr: 2.7000e-06\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 2.7e-06.\n",
      "Epoch 104/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5900e-04 - accuracy: 0.9928 - val_loss: 1.6130e-04 - val_accuracy: 0.9929 - lr: 2.7000e-06\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 2.7e-06.\n",
      "Epoch 105/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5896e-04 - accuracy: 0.9928 - val_loss: 1.6061e-04 - val_accuracy: 0.9929 - lr: 2.7000e-06\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 2.295e-06.\n",
      "Epoch 106/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5883e-04 - accuracy: 0.9928 - val_loss: 1.6042e-04 - val_accuracy: 0.9930 - lr: 2.2950e-06\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 2.295e-06.\n",
      "Epoch 107/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5881e-04 - accuracy: 0.9929 - val_loss: 1.6151e-04 - val_accuracy: 0.9929 - lr: 2.2950e-06\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 2.295e-06.\n",
      "Epoch 108/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5875e-04 - accuracy: 0.9929 - val_loss: 1.6051e-04 - val_accuracy: 0.9929 - lr: 2.2950e-06\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 2.295e-06.\n",
      "Epoch 109/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5878e-04 - accuracy: 0.9928 - val_loss: 1.6055e-04 - val_accuracy: 0.9930 - lr: 2.2950e-06\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 2.295e-06.\n",
      "Epoch 110/150\n",
      "1712/1712 [==============================] - 13s 7ms/step - loss: 1.5879e-04 - accuracy: 0.9929 - val_loss: 1.6256e-04 - val_accuracy: 0.9926 - lr: 2.2950e-06\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.951e-06.\n",
      "Epoch 111/150\n",
      "1712/1712 [==============================] - 13s 7ms/step - loss: 1.5876e-04 - accuracy: 0.9929 - val_loss: 1.6142e-04 - val_accuracy: 0.9928 - lr: 1.9510e-06\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.951e-06.\n",
      "Epoch 112/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5865e-04 - accuracy: 0.9929 - val_loss: 1.6055e-04 - val_accuracy: 0.9929 - lr: 1.9510e-06\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.951e-06.\n",
      "Epoch 113/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5860e-04 - accuracy: 0.9928 - val_loss: 1.6091e-04 - val_accuracy: 0.9929 - lr: 1.9510e-06\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.951e-06.\n",
      "Epoch 114/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5866e-04 - accuracy: 0.9928 - val_loss: 1.6071e-04 - val_accuracy: 0.9928 - lr: 1.9510e-06\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.951e-06.\n",
      "Epoch 115/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5862e-04 - accuracy: 0.9928 - val_loss: 1.6124e-04 - val_accuracy: 0.9929 - lr: 1.9510e-06\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.658e-06.\n",
      "Epoch 116/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5855e-04 - accuracy: 0.9929 - val_loss: 1.6042e-04 - val_accuracy: 0.9930 - lr: 1.6580e-06\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.658e-06.\n",
      "Epoch 117/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5858e-04 - accuracy: 0.9928 - val_loss: 1.6045e-04 - val_accuracy: 0.9930 - lr: 1.6580e-06\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.658e-06.\n",
      "Epoch 118/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5855e-04 - accuracy: 0.9929 - val_loss: 1.6041e-04 - val_accuracy: 0.9929 - lr: 1.6580e-06\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.658e-06.\n",
      "Epoch 119/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5845e-04 - accuracy: 0.9929 - val_loss: 1.6055e-04 - val_accuracy: 0.9930 - lr: 1.6580e-06\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.658e-06.\n",
      "Epoch 120/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5848e-04 - accuracy: 0.9928 - val_loss: 1.6039e-04 - val_accuracy: 0.9929 - lr: 1.6580e-06\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 1.409e-06.\n",
      "Epoch 121/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5839e-04 - accuracy: 0.9929 - val_loss: 1.6049e-04 - val_accuracy: 0.9929 - lr: 1.4090e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 1.409e-06.\n",
      "Epoch 122/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5839e-04 - accuracy: 0.9928 - val_loss: 1.6035e-04 - val_accuracy: 0.9930 - lr: 1.4090e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 1.409e-06.\n",
      "Epoch 123/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5839e-04 - accuracy: 0.9929 - val_loss: 1.6026e-04 - val_accuracy: 0.9930 - lr: 1.4090e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 1.409e-06.\n",
      "Epoch 124/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5837e-04 - accuracy: 0.9929 - val_loss: 1.6035e-04 - val_accuracy: 0.9929 - lr: 1.4090e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 1.409e-06.\n",
      "Epoch 125/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5837e-04 - accuracy: 0.9929 - val_loss: 1.6027e-04 - val_accuracy: 0.9929 - lr: 1.4090e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 1.198e-06.\n",
      "Epoch 126/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5830e-04 - accuracy: 0.9929 - val_loss: 1.6045e-04 - val_accuracy: 0.9929 - lr: 1.1980e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 1.198e-06.\n",
      "Epoch 127/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5828e-04 - accuracy: 0.9929 - val_loss: 1.6028e-04 - val_accuracy: 0.9929 - lr: 1.1980e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 1.198e-06.\n",
      "Epoch 128/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5826e-04 - accuracy: 0.9929 - val_loss: 1.6122e-04 - val_accuracy: 0.9928 - lr: 1.1980e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 1.198e-06.\n",
      "Epoch 129/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5829e-04 - accuracy: 0.9929 - val_loss: 1.6039e-04 - val_accuracy: 0.9930 - lr: 1.1980e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 1.198e-06.\n",
      "Epoch 130/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5827e-04 - accuracy: 0.9929 - val_loss: 1.6029e-04 - val_accuracy: 0.9930 - lr: 1.1980e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 1.018e-06.\n",
      "Epoch 131/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5819e-04 - accuracy: 0.9929 - val_loss: 1.6030e-04 - val_accuracy: 0.9930 - lr: 1.0180e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 1.018e-06.\n",
      "Epoch 132/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5818e-04 - accuracy: 0.9929 - val_loss: 1.6038e-04 - val_accuracy: 0.9930 - lr: 1.0180e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 1.018e-06.\n",
      "Epoch 133/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5821e-04 - accuracy: 0.9929 - val_loss: 1.6042e-04 - val_accuracy: 0.9929 - lr: 1.0180e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 1.018e-06.\n",
      "Epoch 134/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5821e-04 - accuracy: 0.9929 - val_loss: 1.6051e-04 - val_accuracy: 0.9929 - lr: 1.0180e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 1.018e-06.\n",
      "Epoch 135/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5819e-04 - accuracy: 0.9929 - val_loss: 1.6037e-04 - val_accuracy: 0.9930 - lr: 1.0180e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 8.65e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5810e-04 - accuracy: 0.9929 - val_loss: 1.6083e-04 - val_accuracy: 0.9928 - lr: 8.6500e-07\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 8.65e-07.\n",
      "Epoch 137/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5813e-04 - accuracy: 0.9929 - val_loss: 1.6035e-04 - val_accuracy: 0.9929 - lr: 8.6500e-07\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 8.65e-07.\n",
      "Epoch 138/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5812e-04 - accuracy: 0.9929 - val_loss: 1.6025e-04 - val_accuracy: 0.9929 - lr: 8.6500e-07\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 8.65e-07.\n",
      "Epoch 139/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5811e-04 - accuracy: 0.9929 - val_loss: 1.6074e-04 - val_accuracy: 0.9930 - lr: 8.6500e-07\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 8.65e-07.\n",
      "Epoch 140/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5810e-04 - accuracy: 0.9929 - val_loss: 1.6087e-04 - val_accuracy: 0.9929 - lr: 8.6500e-07\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 7.35e-07.\n",
      "Epoch 141/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5808e-04 - accuracy: 0.9929 - val_loss: 1.6026e-04 - val_accuracy: 0.9929 - lr: 7.3500e-07\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 7.35e-07.\n",
      "Epoch 142/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5806e-04 - accuracy: 0.9929 - val_loss: 1.6015e-04 - val_accuracy: 0.9929 - lr: 7.3500e-07\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 7.35e-07.\n",
      "Epoch 143/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5800e-04 - accuracy: 0.9929 - val_loss: 1.6136e-04 - val_accuracy: 0.9928 - lr: 7.3500e-07\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 7.35e-07.\n",
      "Epoch 144/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5800e-04 - accuracy: 0.9929 - val_loss: 1.6053e-04 - val_accuracy: 0.9929 - lr: 7.3500e-07\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 7.35e-07.\n",
      "Epoch 145/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5799e-04 - accuracy: 0.9929 - val_loss: 1.6044e-04 - val_accuracy: 0.9929 - lr: 7.3500e-07\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 146/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5800e-04 - accuracy: 0.9928 - val_loss: 1.6031e-04 - val_accuracy: 0.9929 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 147/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5798e-04 - accuracy: 0.9929 - val_loss: 1.6025e-04 - val_accuracy: 0.9929 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 148/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5795e-04 - accuracy: 0.9929 - val_loss: 1.6057e-04 - val_accuracy: 0.9929 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 149/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5795e-04 - accuracy: 0.9929 - val_loss: 1.6017e-04 - val_accuracy: 0.9929 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 150/150\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 1.5798e-04 - accuracy: 0.9928 - val_loss: 1.6040e-04 - val_accuracy: 0.9929 - lr: 6.2500e-07\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = iter2,batch_size = bs2,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler2,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff62425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 22:15:41.208157: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 256/cp.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
