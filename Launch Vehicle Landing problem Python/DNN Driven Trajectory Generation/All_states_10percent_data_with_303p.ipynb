{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for 10 percent data variation\n",
    "1. Batch size = 64\n",
    "2. Neurons = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DVrymL7YtWo",
    "outputId": "6739e8e0-11b0-403f-ad08-0c603e88fb9d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "g2QhOkBkYzgE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/saichaitanya/Chaitanya/CSV files/May7rd10percent_RLV_data 100 points2 .csv',header = None,names = ['h','v','s','omega','gamma','m','theta','Thrust','beta','time'])\n",
    "input = output =df.values\n",
    "X = input[:,0:7]\n",
    "y = output[:,7:9]\n",
    "# Individual Data\n",
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.minmax_scale(X)\n",
    "y_norm = preprocessing.minmax_scale(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.1, random_state=42)\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>v</th>\n",
       "      <th>s</th>\n",
       "      <th>omega</th>\n",
       "      <th>gamma</th>\n",
       "      <th>m</th>\n",
       "      <th>theta</th>\n",
       "      <th>Thrust</th>\n",
       "      <th>beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>2.210890e+05</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "      <td>221089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>923.478003</td>\n",
       "      <td>102.870601</td>\n",
       "      <td>6.908459e+02</td>\n",
       "      <td>-0.016870</td>\n",
       "      <td>-1.484311</td>\n",
       "      <td>23153.406167</td>\n",
       "      <td>-1.481758</td>\n",
       "      <td>482935.884011</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>21.706884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1334.673350</td>\n",
       "      <td>90.152141</td>\n",
       "      <td>2.535273e+02</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.124744</td>\n",
       "      <td>1339.376075</td>\n",
       "      <td>0.353444</td>\n",
       "      <td>101507.477577</td>\n",
       "      <td>0.046149</td>\n",
       "      <td>9.133048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.059782</td>\n",
       "      <td>4.996700</td>\n",
       "      <td>-5.031700e-07</td>\n",
       "      <td>-0.431760</td>\n",
       "      <td>-1.709600</td>\n",
       "      <td>21357.000000</td>\n",
       "      <td>-2.805200</td>\n",
       "      <td>356960.000000</td>\n",
       "      <td>-0.208800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.201000</td>\n",
       "      <td>18.925000</td>\n",
       "      <td>5.572900e+02</td>\n",
       "      <td>-0.072434</td>\n",
       "      <td>-1.571100</td>\n",
       "      <td>22054.000000</td>\n",
       "      <td>-1.570800</td>\n",
       "      <td>403840.000000</td>\n",
       "      <td>-0.013007</td>\n",
       "      <td>15.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>252.570000</td>\n",
       "      <td>80.095000</td>\n",
       "      <td>8.201600e+02</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-1.552900</td>\n",
       "      <td>22775.000000</td>\n",
       "      <td>-1.558000</td>\n",
       "      <td>442150.000000</td>\n",
       "      <td>-0.002892</td>\n",
       "      <td>24.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1336.200000</td>\n",
       "      <td>174.840000</td>\n",
       "      <td>8.611500e+02</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-1.424600</td>\n",
       "      <td>24081.000000</td>\n",
       "      <td>-1.308800</td>\n",
       "      <td>542160.000000</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>29.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5263.200000</td>\n",
       "      <td>342.110000</td>\n",
       "      <td>9.080300e+02</td>\n",
       "      <td>0.436880</td>\n",
       "      <td>-0.936550</td>\n",
       "      <td>26230.000000</td>\n",
       "      <td>-0.325280</td>\n",
       "      <td>769190.000000</td>\n",
       "      <td>0.210660</td>\n",
       "      <td>34.102000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   h              v             s          omega  \\\n",
       "count  221089.000000  221089.000000  2.210890e+05  221089.000000   \n",
       "mean      923.478003     102.870601  6.908459e+02      -0.016870   \n",
       "std      1334.673350      90.152141  2.535273e+02       0.127985   \n",
       "min        -0.059782       4.996700 -5.031700e-07      -0.431760   \n",
       "25%        11.201000      18.925000  5.572900e+02      -0.072434   \n",
       "50%       252.570000      80.095000  8.201600e+02      -0.006814   \n",
       "75%      1336.200000     174.840000  8.611500e+02      -0.000024   \n",
       "max      5263.200000     342.110000  9.080300e+02       0.436880   \n",
       "\n",
       "               gamma              m          theta         Thrust  \\\n",
       "count  221089.000000  221089.000000  221089.000000  221089.000000   \n",
       "mean       -1.484311   23153.406167      -1.481758  482935.884011   \n",
       "std         0.124744    1339.376075       0.353444  101507.477577   \n",
       "min        -1.709600   21357.000000      -2.805200  356960.000000   \n",
       "25%        -1.571100   22054.000000      -1.570800  403840.000000   \n",
       "50%        -1.552900   22775.000000      -1.558000  442150.000000   \n",
       "75%        -1.424600   24081.000000      -1.308800  542160.000000   \n",
       "max        -0.936550   26230.000000      -0.325280  769190.000000   \n",
       "\n",
       "                beta           time  \n",
       "count  221089.000000  221089.000000  \n",
       "mean        0.001837      21.706884  \n",
       "std         0.046149       9.133048  \n",
       "min        -0.208800       0.000000  \n",
       "25%        -0.013007      15.873000  \n",
       "50%        -0.002892      24.555000  \n",
       "75%         0.001759      29.015000  \n",
       "max         0.210660      34.102000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qmMojsgZZL4J"
   },
   "outputs": [],
   "source": [
    "def create_model2(n):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n,input_shape=(7,),kernel_initializer='uniform'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu')) # since tanh has more nonlinearity we add it here, it also gives -ve values so , some layers which are not necessary will lead to 0 in next layer\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(2,kernel_initializer='uniform',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iDASMcALZLuU"
   },
   "outputs": [],
   "source": [
    "i = 7;\n",
    "model = create_model2(2**i)\n",
    "# model.load_weights(f\"/content/gdrive/My Drive/Last data /1percent model/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtOxXma1ZVEa",
    "outputId": "f9061dfc-f948-4d58-c0b7-e36ff541b702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5000009 , 0.4999882 ],\n",
       "       [0.5000028 , 0.49998745],\n",
       "       [0.50000083, 0.49999076],\n",
       "       ...,\n",
       "       [0.5000019 , 0.49998888],\n",
       "       [0.5000026 , 0.49998564],\n",
       "       [0.49999967, 0.49998665]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fgzcli_dZYAy",
    "outputId": "78df5779-251e-4887-9dc9-7dd1fa2fa894"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77228732, 0.49065417],\n",
       "       [0.33520122, 0.49494994],\n",
       "       [0.18111249, 0.60267487],\n",
       "       ...,\n",
       "       [0.93282876, 0.464738  ],\n",
       "       [0.068651  , 0.63641587],\n",
       "       [0.08703879, 0.31978496]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6AnPdtQZLru",
    "outputId": "ba21d3c2-2260-4183-f1d8-043147601c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def lr_sch3(epoch,lr):\n",
    "    if (epoch >0) &(epoch<300):\n",
    "      if epoch%50==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>300):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_sch3,verbose = 1)\n",
    "bs = 64;\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / bs\n",
    "save_period = 20\n",
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5906/5906 [==============================] - 11s 2ms/step - loss: 0.0552 - accuracy: 0.2254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0551857128739357, 0.22543655335903168]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weightsweights(f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iabK_vxVZcWj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0105 - accuracy: 0.8715 - val_loss: 0.0069 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0064 - accuracy: 0.8922 - val_loss: 0.0064 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0057 - accuracy: 0.8955 - val_loss: 0.0051 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0052 - accuracy: 0.8985 - val_loss: 0.0054 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0049 - accuracy: 0.9014 - val_loss: 0.0045 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0047 - accuracy: 0.9036 - val_loss: 0.0043 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0044 - accuracy: 0.9061 - val_loss: 0.0045 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0043 - accuracy: 0.9077 - val_loss: 0.0041 - val_accuracy: 0.9012 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0041 - accuracy: 0.9093 - val_loss: 0.0035 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0040 - accuracy: 0.9106 - val_loss: 0.0042 - val_accuracy: 0.9189 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0039 - accuracy: 0.9127 - val_loss: 0.0035 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0038 - accuracy: 0.9130 - val_loss: 0.0038 - val_accuracy: 0.9068 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0038 - accuracy: 0.9129 - val_loss: 0.0035 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0037 - accuracy: 0.9125 - val_loss: 0.0031 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0037 - accuracy: 0.9141 - val_loss: 0.0032 - val_accuracy: 0.9151 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9159 - val_loss: 0.0034 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9164 - val_loss: 0.0032 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0032 - accuracy: 0.9191 - val_loss: 0.0026 - val_accuracy: 0.9358 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0031 - accuracy: 0.9221 - val_loss: 0.0038 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/1000\n",
      "2948/2953 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9236\n",
      "Epoch 20: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0030 - accuracy: 0.9236 - val_loss: 0.0028 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0031 - accuracy: 0.9230 - val_loss: 0.0025 - val_accuracy: 0.9375 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9258 - val_loss: 0.0029 - val_accuracy: 0.9307 - lr: 0.0010\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9253 - val_loss: 0.0032 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9256 - val_loss: 0.0037 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0028 - accuracy: 0.9269 - val_loss: 0.0037 - val_accuracy: 0.9227 - lr: 0.0010\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 26/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0027 - accuracy: 0.9278 - val_loss: 0.0028 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 27/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0028 - accuracy: 0.9264 - val_loss: 0.0019 - val_accuracy: 0.9497 - lr: 0.0010\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 28/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0028 - accuracy: 0.9276 - val_loss: 0.0021 - val_accuracy: 0.9433 - lr: 0.0010\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 29/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0028 - accuracy: 0.9267 - val_loss: 0.0021 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 30/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9261 - val_loss: 0.0025 - val_accuracy: 0.9294 - lr: 0.0010\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 31/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0025 - accuracy: 0.9317 - val_loss: 0.0017 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 32/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0025 - accuracy: 0.9331 - val_loss: 0.0024 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 33/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0024 - accuracy: 0.9332 - val_loss: 0.0027 - val_accuracy: 0.9291 - lr: 0.0010\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 34/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0024 - accuracy: 0.9339 - val_loss: 0.0029 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 35/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0023 - accuracy: 0.9352 - val_loss: 0.0017 - val_accuracy: 0.9546 - lr: 0.0010\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0022 - accuracy: 0.9376 - val_loss: 0.0019 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 37/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0022 - accuracy: 0.9377 - val_loss: 0.0016 - val_accuracy: 0.9588 - lr: 0.0010\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 38/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0022 - accuracy: 0.9376 - val_loss: 0.0018 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 39/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0022 - accuracy: 0.9376 - val_loss: 0.0018 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 40/1000\n",
      "2937/2953 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9394\n",
      "Epoch 40: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9394 - val_loss: 0.0022 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 41/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0023 - accuracy: 0.9366 - val_loss: 0.0024 - val_accuracy: 0.9322 - lr: 0.0010\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 42/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0022 - accuracy: 0.9382 - val_loss: 0.0021 - val_accuracy: 0.9387 - lr: 0.0010\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 43/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9395 - val_loss: 0.0025 - val_accuracy: 0.9239 - lr: 0.0010\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 44/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9396 - val_loss: 0.0021 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 45/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0020 - accuracy: 0.9420 - val_loss: 0.0017 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 46/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0020 - accuracy: 0.9425 - val_loss: 0.0047 - val_accuracy: 0.9034 - lr: 0.0010\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 47/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9409 - val_loss: 0.0015 - val_accuracy: 0.9571 - lr: 0.0010\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 48/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0020 - accuracy: 0.9421 - val_loss: 0.0016 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 49/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0019 - accuracy: 0.9450 - val_loss: 0.0020 - val_accuracy: 0.9391 - lr: 0.0010\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 50/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0020 - accuracy: 0.9441 - val_loss: 0.0015 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 51/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0015 - accuracy: 0.9535 - val_loss: 0.0011 - val_accuracy: 0.9699 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 52/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0015 - accuracy: 0.9552 - val_loss: 0.0019 - val_accuracy: 0.9359 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 53/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0015 - accuracy: 0.9535 - val_loss: 0.0013 - val_accuracy: 0.9665 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 54/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0015 - accuracy: 0.9539 - val_loss: 0.0020 - val_accuracy: 0.9396 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 55/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0015 - accuracy: 0.9551 - val_loss: 0.0018 - val_accuracy: 0.9436 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 56/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0014 - accuracy: 0.9561 - val_loss: 0.0010 - val_accuracy: 0.9670 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 57/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0014 - accuracy: 0.9559 - val_loss: 0.0016 - val_accuracy: 0.9525 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 58/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9578 - val_loss: 9.8423e-04 - val_accuracy: 0.9766 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 59/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0014 - accuracy: 0.9571 - val_loss: 9.5710e-04 - val_accuracy: 0.9734 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 60/1000\n",
      "2937/2953 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9570\n",
      "Epoch 60: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0014 - accuracy: 0.9571 - val_loss: 0.0010 - val_accuracy: 0.9709 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 61/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9577 - val_loss: 0.0010 - val_accuracy: 0.9717 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 62/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9594 - val_loss: 0.0015 - val_accuracy: 0.9539 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 63/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0014 - accuracy: 0.9560 - val_loss: 0.0010 - val_accuracy: 0.9646 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 64/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0014 - accuracy: 0.9571 - val_loss: 0.0013 - val_accuracy: 0.9693 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 65/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9601 - val_loss: 0.0015 - val_accuracy: 0.9604 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 66/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9600 - val_loss: 0.0010 - val_accuracy: 0.9721 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 67/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9592 - val_loss: 9.9377e-04 - val_accuracy: 0.9670 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 68/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9582 - val_loss: 9.3782e-04 - val_accuracy: 0.9737 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9592 - val_loss: 0.0010 - val_accuracy: 0.9706 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 70/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9594 - val_loss: 0.0014 - val_accuracy: 0.9529 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 71/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9575 - val_loss: 0.0011 - val_accuracy: 0.9626 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 72/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9584 - val_loss: 0.0012 - val_accuracy: 0.9570 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 73/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9584 - val_loss: 0.0013 - val_accuracy: 0.9578 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 74/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9592 - val_loss: 0.0014 - val_accuracy: 0.9530 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 75/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9597 - val_loss: 0.0019 - val_accuracy: 0.9375 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 76/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9598 - val_loss: 0.0012 - val_accuracy: 0.9587 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 77/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9619 - val_loss: 0.0015 - val_accuracy: 0.9524 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 78/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9600 - val_loss: 0.0013 - val_accuracy: 0.9680 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 79/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9613 - val_loss: 7.8590e-04 - val_accuracy: 0.9742 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 80/1000\n",
      "2931/2953 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9611\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9611 - val_loss: 8.7393e-04 - val_accuracy: 0.9753 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 81/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9609 - val_loss: 0.0018 - val_accuracy: 0.9519 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 82/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9626 - val_loss: 0.0011 - val_accuracy: 0.9651 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 83/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9627 - val_loss: 8.4924e-04 - val_accuracy: 0.9717 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 84/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9610 - val_loss: 0.0011 - val_accuracy: 0.9742 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 85/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9603 - val_loss: 0.0012 - val_accuracy: 0.9639 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 86/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9619 - val_loss: 0.0011 - val_accuracy: 0.9672 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 87/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9591 - val_loss: 0.0012 - val_accuracy: 0.9560 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 88/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9608 - val_loss: 8.1954e-04 - val_accuracy: 0.9705 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 89/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9611 - val_loss: 9.6970e-04 - val_accuracy: 0.9741 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 90/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9606 - val_loss: 0.0015 - val_accuracy: 0.9503 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 91/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9613 - val_loss: 0.0012 - val_accuracy: 0.9684 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 92/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9621 - val_loss: 7.7234e-04 - val_accuracy: 0.9778 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 93/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9616 - val_loss: 0.0011 - val_accuracy: 0.9606 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 94/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9617 - val_loss: 9.9945e-04 - val_accuracy: 0.9716 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 95/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9621 - val_loss: 9.0556e-04 - val_accuracy: 0.9683 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 96/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9630 - val_loss: 0.0011 - val_accuracy: 0.9719 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 97/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9634 - val_loss: 9.9988e-04 - val_accuracy: 0.9696 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 98/1000\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 0.0011 - accuracy: 0.9631 - val_loss: 9.1833e-04 - val_accuracy: 0.9730 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 99/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 7.7008e-04 - val_accuracy: 0.9706 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 100/1000\n",
      "2921/2953 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9630\n",
      "Epoch 100: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9629 - val_loss: 0.0021 - val_accuracy: 0.9270 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 101/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.9502e-04 - accuracy: 0.9687 - val_loss: 7.1524e-04 - val_accuracy: 0.9766 - lr: 4.0660e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 102/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 9.1047e-04 - accuracy: 0.9683 - val_loss: 7.5645e-04 - val_accuracy: 0.9756 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 103/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 9.0078e-04 - accuracy: 0.9688 - val_loss: 0.0012 - val_accuracy: 0.9580 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 104/1000\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.6355e-04 - accuracy: 0.9696 - val_loss: 8.1855e-04 - val_accuracy: 0.9743 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 105/1000\n",
      "1804/2953 [=================>............] - ETA: 4s - loss: 8.3529e-04 - accuracy: 0.9699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/training.py:1376\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1374\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1376\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m         epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m         step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m         _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/data_adapter.py:1246\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1247\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1248\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   1251\u001b[0m     original_spe)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    675\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    676\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:749\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m the read operation.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle()\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    731\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    732\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    734\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    735\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    736\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:718\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_set_handle\u001b[39m():\n\u001b[0;32m--> 718\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m   _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    721\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:479\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    478\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 100,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_sch100(epoch,lr):\n",
    "    epoch = epoch+100\n",
    "    if (epoch >0) &(epoch<125):\n",
    "      if epoch%50==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>125):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "lr_scheduler2 = tf.keras.callbacks.LearningRateScheduler(lr_sch100,verbose = 1)\n",
    "cp_callback2 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1b93fe6e90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 1/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 9.1224e-04 - accuracy: 0.9687 - val_loss: 8.6851e-04 - val_accuracy: 0.9729 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 2/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 9.1803e-04 - accuracy: 0.9680 - val_loss: 6.3282e-04 - val_accuracy: 0.9774 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 3/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 9.1557e-04 - accuracy: 0.9681 - val_loss: 7.9038e-04 - val_accuracy: 0.9718 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 4/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.9270e-04 - accuracy: 0.9687 - val_loss: 8.3350e-04 - val_accuracy: 0.9755 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 5/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 9.0222e-04 - accuracy: 0.9687 - val_loss: 8.3813e-04 - val_accuracy: 0.9681 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 6/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4883e-04 - accuracy: 0.9704 - val_loss: 8.7957e-04 - val_accuracy: 0.9726 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 7/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.6183e-04 - accuracy: 0.9699 - val_loss: 7.3656e-04 - val_accuracy: 0.9729 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 8/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4279e-04 - accuracy: 0.9702 - val_loss: 6.4940e-04 - val_accuracy: 0.9752 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 9/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.3544e-04 - accuracy: 0.9703 - val_loss: 8.7085e-04 - val_accuracy: 0.9732 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 10/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.3260e-04 - accuracy: 0.9706 - val_loss: 9.6749e-04 - val_accuracy: 0.9699 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 11/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.7846e-04 - accuracy: 0.9692 - val_loss: 6.6112e-04 - val_accuracy: 0.9788 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 12/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.9173e-04 - accuracy: 0.9687 - val_loss: 6.8226e-04 - val_accuracy: 0.9779 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 13/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.3479e-04 - accuracy: 0.9701 - val_loss: 7.2894e-04 - val_accuracy: 0.9732 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 14/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.3544e-04 - accuracy: 0.9705 - val_loss: 7.0520e-04 - val_accuracy: 0.9737 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 15/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.3740e-04 - accuracy: 0.9704 - val_loss: 7.4816e-04 - val_accuracy: 0.9766 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 16/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.6882e-04 - accuracy: 0.9692 - val_loss: 7.2850e-04 - val_accuracy: 0.9762 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 17/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.3251e-04 - accuracy: 0.9706 - val_loss: 8.1262e-04 - val_accuracy: 0.9718 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 18/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.3532e-04 - accuracy: 0.9704 - val_loss: 6.8345e-04 - val_accuracy: 0.9769 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 19/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4876e-04 - accuracy: 0.9699 - val_loss: 9.6711e-04 - val_accuracy: 0.9638 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 20/600\n",
      "2937/2953 [============================>.] - ETA: 0s - loss: 8.1492e-04 - accuracy: 0.9708\n",
      "Epoch 20: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.1525e-04 - accuracy: 0.9708 - val_loss: 6.0649e-04 - val_accuracy: 0.9779 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 21/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4017e-04 - accuracy: 0.9702 - val_loss: 0.0015 - val_accuracy: 0.9473 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 22/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.1749e-04 - accuracy: 0.9704 - val_loss: 8.7003e-04 - val_accuracy: 0.9673 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 23/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.0250e-04 - accuracy: 0.9713 - val_loss: 7.0811e-04 - val_accuracy: 0.9746 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 24/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4375e-04 - accuracy: 0.9707 - val_loss: 8.4132e-04 - val_accuracy: 0.9727 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 25/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.4514e-04 - accuracy: 0.9708 - val_loss: 7.3962e-04 - val_accuracy: 0.9775 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 26/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 8.3961e-04 - accuracy: 0.9700 - val_loss: 7.0174e-04 - val_accuracy: 0.9714 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 27/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 8.3063e-04 - accuracy: 0.9704 - val_loss: 7.9125e-04 - val_accuracy: 0.9696 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 28/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 7.9311e-04 - accuracy: 0.9720 - val_loss: 0.0022 - val_accuracy: 0.9314 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 29/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 7.9890e-04 - accuracy: 0.9707 - val_loss: 0.0012 - val_accuracy: 0.9552 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 30/600\n",
      "2640/2953 [=========================>....] - ETA: 1s - loss: 8.2685e-04 - accuracy: 0.9700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 7.2991e-04 - accuracy: 0.9735 - val_loss: 9.4370e-04 - val_accuracy: 0.9666 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 47/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 7.4224e-04 - accuracy: 0.9726 - val_loss: 6.4031e-04 - val_accuracy: 0.9732 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 48/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 7.2179e-04 - accuracy: 0.9730 - val_loss: 5.1998e-04 - val_accuracy: 0.9804 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 49/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 7.4854e-04 - accuracy: 0.9722 - val_loss: 0.0012 - val_accuracy: 0.9630 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 50/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 7.2292e-04 - accuracy: 0.9734 - val_loss: 5.2919e-04 - val_accuracy: 0.9788 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 51/600\n",
      "1557/2953 [==============>...............] - ETA: 5s - loss: 6.9654e-04 - accuracy: 0.9741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 7.1962e-04 - accuracy: 0.9732 - val_loss: 5.2912e-04 - val_accuracy: 0.9802 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 59/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 6.9898e-04 - accuracy: 0.9738 - val_loss: 5.6690e-04 - val_accuracy: 0.9769 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00034561.\n",
      "Epoch 60/600\n",
      "2929/2953 [============================>.] - ETA: 0s - loss: 6.8842e-04 - accuracy: 0.9743\n",
      "Epoch 60: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 6.8730e-04 - accuracy: 0.9743 - val_loss: 7.7900e-04 - val_accuracy: 0.9729 - lr: 3.4561e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 61/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 6.5509e-04 - accuracy: 0.9753 - val_loss: 5.9855e-04 - val_accuracy: 0.9763 - lr: 2.9377e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 62/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 6.1708e-04 - accuracy: 0.9766 - val_loss: 6.1142e-04 - val_accuracy: 0.9786 - lr: 2.9377e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 63/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 6.7026e-04 - accuracy: 0.9743 - val_loss: 7.0748e-04 - val_accuracy: 0.9713 - lr: 2.9377e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 64/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 6.4510e-04 - accuracy: 0.9752 - val_loss: 5.5572e-04 - val_accuracy: 0.9790 - lr: 2.9377e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 65/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 6.4179e-04 - accuracy: 0.9758 - val_loss: 4.9845e-04 - val_accuracy: 0.9800 - lr: 2.9377e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.000293768.\n",
      "Epoch 66/600\n",
      " 863/2953 [=======>......................] - ETA: 8s - loss: 6.7542e-04 - accuracy: 0.9752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.9931e-04 - accuracy: 0.9767 - val_loss: 6.1196e-04 - val_accuracy: 0.9801 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 84/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.9014e-04 - accuracy: 0.9774 - val_loss: 5.3145e-04 - val_accuracy: 0.9827 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 85/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.8277e-04 - accuracy: 0.9775 - val_loss: 6.6112e-04 - val_accuracy: 0.9741 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 86/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.8365e-04 - accuracy: 0.9773 - val_loss: 4.4268e-04 - val_accuracy: 0.9840 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 87/600\n",
      "1840/2953 [=================>............] - ETA: 4s - loss: 5.8104e-04 - accuracy: 0.9771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.6301e-04 - accuracy: 0.9776 - val_loss: 8.4131e-04 - val_accuracy: 0.9680 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 95/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.6791e-04 - accuracy: 0.9776 - val_loss: 6.0207e-04 - val_accuracy: 0.9762 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 96/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.8045e-04 - accuracy: 0.9774 - val_loss: 0.0011 - val_accuracy: 0.9617 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 97/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.8911e-04 - accuracy: 0.9767 - val_loss: 6.3441e-04 - val_accuracy: 0.9788 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 98/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.7413e-04 - accuracy: 0.9776 - val_loss: 4.8680e-04 - val_accuracy: 0.9820 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 99/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.5236e-04 - accuracy: 0.9782 - val_loss: 5.0176e-04 - val_accuracy: 0.9788 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.000249703.\n",
      "Epoch 100/600\n",
      "2927/2953 [============================>.] - ETA: 0s - loss: 5.6657e-04 - accuracy: 0.9781\n",
      "Epoch 100: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.6762e-04 - accuracy: 0.9781 - val_loss: 4.5250e-04 - val_accuracy: 0.9818 - lr: 2.4970e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.000212248.\n",
      "Epoch 101/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.2383e-04 - accuracy: 0.9790 - val_loss: 4.0788e-04 - val_accuracy: 0.9832 - lr: 2.1225e-04\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.000212248.\n",
      "Epoch 102/600\n",
      "1118/2953 [==========>...................] - ETA: 7s - loss: 5.1897e-04 - accuracy: 0.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.3810e-04 - accuracy: 0.9792 - val_loss: 4.3922e-04 - val_accuracy: 0.9815 - lr: 2.1225e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.000212248.\n",
      "Epoch 119/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 5.0135e-04 - accuracy: 0.9801 - val_loss: 4.2603e-04 - val_accuracy: 0.9823 - lr: 2.1225e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.000212248.\n",
      "Epoch 120/600\n",
      "2920/2953 [============================>.] - ETA: 0s - loss: 5.3983e-04 - accuracy: 0.9790\n",
      "Epoch 120: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 5.3934e-04 - accuracy: 0.9790 - val_loss: 5.9519e-04 - val_accuracy: 0.9742 - lr: 2.1225e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 121/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.9062e-04 - accuracy: 0.9802 - val_loss: 4.2023e-04 - val_accuracy: 0.9809 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 122/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.9004e-04 - accuracy: 0.9798 - val_loss: 5.5616e-04 - val_accuracy: 0.9756 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 123/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.7770e-04 - accuracy: 0.9806 - val_loss: 5.9698e-04 - val_accuracy: 0.9804 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 124/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.7980e-04 - accuracy: 0.9804 - val_loss: 4.8926e-04 - val_accuracy: 0.9781 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 125/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.8259e-04 - accuracy: 0.9802 - val_loss: 4.3283e-04 - val_accuracy: 0.9856 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 126/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.6883e-04 - accuracy: 0.9805 - val_loss: 4.2279e-04 - val_accuracy: 0.9838 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 127/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.7084e-04 - accuracy: 0.9807 - val_loss: 3.9710e-04 - val_accuracy: 0.9845 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 128/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.8457e-04 - accuracy: 0.9799 - val_loss: 3.9335e-04 - val_accuracy: 0.9841 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 129/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.8461e-04 - accuracy: 0.9804 - val_loss: 9.2016e-04 - val_accuracy: 0.9647 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 130/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.7981e-04 - accuracy: 0.9804 - val_loss: 4.0086e-04 - val_accuracy: 0.9859 - lr: 1.8041e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.000180411.\n",
      "Epoch 131/600\n",
      " 414/2953 [===>..........................] - ETA: 10s - loss: 5.0274e-04 - accuracy: 0.9785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.4031e-04 - accuracy: 0.9814 - val_loss: 3.8831e-04 - val_accuracy: 0.9856 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 155/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.3005e-04 - accuracy: 0.9822 - val_loss: 3.5386e-04 - val_accuracy: 0.9844 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 156/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.5756e-04 - accuracy: 0.9814 - val_loss: 3.5534e-04 - val_accuracy: 0.9872 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 157/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.3698e-04 - accuracy: 0.9822 - val_loss: 3.9172e-04 - val_accuracy: 0.9848 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 158/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.2741e-04 - accuracy: 0.9821 - val_loss: 3.4135e-04 - val_accuracy: 0.9882 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 159/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.3012e-04 - accuracy: 0.9819 - val_loss: 3.8632e-04 - val_accuracy: 0.9870 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.000153349.\n",
      "Epoch 160/600\n",
      "2908/2953 [============================>.] - ETA: 0s - loss: 4.5419e-04 - accuracy: 0.9817\n",
      "Epoch 160: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.5359e-04 - accuracy: 0.9817 - val_loss: 3.9791e-04 - val_accuracy: 0.9863 - lr: 1.5335e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 161/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.2391e-04 - accuracy: 0.9823 - val_loss: 3.6814e-04 - val_accuracy: 0.9852 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 162/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.0950e-04 - accuracy: 0.9828 - val_loss: 3.4005e-04 - val_accuracy: 0.9868 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 163/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.1952e-04 - accuracy: 0.9823 - val_loss: 4.0098e-04 - val_accuracy: 0.9854 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 164/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.1392e-04 - accuracy: 0.9826 - val_loss: 6.4047e-04 - val_accuracy: 0.9754 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 165/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 4.0411e-04 - accuracy: 0.9830 - val_loss: 3.5994e-04 - val_accuracy: 0.9843 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 166/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 4.0953e-04 - accuracy: 0.9826 - val_loss: 4.3042e-04 - val_accuracy: 0.9824 - lr: 1.3035e-04\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.000130347.\n",
      "Epoch 167/600\n",
      " 581/2953 [====>.........................] - ETA: 10s - loss: 4.0168e-04 - accuracy: 0.9846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.8519e-04 - accuracy: 0.9834 - val_loss: 3.3825e-04 - val_accuracy: 0.9848 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 191/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.9129e-04 - accuracy: 0.9830 - val_loss: 3.3207e-04 - val_accuracy: 0.9884 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 192/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.7744e-04 - accuracy: 0.9840 - val_loss: 0.0013 - val_accuracy: 0.9635 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 193/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.7955e-04 - accuracy: 0.9841 - val_loss: 4.1263e-04 - val_accuracy: 0.9835 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 194/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.8076e-04 - accuracy: 0.9843 - val_loss: 3.7933e-04 - val_accuracy: 0.9835 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 195/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.7670e-04 - accuracy: 0.9839 - val_loss: 3.0797e-04 - val_accuracy: 0.9877 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 196/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.8594e-04 - accuracy: 0.9835 - val_loss: 3.1232e-04 - val_accuracy: 0.9889 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 197/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.7520e-04 - accuracy: 0.9841 - val_loss: 3.3183e-04 - val_accuracy: 0.9875 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 198/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.7851e-04 - accuracy: 0.9843 - val_loss: 3.3425e-04 - val_accuracy: 0.9886 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 199/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.6942e-04 - accuracy: 0.9840 - val_loss: 3.2886e-04 - val_accuracy: 0.9848 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.000110795.\n",
      "Epoch 200/600\n",
      "2905/2953 [============================>.] - ETA: 0s - loss: 3.7811e-04 - accuracy: 0.9840\n",
      "Epoch 200: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.7777e-04 - accuracy: 0.9841 - val_loss: 3.6827e-04 - val_accuracy: 0.9860 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 9.4176e-05.\n",
      "Epoch 201/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.5548e-04 - accuracy: 0.9847 - val_loss: 3.1799e-04 - val_accuracy: 0.9884 - lr: 9.4176e-05\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 9.4176e-05.\n",
      "Epoch 202/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.5925e-04 - accuracy: 0.9849 - val_loss: 4.3491e-04 - val_accuracy: 0.9796 - lr: 9.4176e-05\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 9.4176e-05.\n",
      "Epoch 203/600\n",
      "1120/2953 [==========>...................] - ETA: 7s - loss: 3.7453e-04 - accuracy: 0.9838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.3790e-04 - accuracy: 0.9855 - val_loss: 3.2280e-04 - val_accuracy: 0.9876 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 227/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.3970e-04 - accuracy: 0.9854 - val_loss: 3.0033e-04 - val_accuracy: 0.9890 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 228/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.3583e-04 - accuracy: 0.9853 - val_loss: 3.7181e-04 - val_accuracy: 0.9868 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 229/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.3333e-04 - accuracy: 0.9855 - val_loss: 3.0538e-04 - val_accuracy: 0.9890 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 230/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.3087e-04 - accuracy: 0.9855 - val_loss: 3.1007e-04 - val_accuracy: 0.9855 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 231/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.3496e-04 - accuracy: 0.9855 - val_loss: 3.5344e-04 - val_accuracy: 0.9838 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 232/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.2897e-04 - accuracy: 0.9856 - val_loss: 3.0846e-04 - val_accuracy: 0.9889 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 233/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.4086e-04 - accuracy: 0.9854 - val_loss: 3.2889e-04 - val_accuracy: 0.9885 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 234/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.3550e-04 - accuracy: 0.9852 - val_loss: 2.9273e-04 - val_accuracy: 0.9890 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 235/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.3223e-04 - accuracy: 0.9856 - val_loss: 3.2876e-04 - val_accuracy: 0.9853 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 236/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.4327e-04 - accuracy: 0.9852 - val_loss: 3.0743e-04 - val_accuracy: 0.9882 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 237/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.4193e-04 - accuracy: 0.9851 - val_loss: 3.7947e-04 - val_accuracy: 0.9833 - lr: 8.0050e-05\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 8.005e-05.\n",
      "Epoch 238/600\n",
      "2790/2953 [===========================>..] - ETA: 0s - loss: 3.3399e-04 - accuracy: 0.9855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.2243e-04 - accuracy: 0.9859 - val_loss: 7.1808e-04 - val_accuracy: 0.9726 - lr: 6.8042e-05\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 6.8042e-05.\n",
      "Epoch 258/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.1644e-04 - accuracy: 0.9864 - val_loss: 2.7701e-04 - val_accuracy: 0.9890 - lr: 6.8042e-05\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 6.8042e-05.\n",
      "Epoch 259/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.1299e-04 - accuracy: 0.9863 - val_loss: 3.1230e-04 - val_accuracy: 0.9868 - lr: 6.8042e-05\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 6.8042e-05.\n",
      "Epoch 260/600\n",
      "2890/2953 [============================>.] - ETA: 0s - loss: 3.1806e-04 - accuracy: 0.9860\n",
      "Epoch 260: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.1792e-04 - accuracy: 0.9860 - val_loss: 5.5209e-04 - val_accuracy: 0.9789 - lr: 6.8042e-05\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 261/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.0193e-04 - accuracy: 0.9868 - val_loss: 2.8141e-04 - val_accuracy: 0.9888 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 262/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.0355e-04 - accuracy: 0.9866 - val_loss: 2.9133e-04 - val_accuracy: 0.9886 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 263/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.0486e-04 - accuracy: 0.9864 - val_loss: 2.9667e-04 - val_accuracy: 0.9894 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 264/600\n",
      "2876/2953 [============================>.] - ETA: 0s - loss: 3.0123e-04 - accuracy: 0.9867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 3.0114e-04 - accuracy: 0.9868 - val_loss: 3.3962e-04 - val_accuracy: 0.9854 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 272/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.0666e-04 - accuracy: 0.9864 - val_loss: 3.3932e-04 - val_accuracy: 0.9845 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 273/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.9921e-04 - accuracy: 0.9869 - val_loss: 2.7647e-04 - val_accuracy: 0.9888 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 274/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.0210e-04 - accuracy: 0.9869 - val_loss: 4.9184e-04 - val_accuracy: 0.9812 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 275/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 3.0372e-04 - accuracy: 0.9867 - val_loss: 2.9530e-04 - val_accuracy: 0.9877 - lr: 5.7836e-05\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 5.7836e-05.\n",
      "Epoch 276/600\n",
      " 490/2953 [===>..........................] - ETA: 10s - loss: 3.0500e-04 - accuracy: 0.9867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8654e-04 - accuracy: 0.9872 - val_loss: 2.8066e-04 - val_accuracy: 0.9893 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 294/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.8691e-04 - accuracy: 0.9872 - val_loss: 2.9332e-04 - val_accuracy: 0.9899 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 295/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8856e-04 - accuracy: 0.9874 - val_loss: 2.8009e-04 - val_accuracy: 0.9877 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 296/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8337e-04 - accuracy: 0.9874 - val_loss: 3.6904e-04 - val_accuracy: 0.9840 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 297/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.8763e-04 - accuracy: 0.9869 - val_loss: 2.7401e-04 - val_accuracy: 0.9894 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 298/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.9123e-04 - accuracy: 0.9871 - val_loss: 3.6143e-04 - val_accuracy: 0.9847 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 299/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.9432e-04 - accuracy: 0.9873 - val_loss: 2.7344e-04 - val_accuracy: 0.9900 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 4.9161e-05.\n",
      "Epoch 300/600\n",
      "2887/2953 [============================>.] - ETA: 0s - loss: 2.8907e-04 - accuracy: 0.9870\n",
      "Epoch 300: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8781e-04 - accuracy: 0.9870 - val_loss: 3.5742e-04 - val_accuracy: 0.9857 - lr: 4.9161e-05\n",
      "\n",
      "Epoch 301: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 301/600\n",
      " 377/2953 [==>...........................] - ETA: 10s - loss: 2.8379e-04 - accuracy: 0.9896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.7841e-04 - accuracy: 0.9875 - val_loss: 2.6542e-04 - val_accuracy: 0.9900 - lr: 4.1787e-05\n",
      "\n",
      "Epoch 308: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 308/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8281e-04 - accuracy: 0.9873 - val_loss: 2.7247e-04 - val_accuracy: 0.9908 - lr: 4.1787e-05\n",
      "\n",
      "Epoch 309: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 309/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.7950e-04 - accuracy: 0.9876 - val_loss: 2.6075e-04 - val_accuracy: 0.9910 - lr: 4.1787e-05\n",
      "\n",
      "Epoch 310: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 310/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.8019e-04 - accuracy: 0.9876 - val_loss: 2.7570e-04 - val_accuracy: 0.9891 - lr: 4.1787e-05\n",
      "\n",
      "Epoch 311: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 311/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.7854e-04 - accuracy: 0.9877 - val_loss: 2.9861e-04 - val_accuracy: 0.9873 - lr: 4.1787e-05\n",
      "\n",
      "Epoch 312: LearningRateScheduler setting learning rate to 4.1787e-05.\n",
      "Epoch 312/600\n",
      " 435/2953 [===>..........................] - ETA: 10s - loss: 2.5065e-04 - accuracy: 0.9892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.6672e-04 - accuracy: 0.9882 - val_loss: 2.6308e-04 - val_accuracy: 0.9903 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 330: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 330/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6914e-04 - accuracy: 0.9883 - val_loss: 2.6310e-04 - val_accuracy: 0.9899 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 331: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 331/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6907e-04 - accuracy: 0.9880 - val_loss: 4.7425e-04 - val_accuracy: 0.9816 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 332: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 332/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6945e-04 - accuracy: 0.9879 - val_loss: 2.5526e-04 - val_accuracy: 0.9907 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 333: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 333/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6674e-04 - accuracy: 0.9881 - val_loss: 2.7160e-04 - val_accuracy: 0.9899 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 334: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 334/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6638e-04 - accuracy: 0.9879 - val_loss: 2.5757e-04 - val_accuracy: 0.9910 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 335: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 335/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.7067e-04 - accuracy: 0.9877 - val_loss: 2.6829e-04 - val_accuracy: 0.9903 - lr: 3.5519e-05\n",
      "\n",
      "Epoch 336: LearningRateScheduler setting learning rate to 3.5519e-05.\n",
      "Epoch 336/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.6679e-04 - accuracy: 0.9882 - val_loss: 2.6907e-04 - val_accuracy: 0.9903 - lr: 3.5519e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.6134e-04 - accuracy: 0.9881 - val_loss: 2.6250e-04 - val_accuracy: 0.9903 - lr: 3.0191e-05\n",
      "\n",
      "Epoch 343: LearningRateScheduler setting learning rate to 3.0191e-05.\n",
      "Epoch 343/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5799e-04 - accuracy: 0.9884 - val_loss: 2.5211e-04 - val_accuracy: 0.9910 - lr: 3.0191e-05\n",
      "\n",
      "Epoch 344: LearningRateScheduler setting learning rate to 3.0191e-05.\n",
      "Epoch 344/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.6129e-04 - accuracy: 0.9883 - val_loss: 2.5498e-04 - val_accuracy: 0.9902 - lr: 3.0191e-05\n",
      "\n",
      "Epoch 345: LearningRateScheduler setting learning rate to 3.0191e-05.\n",
      "Epoch 345/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.5664e-04 - accuracy: 0.9884 - val_loss: 2.8461e-04 - val_accuracy: 0.9896 - lr: 3.0191e-05\n",
      "\n",
      "Epoch 346: LearningRateScheduler setting learning rate to 3.0191e-05.\n",
      "Epoch 346/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.6851e-04 - accuracy: 0.9879 - val_loss: 3.4998e-04 - val_accuracy: 0.9867 - lr: 3.0191e-05\n",
      "\n",
      "Epoch 347: LearningRateScheduler setting learning rate to 3.0191e-05.\n",
      "Epoch 347/600\n",
      " 618/2953 [=====>........................] - ETA: 9s - loss: 2.6050e-04 - accuracy: 0.9881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5251e-04 - accuracy: 0.9885 - val_loss: 2.5555e-04 - val_accuracy: 0.9908 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 366: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 366/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5206e-04 - accuracy: 0.9885 - val_loss: 2.5342e-04 - val_accuracy: 0.9908 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 367: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 367/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5283e-04 - accuracy: 0.9886 - val_loss: 2.6875e-04 - val_accuracy: 0.9894 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 368: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 368/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5535e-04 - accuracy: 0.9884 - val_loss: 2.7770e-04 - val_accuracy: 0.9885 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 369: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 369/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5124e-04 - accuracy: 0.9888 - val_loss: 2.5569e-04 - val_accuracy: 0.9893 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 370: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 370/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4926e-04 - accuracy: 0.9886 - val_loss: 2.5830e-04 - val_accuracy: 0.9901 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 371: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 371/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.5251e-04 - accuracy: 0.9886 - val_loss: 2.5278e-04 - val_accuracy: 0.9900 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 372: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 372/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5195e-04 - accuracy: 0.9887 - val_loss: 2.7041e-04 - val_accuracy: 0.9891 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 373: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 373/600\n",
      "1183/2953 [===========>..................] - ETA: 7s - loss: 2.5029e-04 - accuracy: 0.9892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5002e-04 - accuracy: 0.9887 - val_loss: 2.5020e-04 - val_accuracy: 0.9909 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 379: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 379/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5178e-04 - accuracy: 0.9885 - val_loss: 2.4813e-04 - val_accuracy: 0.9906 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 380: LearningRateScheduler setting learning rate to 2.5662e-05.\n",
      "Epoch 380/600\n",
      "2874/2953 [============================>.] - ETA: 0s - loss: 2.4994e-04 - accuracy: 0.9889\n",
      "Epoch 380: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.5149e-04 - accuracy: 0.9889 - val_loss: 4.6132e-04 - val_accuracy: 0.9806 - lr: 2.5662e-05\n",
      "\n",
      "Epoch 381: LearningRateScheduler setting learning rate to 2.1813e-05.\n",
      "Epoch 381/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4649e-04 - accuracy: 0.9889 - val_loss: 2.5182e-04 - val_accuracy: 0.9911 - lr: 2.1813e-05\n",
      "\n",
      "Epoch 382: LearningRateScheduler setting learning rate to 2.1813e-05.\n",
      "Epoch 382/600\n",
      "2927/2953 [============================>.] - ETA: 0s - loss: 2.4538e-04 - accuracy: 0.9890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4879e-04 - accuracy: 0.9885 - val_loss: 2.5352e-04 - val_accuracy: 0.9907 - lr: 2.1813e-05\n",
      "\n",
      "Epoch 398: LearningRateScheduler setting learning rate to 2.1813e-05.\n",
      "Epoch 398/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4435e-04 - accuracy: 0.9889 - val_loss: 3.0092e-04 - val_accuracy: 0.9875 - lr: 2.1813e-05\n",
      "\n",
      "Epoch 399: LearningRateScheduler setting learning rate to 2.1813e-05.\n",
      "Epoch 399/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4566e-04 - accuracy: 0.9889 - val_loss: 2.5496e-04 - val_accuracy: 0.9898 - lr: 2.1813e-05\n",
      "\n",
      "Epoch 400: LearningRateScheduler setting learning rate to 2.1813e-05.\n",
      "Epoch 400/600\n",
      "2861/2953 [============================>.] - ETA: 0s - loss: 2.4270e-04 - accuracy: 0.9889\n",
      "Epoch 400: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4221e-04 - accuracy: 0.9889 - val_loss: 2.4961e-04 - val_accuracy: 0.9901 - lr: 2.1813e-05\n",
      "\n",
      "Epoch 401: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 401/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4080e-04 - accuracy: 0.9893 - val_loss: 2.6026e-04 - val_accuracy: 0.9899 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 402: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 402/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3921e-04 - accuracy: 0.9891 - val_loss: 2.5360e-04 - val_accuracy: 0.9909 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 403: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 403/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4209e-04 - accuracy: 0.9891 - val_loss: 2.4574e-04 - val_accuracy: 0.9901 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 404: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 404/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4086e-04 - accuracy: 0.9887 - val_loss: 2.4387e-04 - val_accuracy: 0.9910 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 405: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 405/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3968e-04 - accuracy: 0.9890 - val_loss: 2.5724e-04 - val_accuracy: 0.9902 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 406: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 406/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4124e-04 - accuracy: 0.9891 - val_loss: 2.5297e-04 - val_accuracy: 0.9912 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 407: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 407/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4001e-04 - accuracy: 0.9892 - val_loss: 2.5032e-04 - val_accuracy: 0.9911 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 408: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 408/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4111e-04 - accuracy: 0.9892 - val_loss: 2.4622e-04 - val_accuracy: 0.9905 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 409: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 409/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4231e-04 - accuracy: 0.9890 - val_loss: 2.8296e-04 - val_accuracy: 0.9877 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 410: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 410/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4569e-04 - accuracy: 0.9886 - val_loss: 3.2057e-04 - val_accuracy: 0.9872 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 411: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 411/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4100e-04 - accuracy: 0.9892 - val_loss: 2.4654e-04 - val_accuracy: 0.9915 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 412: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 412/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4055e-04 - accuracy: 0.9891 - val_loss: 2.6929e-04 - val_accuracy: 0.9891 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 413: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 413/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3885e-04 - accuracy: 0.9892 - val_loss: 2.4794e-04 - val_accuracy: 0.9904 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 414: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 414/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4142e-04 - accuracy: 0.9891 - val_loss: 2.6433e-04 - val_accuracy: 0.9890 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 415: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 415/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3828e-04 - accuracy: 0.9893 - val_loss: 2.4860e-04 - val_accuracy: 0.9909 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 416: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 416/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4278e-04 - accuracy: 0.9889 - val_loss: 2.9967e-04 - val_accuracy: 0.9882 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 417: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 417/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3938e-04 - accuracy: 0.9891 - val_loss: 2.4753e-04 - val_accuracy: 0.9909 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 418: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 418/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4011e-04 - accuracy: 0.9891 - val_loss: 2.4958e-04 - val_accuracy: 0.9904 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 419: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 419/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.4062e-04 - accuracy: 0.9891 - val_loss: 2.5141e-04 - val_accuracy: 0.9904 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 420: LearningRateScheduler setting learning rate to 1.8541e-05.\n",
      "Epoch 420/600\n",
      "2864/2953 [============================>.] - ETA: 0s - loss: 2.4107e-04 - accuracy: 0.9890\n",
      "Epoch 420: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.4088e-04 - accuracy: 0.9891 - val_loss: 2.4419e-04 - val_accuracy: 0.9916 - lr: 1.8541e-05\n",
      "\n",
      "Epoch 421: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 421/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3550e-04 - accuracy: 0.9893 - val_loss: 2.4648e-04 - val_accuracy: 0.9912 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 422: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 422/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3731e-04 - accuracy: 0.9893 - val_loss: 2.4852e-04 - val_accuracy: 0.9913 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 423: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 423/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3583e-04 - accuracy: 0.9892 - val_loss: 2.4800e-04 - val_accuracy: 0.9909 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 424: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 424/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3364e-04 - accuracy: 0.9892 - val_loss: 2.5811e-04 - val_accuracy: 0.9901 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 425: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 425/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3633e-04 - accuracy: 0.9892 - val_loss: 3.0675e-04 - val_accuracy: 0.9872 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 426: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 426/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3511e-04 - accuracy: 0.9894 - val_loss: 2.4352e-04 - val_accuracy: 0.9915 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 427: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 427/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3445e-04 - accuracy: 0.9894 - val_loss: 2.4544e-04 - val_accuracy: 0.9913 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 428: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 428/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3541e-04 - accuracy: 0.9891 - val_loss: 2.4341e-04 - val_accuracy: 0.9905 - lr: 1.5760e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 429: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 429/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3348e-04 - accuracy: 0.9894 - val_loss: 2.5768e-04 - val_accuracy: 0.9897 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 430: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 430/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3832e-04 - accuracy: 0.9893 - val_loss: 2.4674e-04 - val_accuracy: 0.9906 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 431: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 431/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3497e-04 - accuracy: 0.9892 - val_loss: 2.6537e-04 - val_accuracy: 0.9900 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 432: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 432/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3472e-04 - accuracy: 0.9893 - val_loss: 2.5902e-04 - val_accuracy: 0.9906 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 433: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 433/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3583e-04 - accuracy: 0.9894 - val_loss: 2.4428e-04 - val_accuracy: 0.9908 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 434: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 434/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3732e-04 - accuracy: 0.9893 - val_loss: 2.4584e-04 - val_accuracy: 0.9913 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 435: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 435/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3587e-04 - accuracy: 0.9894 - val_loss: 2.5031e-04 - val_accuracy: 0.9905 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 436: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 436/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3451e-04 - accuracy: 0.9896 - val_loss: 3.4166e-04 - val_accuracy: 0.9855 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 437: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 437/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3560e-04 - accuracy: 0.9893 - val_loss: 2.6250e-04 - val_accuracy: 0.9907 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 438: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 438/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3550e-04 - accuracy: 0.9893 - val_loss: 3.9164e-04 - val_accuracy: 0.9838 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 439: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 439/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3513e-04 - accuracy: 0.9894 - val_loss: 2.8562e-04 - val_accuracy: 0.9891 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 440: LearningRateScheduler setting learning rate to 1.576e-05.\n",
      "Epoch 440/600\n",
      "2859/2953 [============================>.] - ETA: 0s - loss: 2.3589e-04 - accuracy: 0.9891\n",
      "Epoch 440: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3605e-04 - accuracy: 0.9892 - val_loss: 2.4550e-04 - val_accuracy: 0.9903 - lr: 1.5760e-05\n",
      "\n",
      "Epoch 441: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 441/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3274e-04 - accuracy: 0.9893 - val_loss: 2.4288e-04 - val_accuracy: 0.9900 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 442: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 442/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3077e-04 - accuracy: 0.9895 - val_loss: 2.4397e-04 - val_accuracy: 0.9916 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 443: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 443/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3074e-04 - accuracy: 0.9895 - val_loss: 2.4311e-04 - val_accuracy: 0.9903 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 444: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 444/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3107e-04 - accuracy: 0.9895 - val_loss: 2.6956e-04 - val_accuracy: 0.9889 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 445: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 445/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3065e-04 - accuracy: 0.9897 - val_loss: 2.4665e-04 - val_accuracy: 0.9908 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 446: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 446/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2978e-04 - accuracy: 0.9895 - val_loss: 2.4577e-04 - val_accuracy: 0.9902 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 447: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 447/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3011e-04 - accuracy: 0.9897 - val_loss: 2.6179e-04 - val_accuracy: 0.9898 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 448: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 448/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2999e-04 - accuracy: 0.9898 - val_loss: 2.5352e-04 - val_accuracy: 0.9910 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 449: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 449/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3100e-04 - accuracy: 0.9895 - val_loss: 2.4973e-04 - val_accuracy: 0.9912 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 450: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 450/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3200e-04 - accuracy: 0.9895 - val_loss: 2.7696e-04 - val_accuracy: 0.9888 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 451: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 451/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3342e-04 - accuracy: 0.9894 - val_loss: 2.4430e-04 - val_accuracy: 0.9908 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 452: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 452/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3070e-04 - accuracy: 0.9894 - val_loss: 2.4579e-04 - val_accuracy: 0.9913 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 453: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 453/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2973e-04 - accuracy: 0.9895 - val_loss: 2.4737e-04 - val_accuracy: 0.9907 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 454: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 454/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2859e-04 - accuracy: 0.9895 - val_loss: 2.7117e-04 - val_accuracy: 0.9885 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 455: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 455/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3180e-04 - accuracy: 0.9895 - val_loss: 2.5287e-04 - val_accuracy: 0.9891 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 456: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 456/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.3076e-04 - accuracy: 0.9893 - val_loss: 2.5069e-04 - val_accuracy: 0.9906 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 457: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 457/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3021e-04 - accuracy: 0.9893 - val_loss: 2.7142e-04 - val_accuracy: 0.9893 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 458: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 458/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3152e-04 - accuracy: 0.9892 - val_loss: 2.4037e-04 - val_accuracy: 0.9906 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 459: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 459/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2932e-04 - accuracy: 0.9895 - val_loss: 2.4296e-04 - val_accuracy: 0.9910 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 460: LearningRateScheduler setting learning rate to 1.3396e-05.\n",
      "Epoch 460/600\n",
      "2853/2953 [===========================>..] - ETA: 0s - loss: 2.3101e-04 - accuracy: 0.9895\n",
      "Epoch 460: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/10 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.3054e-04 - accuracy: 0.9896 - val_loss: 2.6210e-04 - val_accuracy: 0.9891 - lr: 1.3396e-05\n",
      "\n",
      "Epoch 461: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 461/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2797e-04 - accuracy: 0.9895 - val_loss: 2.6567e-04 - val_accuracy: 0.9889 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 462: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 462/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2889e-04 - accuracy: 0.9895 - val_loss: 2.6096e-04 - val_accuracy: 0.9898 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 463: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 463/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2957e-04 - accuracy: 0.9895 - val_loss: 2.4153e-04 - val_accuracy: 0.9913 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 464: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 464/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2933e-04 - accuracy: 0.9895 - val_loss: 2.4099e-04 - val_accuracy: 0.9904 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 465: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 465/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.2846e-04 - accuracy: 0.9897 - val_loss: 2.5391e-04 - val_accuracy: 0.9904 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 466: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 466/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2767e-04 - accuracy: 0.9897 - val_loss: 2.5195e-04 - val_accuracy: 0.9897 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 467: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 467/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.2971e-04 - accuracy: 0.9895 - val_loss: 2.7743e-04 - val_accuracy: 0.9890 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 468: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 468/600\n",
      "2953/2953 [==============================] - 13s 4ms/step - loss: 2.2881e-04 - accuracy: 0.9894 - val_loss: 3.1696e-04 - val_accuracy: 0.9870 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 469: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 469/600\n",
      "2953/2953 [==============================] - 12s 4ms/step - loss: 2.2898e-04 - accuracy: 0.9895 - val_loss: 2.4337e-04 - val_accuracy: 0.9912 - lr: 1.1387e-05\n",
      "\n",
      "Epoch 470: LearningRateScheduler setting learning rate to 1.1387e-05.\n",
      "Epoch 470/600\n",
      "1338/2953 [============>.................] - ETA: 6s - loss: 2.1965e-04 - accuracy: 0.9903"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 600,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler2,cp_callback2],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZTif_ciZcTu"
   },
   "source": [
    "model.save(f\"/content/gdrive/My Drive/Last data /10percent model/best models/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TIhxCgSZcRf"
   },
   "outputs": [],
   "source": [
    "lr =hist.history.get('lr')[-1] # It takes the last used learning rate.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def ModelsWith99PercentAccuracy(epoch,lr):\n",
    "    if(epoch>0):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "      return round(lr,9)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(ModelsWith99PercentAccuracy,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iSnNGEKZcPT"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 20,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfR_MxjOueej"
   },
   "source": [
    "## Antinormalizing all the input and output features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUAtpuawuL-m"
   },
   "outputs": [],
   "source": [
    "def AntiNorm(Norm_value,actual):\n",
    "  return (max(actual)-min(actual))*Norm_value+min(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0ymQqeKuL8Z"
   },
   "outputs": [],
   "source": [
    "h_norm = X_norm[:,0]\n",
    "v_norm = X_norm[:,1]\n",
    "s_norm = X_norm[:,2]\n",
    "omega_norm = X_norm[:,3]\n",
    "gamma_norm = X_norm[:,4]\n",
    "m_norm = X_norm[:,5]\n",
    "theta_norm = X_norm[:,6]\n",
    "Thrust_norm = y_norm[:,0]\n",
    "beta_norm = y_norm[:,1]\n",
    "h = X[:,0]\n",
    "v = X[:,1]\n",
    "s = X[:,2]\n",
    "omega = X[:,3]\n",
    "gamma = X[:,4]\n",
    "m = X[:,5]\n",
    "theta = X[:,6]\n",
    "Thrust = y[:,0]\n",
    "beta = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vxoUvvEuL5q"
   },
   "outputs": [],
   "source": [
    "# predicted outputs\n",
    "y_pred = model.predict(X_norm)\n",
    "Thrust_p = AntiNorm(y_pred[:,0],Thrust)\n",
    "beta_p = AntiNorm(y_pred[:,1],beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tyRZnz3ZcMV"
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_p[0:3030])\n",
    "plt.plot(beta[0:3030])\n",
    "plt.legend([\"Predicted\",\"Actual\"])\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Nozzle Gamble\")\n",
    "\n",
    "plt.plot(Thrust_p[0:3030])\n",
    "plt.plot(Thrust[0:3030])\n",
    "plt.legend([\"Predicted\",\"Actual\"])\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Thrust\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "All states 5percent data with 303p.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
