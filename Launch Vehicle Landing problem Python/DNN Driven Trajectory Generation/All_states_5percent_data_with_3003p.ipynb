{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c4cb26",
   "metadata": {},
   "source": [
    "## Model for 1000 points per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983cc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffa645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a8edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/saichaitanya/Chaitanya/CSV files/1000 points per trajectory/May10rd5percent_RLV_data 1000 points.csv',header = None,names = ['h','v','s','omega','gamma','m','theta','Thrust','beta','time'])\n",
    "input = output =df.values\n",
    "X = input[:,0:7]\n",
    "y = output[:,7:9]\n",
    "# Individual Data\n",
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.minmax_scale(X)\n",
    "y_norm = preprocessing.minmax_scale(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.1, random_state=42)\n",
    "cross_validation_number = int(X.shape[0]*0.1)\n",
    "X_val = X_train[-cross_validation_number:]\n",
    "y_val = y_train[-cross_validation_number:]\n",
    "X_train = X_train[:-cross_validation_number]\n",
    "y_train = y_train[:-cross_validation_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d864167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(n):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n,input_shape=(7,),kernel_initializer='uniform'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu')) # since tanh has more nonlinearity we add it here, it also gives -ve values so , some layers which are not necessary will lead to 0 in next layer\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(2,kernel_initializer='uniform',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5998bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    }
   ],
   "source": [
    "i = 7;\n",
    "model = create_model2(2**i)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def lr_sch3(epoch,lr):\n",
    "    if (epoch >0) &(epoch<125):\n",
    "      if epoch%30==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>125):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_sch3,verbose = 1)\n",
    "bs = 256;\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / bs\n",
    "save_period = 20\n",
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')\n",
    "iter1 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fe3b2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 0.0056 - accuracy: 0.8753 - val_loss: 0.0042 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/500\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 0.0036 - accuracy: 0.8955 - val_loss: 0.0045 - val_accuracy: 0.8749 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0034 - accuracy: 0.8999 - val_loss: 0.0026 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/500\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 0.0030 - accuracy: 0.9056 - val_loss: 0.0044 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/500\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 0.0027 - accuracy: 0.9091 - val_loss: 0.0029 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/500\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 0.0024 - accuracy: 0.9170 - val_loss: 0.0029 - val_accuracy: 0.9068 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0025 - accuracy: 0.9143 - val_loss: 0.0021 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0024 - accuracy: 0.9177 - val_loss: 0.0022 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0021 - accuracy: 0.9273 - val_loss: 0.0024 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0020 - accuracy: 0.9298 - val_loss: 0.0026 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0019 - accuracy: 0.9316 - val_loss: 9.9235e-04 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0017 - accuracy: 0.9379 - val_loss: 0.0026 - val_accuracy: 0.9239 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0016 - accuracy: 0.9395 - val_loss: 0.0018 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0016 - accuracy: 0.9401 - val_loss: 0.0026 - val_accuracy: 0.9191 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0016 - accuracy: 0.9422 - val_loss: 0.0021 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0015 - accuracy: 0.9449 - val_loss: 0.0016 - val_accuracy: 0.9372 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0014 - accuracy: 0.9458 - val_loss: 0.0016 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0014 - accuracy: 0.9466 - val_loss: 0.0034 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 0.0013 - accuracy: 0.9494 - val_loss: 0.0015 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/500\n",
      "7641/7658 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9527\n",
      "Epoch 20: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0012 - accuracy: 0.9527 - val_loss: 6.6580e-04 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/500\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 0.0012 - accuracy: 0.9520 - val_loss: 7.2252e-04 - val_accuracy: 0.9720 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0011 - accuracy: 0.9567 - val_loss: 7.3551e-04 - val_accuracy: 0.9745 - lr: 0.0010\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0011 - accuracy: 0.9571 - val_loss: 6.6694e-04 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0011 - accuracy: 0.9554 - val_loss: 0.0011 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0011 - accuracy: 0.9568 - val_loss: 9.8907e-04 - val_accuracy: 0.9616 - lr: 0.0010\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 26/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 9.0545e-04 - accuracy: 0.9612 - val_loss: 9.4232e-04 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 27/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0011 - accuracy: 0.9571 - val_loss: 6.8998e-04 - val_accuracy: 0.9749 - lr: 0.0010\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 28/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 0.0010 - accuracy: 0.9593 - val_loss: 7.6128e-04 - val_accuracy: 0.9755 - lr: 0.0010\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 29/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 9.7867e-04 - accuracy: 0.9599 - val_loss: 6.6883e-04 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 30/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 9.2256e-04 - accuracy: 0.9616 - val_loss: 6.6886e-04 - val_accuracy: 0.9772 - lr: 0.0010\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 31/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 6.0166e-04 - accuracy: 0.9729 - val_loss: 4.6176e-04 - val_accuracy: 0.9809 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 32/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.8934e-04 - accuracy: 0.9729 - val_loss: 5.8739e-04 - val_accuracy: 0.9771 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 33/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.9320e-04 - accuracy: 0.9728 - val_loss: 4.3362e-04 - val_accuracy: 0.9717 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 34/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 5.4619e-04 - accuracy: 0.9748 - val_loss: 3.8790e-04 - val_accuracy: 0.9777 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 35/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 5.7144e-04 - accuracy: 0.9736 - val_loss: 4.4687e-04 - val_accuracy: 0.9830 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 36/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.9445e-04 - accuracy: 0.9731 - val_loss: 3.3668e-04 - val_accuracy: 0.9848 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 37/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.7097e-04 - accuracy: 0.9739 - val_loss: 0.0010 - val_accuracy: 0.9543 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 38/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.5808e-04 - accuracy: 0.9743 - val_loss: 8.7992e-04 - val_accuracy: 0.9596 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 39/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.5271e-04 - accuracy: 0.9744 - val_loss: 5.9782e-04 - val_accuracy: 0.9657 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 40/500\n",
      "7620/7658 [============================>.] - ETA: 0s - loss: 5.4545e-04 - accuracy: 0.9748\n",
      "Epoch 40: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.4458e-04 - accuracy: 0.9749 - val_loss: 4.1271e-04 - val_accuracy: 0.9738 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 41/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 5.4828e-04 - accuracy: 0.9746 - val_loss: 6.2970e-04 - val_accuracy: 0.9752 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 42/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.4514e-04 - accuracy: 0.9748 - val_loss: 7.7457e-04 - val_accuracy: 0.9672 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 43/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.1218e-04 - accuracy: 0.9758 - val_loss: 4.6638e-04 - val_accuracy: 0.9701 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 44/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.3398e-04 - accuracy: 0.9753 - val_loss: 4.6340e-04 - val_accuracy: 0.9729 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 45/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.2229e-04 - accuracy: 0.9756 - val_loss: 5.9152e-04 - val_accuracy: 0.9670 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 46/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.3580e-04 - accuracy: 0.9752 - val_loss: 8.9941e-04 - val_accuracy: 0.9658 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 47/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.1173e-04 - accuracy: 0.9761 - val_loss: 5.6163e-04 - val_accuracy: 0.9736 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 48/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.0307e-04 - accuracy: 0.9762 - val_loss: 5.0195e-04 - val_accuracy: 0.9781 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 49/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 5.2074e-04 - accuracy: 0.9756 - val_loss: 3.1083e-04 - val_accuracy: 0.9845 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 50/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.1179e-04 - accuracy: 0.9761 - val_loss: 5.5594e-04 - val_accuracy: 0.9715 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 51/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 4.8866e-04 - accuracy: 0.9768 - val_loss: 3.8148e-04 - val_accuracy: 0.9835 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 52/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 5.1158e-04 - accuracy: 0.9760 - val_loss: 5.2544e-04 - val_accuracy: 0.9778 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 53/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 4.8889e-04 - accuracy: 0.9769 - val_loss: 9.7667e-04 - val_accuracy: 0.9575 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 54/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 4.8178e-04 - accuracy: 0.9771 - val_loss: 4.0912e-04 - val_accuracy: 0.9829 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 55/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 4.7755e-04 - accuracy: 0.9773 - val_loss: 2.9603e-04 - val_accuracy: 0.9831 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 56/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 5.0345e-04 - accuracy: 0.9762 - val_loss: 3.1573e-04 - val_accuracy: 0.9830 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 57/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 4.8011e-04 - accuracy: 0.9770 - val_loss: 2.9765e-04 - val_accuracy: 0.9865 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 58/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 4.8231e-04 - accuracy: 0.9772 - val_loss: 3.0621e-04 - val_accuracy: 0.9829 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 59/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 4.7941e-04 - accuracy: 0.9773 - val_loss: 4.5237e-04 - val_accuracy: 0.9749 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 60/500\n",
      "7610/7658 [============================>.] - ETA: 0s - loss: 4.6552e-04 - accuracy: 0.9777\n",
      "Epoch 60: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 4.6602e-04 - accuracy: 0.9777 - val_loss: 4.2926e-04 - val_accuracy: 0.9753 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 61/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4669e-04 - accuracy: 0.9824 - val_loss: 2.3295e-04 - val_accuracy: 0.9886 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 62/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4810e-04 - accuracy: 0.9824 - val_loss: 4.4938e-04 - val_accuracy: 0.9704 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 63/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.3985e-04 - accuracy: 0.9827 - val_loss: 2.5835e-04 - val_accuracy: 0.9864 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 64/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.4563e-04 - accuracy: 0.9825 - val_loss: 2.5509e-04 - val_accuracy: 0.9878 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 65/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4221e-04 - accuracy: 0.9826 - val_loss: 4.9593e-04 - val_accuracy: 0.9760 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 66/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4103e-04 - accuracy: 0.9828 - val_loss: 2.2010e-04 - val_accuracy: 0.9871 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0004066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4528e-04 - accuracy: 0.9823 - val_loss: 2.2532e-04 - val_accuracy: 0.9896 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 68/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4599e-04 - accuracy: 0.9825 - val_loss: 3.5292e-04 - val_accuracy: 0.9743 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 69/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.3066e-04 - accuracy: 0.9833 - val_loss: 2.2971e-04 - val_accuracy: 0.9891 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 70/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.3133e-04 - accuracy: 0.9831 - val_loss: 2.6258e-04 - val_accuracy: 0.9858 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 71/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.4063e-04 - accuracy: 0.9830 - val_loss: 2.4156e-04 - val_accuracy: 0.9840 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 72/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2257e-04 - accuracy: 0.9835 - val_loss: 4.3108e-04 - val_accuracy: 0.9821 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 73/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.3139e-04 - accuracy: 0.9831 - val_loss: 5.0985e-04 - val_accuracy: 0.9745 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 74/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.3841e-04 - accuracy: 0.9829 - val_loss: 3.0421e-04 - val_accuracy: 0.9868 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 75/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.3722e-04 - accuracy: 0.9829 - val_loss: 2.8630e-04 - val_accuracy: 0.9864 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 76/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.1817e-04 - accuracy: 0.9837 - val_loss: 2.8288e-04 - val_accuracy: 0.9852 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 77/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.3297e-04 - accuracy: 0.9833 - val_loss: 2.0368e-04 - val_accuracy: 0.9864 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 78/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2057e-04 - accuracy: 0.9836 - val_loss: 2.7508e-04 - val_accuracy: 0.9828 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 79/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2190e-04 - accuracy: 0.9834 - val_loss: 2.7055e-04 - val_accuracy: 0.9873 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 80/500\n",
      "7595/7658 [============================>.] - ETA: 0s - loss: 3.1748e-04 - accuracy: 0.9837\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.1710e-04 - accuracy: 0.9837 - val_loss: 2.1558e-04 - val_accuracy: 0.9864 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 81/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2228e-04 - accuracy: 0.9836 - val_loss: 2.1067e-04 - val_accuracy: 0.9877 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 82/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.1950e-04 - accuracy: 0.9836 - val_loss: 2.6481e-04 - val_accuracy: 0.9834 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 83/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.1326e-04 - accuracy: 0.9839 - val_loss: 2.1107e-04 - val_accuracy: 0.9863 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 84/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.2145e-04 - accuracy: 0.9837 - val_loss: 4.0189e-04 - val_accuracy: 0.9815 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 85/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2245e-04 - accuracy: 0.9835 - val_loss: 3.6770e-04 - val_accuracy: 0.9772 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 86/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.1490e-04 - accuracy: 0.9837 - val_loss: 2.1433e-04 - val_accuracy: 0.9879 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 87/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.2326e-04 - accuracy: 0.9836 - val_loss: 4.4745e-04 - val_accuracy: 0.9725 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 88/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.1686e-04 - accuracy: 0.9838 - val_loss: 2.5270e-04 - val_accuracy: 0.9872 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 89/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 3.0798e-04 - accuracy: 0.9842 - val_loss: 3.2918e-04 - val_accuracy: 0.9846 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 90/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 3.2030e-04 - accuracy: 0.9836 - val_loss: 2.2827e-04 - val_accuracy: 0.9877 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 91/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.4620e-04 - accuracy: 0.9868 - val_loss: 2.7932e-04 - val_accuracy: 0.9868 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 92/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.4667e-04 - accuracy: 0.9868 - val_loss: 2.0674e-04 - val_accuracy: 0.9894 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 93/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.4024e-04 - accuracy: 0.9871 - val_loss: 2.0580e-04 - val_accuracy: 0.9889 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 94/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.4198e-04 - accuracy: 0.9869 - val_loss: 2.4880e-04 - val_accuracy: 0.9865 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 95/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3745e-04 - accuracy: 0.9872 - val_loss: 2.7541e-04 - val_accuracy: 0.9858 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 96/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3865e-04 - accuracy: 0.9871 - val_loss: 1.7376e-04 - val_accuracy: 0.9910 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 97/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3700e-04 - accuracy: 0.9873 - val_loss: 1.8949e-04 - val_accuracy: 0.9893 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 98/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3809e-04 - accuracy: 0.9871 - val_loss: 1.9394e-04 - val_accuracy: 0.9861 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 99/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.4118e-04 - accuracy: 0.9871 - val_loss: 2.0809e-04 - val_accuracy: 0.9903 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0002593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "7576/7658 [============================>.] - ETA: 0s - loss: 2.3606e-04 - accuracy: 0.9872\n",
      "Epoch 100: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3578e-04 - accuracy: 0.9872 - val_loss: 2.1428e-04 - val_accuracy: 0.9901 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 101/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3266e-04 - accuracy: 0.9874 - val_loss: 3.0252e-04 - val_accuracy: 0.9806 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 102/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3783e-04 - accuracy: 0.9871 - val_loss: 1.6372e-04 - val_accuracy: 0.9911 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 103/500\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 2.2889e-04 - accuracy: 0.9876 - val_loss: 2.3550e-04 - val_accuracy: 0.9882 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 104/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3938e-04 - accuracy: 0.9870 - val_loss: 1.9345e-04 - val_accuracy: 0.9908 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 105/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3632e-04 - accuracy: 0.9872 - val_loss: 1.7179e-04 - val_accuracy: 0.9909 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 106/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3183e-04 - accuracy: 0.9875 - val_loss: 2.1246e-04 - val_accuracy: 0.9851 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 107/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3059e-04 - accuracy: 0.9874 - val_loss: 1.6905e-04 - val_accuracy: 0.9880 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 108/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3545e-04 - accuracy: 0.9872 - val_loss: 1.6176e-04 - val_accuracy: 0.9919 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 109/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.2946e-04 - accuracy: 0.9876 - val_loss: 2.0713e-04 - val_accuracy: 0.9894 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 110/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3296e-04 - accuracy: 0.9875 - val_loss: 1.9234e-04 - val_accuracy: 0.9872 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 111/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.3413e-04 - accuracy: 0.9871 - val_loss: 1.7162e-04 - val_accuracy: 0.9911 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 112/500\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 2.3371e-04 - accuracy: 0.9874 - val_loss: 2.1597e-04 - val_accuracy: 0.9894 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 113/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.2926e-04 - accuracy: 0.9875 - val_loss: 2.0414e-04 - val_accuracy: 0.9867 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 114/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.2955e-04 - accuracy: 0.9876 - val_loss: 2.1393e-04 - val_accuracy: 0.9850 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 115/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.2961e-04 - accuracy: 0.9875 - val_loss: 2.9176e-04 - val_accuracy: 0.9868 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 116/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.2426e-04 - accuracy: 0.9877 - val_loss: 1.8061e-04 - val_accuracy: 0.9870 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 117/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3118e-04 - accuracy: 0.9873 - val_loss: 2.2193e-04 - val_accuracy: 0.9885 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 118/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.3527e-04 - accuracy: 0.9873 - val_loss: 2.2814e-04 - val_accuracy: 0.9897 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 119/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 2.1982e-04 - accuracy: 0.9879 - val_loss: 1.4196e-04 - val_accuracy: 0.9909 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 120/500\n",
      "7560/7658 [============================>.] - ETA: 0s - loss: 2.2235e-04 - accuracy: 0.9879\n",
      "Epoch 120: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 2.2221e-04 - accuracy: 0.9879 - val_loss: 1.6911e-04 - val_accuracy: 0.9884 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 121/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.8362e-04 - accuracy: 0.9896 - val_loss: 1.3354e-04 - val_accuracy: 0.9919 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 122/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.8426e-04 - accuracy: 0.9896 - val_loss: 1.6533e-04 - val_accuracy: 0.9916 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 123/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.8459e-04 - accuracy: 0.9895 - val_loss: 1.3809e-04 - val_accuracy: 0.9922 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 124/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.8250e-04 - accuracy: 0.9898 - val_loss: 1.8607e-04 - val_accuracy: 0.9913 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 125/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.8084e-04 - accuracy: 0.9898 - val_loss: 2.5053e-04 - val_accuracy: 0.9820 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 126/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.8176e-04 - accuracy: 0.9897 - val_loss: 1.5436e-04 - val_accuracy: 0.9923 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 127/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.8361e-04 - accuracy: 0.9896 - val_loss: 2.3816e-04 - val_accuracy: 0.9879 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 128/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.7896e-04 - accuracy: 0.9897 - val_loss: 2.8886e-04 - val_accuracy: 0.9858 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 129/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.8019e-04 - accuracy: 0.9897 - val_loss: 1.4519e-04 - val_accuracy: 0.9917 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 130/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.8022e-04 - accuracy: 0.9897 - val_loss: 1.3365e-04 - val_accuracy: 0.9932 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 131/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.7656e-04 - accuracy: 0.9900 - val_loss: 1.7047e-04 - val_accuracy: 0.9910 - lr: 1.6530e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 132/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.7822e-04 - accuracy: 0.9899 - val_loss: 1.8422e-04 - val_accuracy: 0.9847 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 133/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.7989e-04 - accuracy: 0.9897 - val_loss: 1.7612e-04 - val_accuracy: 0.9917 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 134/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.7621e-04 - accuracy: 0.9899 - val_loss: 1.5473e-04 - val_accuracy: 0.9882 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 135/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.7669e-04 - accuracy: 0.9899 - val_loss: 1.5709e-04 - val_accuracy: 0.9892 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 136/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.7663e-04 - accuracy: 0.9898 - val_loss: 1.3913e-04 - val_accuracy: 0.9924 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 137/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.8180e-04 - accuracy: 0.9896 - val_loss: 1.6494e-04 - val_accuracy: 0.9901 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 138/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.7345e-04 - accuracy: 0.9901 - val_loss: 1.2653e-04 - val_accuracy: 0.9927 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 139/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.7721e-04 - accuracy: 0.9899 - val_loss: 1.5849e-04 - val_accuracy: 0.9919 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.0001653.\n",
      "Epoch 140/500\n",
      "7548/7658 [============================>.] - ETA: 0s - loss: 1.7830e-04 - accuracy: 0.9898\n",
      "Epoch 140: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.7806e-04 - accuracy: 0.9898 - val_loss: 1.2595e-04 - val_accuracy: 0.9925 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 141/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6535e-04 - accuracy: 0.9904 - val_loss: 1.2196e-04 - val_accuracy: 0.9936 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 142/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6429e-04 - accuracy: 0.9906 - val_loss: 1.3857e-04 - val_accuracy: 0.9921 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 143/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6512e-04 - accuracy: 0.9904 - val_loss: 1.4005e-04 - val_accuracy: 0.9925 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 144/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6229e-04 - accuracy: 0.9906 - val_loss: 1.5718e-04 - val_accuracy: 0.9904 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 145/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6593e-04 - accuracy: 0.9904 - val_loss: 2.0383e-04 - val_accuracy: 0.9859 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 146/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6272e-04 - accuracy: 0.9907 - val_loss: 1.2103e-04 - val_accuracy: 0.9930 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 147/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6411e-04 - accuracy: 0.9905 - val_loss: 1.3150e-04 - val_accuracy: 0.9936 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 148/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6411e-04 - accuracy: 0.9906 - val_loss: 1.4996e-04 - val_accuracy: 0.9927 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 149/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6613e-04 - accuracy: 0.9904 - val_loss: 3.4894e-04 - val_accuracy: 0.9777 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 150/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6366e-04 - accuracy: 0.9904 - val_loss: 1.4406e-04 - val_accuracy: 0.9925 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 151/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6148e-04 - accuracy: 0.9905 - val_loss: 1.2740e-04 - val_accuracy: 0.9922 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 152/500\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 1.6070e-04 - accuracy: 0.9907 - val_loss: 1.1893e-04 - val_accuracy: 0.9924 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 153/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6395e-04 - accuracy: 0.9905 - val_loss: 1.4608e-04 - val_accuracy: 0.9922 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 154/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6336e-04 - accuracy: 0.9906 - val_loss: 2.1645e-04 - val_accuracy: 0.9885 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 155/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6401e-04 - accuracy: 0.9906 - val_loss: 1.6790e-04 - val_accuracy: 0.9897 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 156/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6079e-04 - accuracy: 0.9907 - val_loss: 1.5496e-04 - val_accuracy: 0.9913 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 157/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.5966e-04 - accuracy: 0.9906 - val_loss: 1.2655e-04 - val_accuracy: 0.9927 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 158/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.6279e-04 - accuracy: 0.9905 - val_loss: 1.3989e-04 - val_accuracy: 0.9903 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 159/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.5926e-04 - accuracy: 0.9907 - val_loss: 2.0510e-04 - val_accuracy: 0.9893 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.000140505.\n",
      "Epoch 160/500\n",
      "7531/7658 [============================>.] - ETA: 0s - loss: 1.5995e-04 - accuracy: 0.9907\n",
      "Epoch 160: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.6001e-04 - accuracy: 0.9907 - val_loss: 1.6292e-04 - val_accuracy: 0.9871 - lr: 1.4050e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 161/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.5273e-04 - accuracy: 0.9910 - val_loss: 1.3685e-04 - val_accuracy: 0.9886 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 162/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.5295e-04 - accuracy: 0.9910 - val_loss: 2.7370e-04 - val_accuracy: 0.9840 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.000119429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4887e-04 - accuracy: 0.9913 - val_loss: 1.1499e-04 - val_accuracy: 0.9929 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 164/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.5110e-04 - accuracy: 0.9911 - val_loss: 1.3276e-04 - val_accuracy: 0.9912 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 165/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4960e-04 - accuracy: 0.9912 - val_loss: 1.4119e-04 - val_accuracy: 0.9925 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 166/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4975e-04 - accuracy: 0.9911 - val_loss: 1.1238e-04 - val_accuracy: 0.9933 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 167/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4851e-04 - accuracy: 0.9913 - val_loss: 1.2176e-04 - val_accuracy: 0.9927 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 168/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4933e-04 - accuracy: 0.9911 - val_loss: 1.6702e-04 - val_accuracy: 0.9909 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 169/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4950e-04 - accuracy: 0.9912 - val_loss: 1.6349e-04 - val_accuracy: 0.9906 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 170/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.5081e-04 - accuracy: 0.9912 - val_loss: 1.5139e-04 - val_accuracy: 0.9913 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 171/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4999e-04 - accuracy: 0.9911 - val_loss: 1.8906e-04 - val_accuracy: 0.9838 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 172/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4969e-04 - accuracy: 0.9911 - val_loss: 1.6888e-04 - val_accuracy: 0.9879 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 173/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4861e-04 - accuracy: 0.9912 - val_loss: 1.1588e-04 - val_accuracy: 0.9927 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 174/500\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.5228e-04 - accuracy: 0.9911 - val_loss: 1.5269e-04 - val_accuracy: 0.9918 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 175/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4913e-04 - accuracy: 0.9911 - val_loss: 1.2265e-04 - val_accuracy: 0.9921 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 176/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4828e-04 - accuracy: 0.9913 - val_loss: 2.5368e-04 - val_accuracy: 0.9830 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 177/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4878e-04 - accuracy: 0.9913 - val_loss: 1.3158e-04 - val_accuracy: 0.9918 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 178/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4947e-04 - accuracy: 0.9912 - val_loss: 1.1598e-04 - val_accuracy: 0.9931 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 179/500\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4974e-04 - accuracy: 0.9912 - val_loss: 1.5648e-04 - val_accuracy: 0.9902 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 180/500\n",
      "7515/7658 [============================>.] - ETA: 0s - loss: 1.4933e-04 - accuracy: 0.9911\n",
      "Epoch 180: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.4986e-04 - accuracy: 0.9911 - val_loss: 1.2357e-04 - val_accuracy: 0.9916 - lr: 1.1943e-04\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 181/500\n",
      "2850/7658 [==========>...................] - ETA: 30s - loss: 1.4721e-04 - accuracy: 0.9914"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = iter1,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42df9391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    }
   ],
   "source": [
    "i = 7;\n",
    "model = create_model2(2**i)\n",
    "lr = 0.000101515;\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "stopped_itera = 181; # adding stopped iteration to the function call.\n",
    "remaining_iterations = iter1 - stopped_itera\n",
    "def lr_sch(epoch,lr):\n",
    "    epoch = epoch+181\n",
    "    print(epoch)\n",
    "    if (epoch >0) &(epoch<25):\n",
    "      if epoch%5==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>25):\n",
    "        if epoch%5==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler2 = tf.keras.callbacks.LearningRateScheduler(lr_sch,verbose = 1)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbf839ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 1/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4602e-04 - accuracy: 0.9913 - val_loss: 1.1358e-04 - val_accuracy: 0.9930 - lr: 1.1943e-04\n",
      "182\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 2/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4952e-04 - accuracy: 0.9912 - val_loss: 1.3259e-04 - val_accuracy: 0.9897 - lr: 1.1943e-04\n",
      "183\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 3/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 1.4832e-04 - accuracy: 0.9912 - val_loss: 1.6065e-04 - val_accuracy: 0.9911 - lr: 1.1943e-04\n",
      "184\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000119429.\n",
      "Epoch 4/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.4847e-04 - accuracy: 0.9912 - val_loss: 1.3651e-04 - val_accuracy: 0.9924 - lr: 1.1943e-04\n",
      "185\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 5/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3964e-04 - accuracy: 0.9916 - val_loss: 1.0898e-04 - val_accuracy: 0.9928 - lr: 1.0151e-04\n",
      "186\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 6/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.3951e-04 - accuracy: 0.9916 - val_loss: 1.1894e-04 - val_accuracy: 0.9933 - lr: 1.0151e-04\n",
      "187\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 7/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3954e-04 - accuracy: 0.9916 - val_loss: 1.2356e-04 - val_accuracy: 0.9927 - lr: 1.0151e-04\n",
      "188\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 8/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 1.3777e-04 - accuracy: 0.9918 - val_loss: 1.0066e-04 - val_accuracy: 0.9930 - lr: 1.0151e-04\n",
      "189\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.000101515.\n",
      "Epoch 9/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3726e-04 - accuracy: 0.9917 - val_loss: 1.3159e-04 - val_accuracy: 0.9914 - lr: 1.0151e-04\n",
      "190\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 8.6288e-05.\n",
      "Epoch 10/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3201e-04 - accuracy: 0.9921 - val_loss: 1.2559e-04 - val_accuracy: 0.9908 - lr: 8.6288e-05\n",
      "191\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 8.6288e-05.\n",
      "Epoch 11/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3021e-04 - accuracy: 0.9922 - val_loss: 1.2593e-04 - val_accuracy: 0.9925 - lr: 8.6288e-05\n",
      "192\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 8.6288e-05.\n",
      "Epoch 12/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.2865e-04 - accuracy: 0.9922 - val_loss: 1.2013e-04 - val_accuracy: 0.9917 - lr: 8.6288e-05\n",
      "193\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 8.6288e-05.\n",
      "Epoch 13/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.3331e-04 - accuracy: 0.9919 - val_loss: 1.2429e-04 - val_accuracy: 0.9906 - lr: 8.6288e-05\n",
      "194\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 8.6288e-05.\n",
      "Epoch 14/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.2806e-04 - accuracy: 0.9922 - val_loss: 1.0595e-04 - val_accuracy: 0.9930 - lr: 8.6288e-05\n",
      "195\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 7.3345e-05.\n",
      "Epoch 15/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.2188e-04 - accuracy: 0.9926 - val_loss: 1.1762e-04 - val_accuracy: 0.9930 - lr: 7.3345e-05\n",
      "196\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 7.3345e-05.\n",
      "Epoch 16/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.2353e-04 - accuracy: 0.9924 - val_loss: 1.0491e-04 - val_accuracy: 0.9935 - lr: 7.3345e-05\n",
      "197\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 7.3345e-05.\n",
      "Epoch 17/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.2239e-04 - accuracy: 0.9926 - val_loss: 1.2150e-04 - val_accuracy: 0.9924 - lr: 7.3345e-05\n",
      "198\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 7.3345e-05.\n",
      "Epoch 18/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.2038e-04 - accuracy: 0.9926 - val_loss: 1.2222e-04 - val_accuracy: 0.9930 - lr: 7.3345e-05\n",
      "199\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 7.3345e-05.\n",
      "Epoch 19/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.2127e-04 - accuracy: 0.9925 - val_loss: 1.2102e-04 - val_accuracy: 0.9908 - lr: 7.3345e-05\n",
      "200\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 6.2343e-05.\n",
      "Epoch 20/319\n",
      "7634/7658 [============================>.] - ETA: 0s - loss: 1.1539e-04 - accuracy: 0.9929\n",
      "Epoch 20: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1538e-04 - accuracy: 0.9929 - val_loss: 1.2826e-04 - val_accuracy: 0.9922 - lr: 6.2343e-05\n",
      "201\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 6.2343e-05.\n",
      "Epoch 21/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1570e-04 - accuracy: 0.9928 - val_loss: 1.0564e-04 - val_accuracy: 0.9932 - lr: 6.2343e-05\n",
      "202\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 6.2343e-05.\n",
      "Epoch 22/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1467e-04 - accuracy: 0.9928 - val_loss: 1.0764e-04 - val_accuracy: 0.9930 - lr: 6.2343e-05\n",
      "203\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 6.2343e-05.\n",
      "Epoch 23/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1692e-04 - accuracy: 0.9927 - val_loss: 1.1171e-04 - val_accuracy: 0.9922 - lr: 6.2343e-05\n",
      "204\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 6.2343e-05.\n",
      "Epoch 24/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 1.1572e-04 - accuracy: 0.9928 - val_loss: 1.6902e-04 - val_accuracy: 0.9895 - lr: 6.2343e-05\n",
      "205\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 5.2992e-05.\n",
      "Epoch 25/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1033e-04 - accuracy: 0.9931 - val_loss: 1.1140e-04 - val_accuracy: 0.9932 - lr: 5.2992e-05\n",
      "206\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5.2992e-05.\n",
      "Epoch 26/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1018e-04 - accuracy: 0.9931 - val_loss: 1.1946e-04 - val_accuracy: 0.9901 - lr: 5.2992e-05\n",
      "207\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5.2992e-05.\n",
      "Epoch 27/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0991e-04 - accuracy: 0.9930 - val_loss: 9.3402e-05 - val_accuracy: 0.9936 - lr: 5.2992e-05\n",
      "208\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 5.2992e-05.\n",
      "Epoch 28/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 1.0906e-04 - accuracy: 0.9931 - val_loss: 9.9180e-05 - val_accuracy: 0.9929 - lr: 5.2992e-05\n",
      "209\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 5.2992e-05.\n",
      "Epoch 29/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.1143e-04 - accuracy: 0.9930 - val_loss: 1.0368e-04 - val_accuracy: 0.9928 - lr: 5.2992e-05\n",
      "210\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.5043e-05.\n",
      "Epoch 30/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 1.0643e-04 - accuracy: 0.9932 - val_loss: 9.8892e-05 - val_accuracy: 0.9931 - lr: 4.5043e-05\n",
      "211\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 4.5043e-05.\n",
      "Epoch 31/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0539e-04 - accuracy: 0.9934 - val_loss: 9.1909e-05 - val_accuracy: 0.9929 - lr: 4.5043e-05\n",
      "212\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 4.5043e-05.\n",
      "Epoch 32/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0581e-04 - accuracy: 0.9932 - val_loss: 9.6590e-05 - val_accuracy: 0.9936 - lr: 4.5043e-05\n",
      "213\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 4.5043e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0474e-04 - accuracy: 0.9934 - val_loss: 1.0549e-04 - val_accuracy: 0.9930 - lr: 4.5043e-05\n",
      "214\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 4.5043e-05.\n",
      "Epoch 34/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0419e-04 - accuracy: 0.9933 - val_loss: 9.2472e-05 - val_accuracy: 0.9938 - lr: 4.5043e-05\n",
      "215\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 3.8287e-05.\n",
      "Epoch 35/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0132e-04 - accuracy: 0.9935 - val_loss: 9.2002e-05 - val_accuracy: 0.9934 - lr: 3.8287e-05\n",
      "216\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 3.8287e-05.\n",
      "Epoch 36/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0047e-04 - accuracy: 0.9936 - val_loss: 9.2339e-05 - val_accuracy: 0.9925 - lr: 3.8287e-05\n",
      "217\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 3.8287e-05.\n",
      "Epoch 37/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0234e-04 - accuracy: 0.9935 - val_loss: 1.8461e-04 - val_accuracy: 0.9860 - lr: 3.8287e-05\n",
      "218\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 3.8287e-05.\n",
      "Epoch 38/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0115e-04 - accuracy: 0.9935 - val_loss: 9.0894e-05 - val_accuracy: 0.9933 - lr: 3.8287e-05\n",
      "219\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 3.8287e-05.\n",
      "Epoch 39/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 1.0110e-04 - accuracy: 0.9935 - val_loss: 9.3348e-05 - val_accuracy: 0.9926 - lr: 3.8287e-05\n",
      "220\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 3.2544e-05.\n",
      "Epoch 40/319\n",
      "7625/7658 [============================>.] - ETA: 0s - loss: 9.7824e-05 - accuracy: 0.9937\n",
      "Epoch 40: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.7734e-05 - accuracy: 0.9937 - val_loss: 9.1828e-05 - val_accuracy: 0.9924 - lr: 3.2544e-05\n",
      "221\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 3.2544e-05.\n",
      "Epoch 41/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.7563e-05 - accuracy: 0.9937 - val_loss: 8.9984e-05 - val_accuracy: 0.9940 - lr: 3.2544e-05\n",
      "222\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 3.2544e-05.\n",
      "Epoch 42/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.6281e-05 - accuracy: 0.9937 - val_loss: 9.2037e-05 - val_accuracy: 0.9918 - lr: 3.2544e-05\n",
      "223\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 3.2544e-05.\n",
      "Epoch 43/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.6584e-05 - accuracy: 0.9937 - val_loss: 8.8875e-05 - val_accuracy: 0.9935 - lr: 3.2544e-05\n",
      "224\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 3.2544e-05.\n",
      "Epoch 44/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 9.6896e-05 - accuracy: 0.9937 - val_loss: 8.5753e-05 - val_accuracy: 0.9932 - lr: 3.2544e-05\n",
      "225\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 2.7662e-05.\n",
      "Epoch 45/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.5300e-05 - accuracy: 0.9938 - val_loss: 9.6487e-05 - val_accuracy: 0.9929 - lr: 2.7662e-05\n",
      "226\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 2.7662e-05.\n",
      "Epoch 46/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 9.3208e-05 - accuracy: 0.9939 - val_loss: 1.2113e-04 - val_accuracy: 0.9898 - lr: 2.7662e-05\n",
      "227\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 2.7662e-05.\n",
      "Epoch 47/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.3797e-05 - accuracy: 0.9939 - val_loss: 9.4243e-05 - val_accuracy: 0.9939 - lr: 2.7662e-05\n",
      "228\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 2.7662e-05.\n",
      "Epoch 48/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.3432e-05 - accuracy: 0.9938 - val_loss: 1.2187e-04 - val_accuracy: 0.9915 - lr: 2.7662e-05\n",
      "229\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 2.7662e-05.\n",
      "Epoch 49/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.4724e-05 - accuracy: 0.9938 - val_loss: 9.5921e-05 - val_accuracy: 0.9933 - lr: 2.7662e-05\n",
      "230\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 2.3513e-05.\n",
      "Epoch 50/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.0543e-05 - accuracy: 0.9941 - val_loss: 1.1110e-04 - val_accuracy: 0.9897 - lr: 2.3513e-05\n",
      "231\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 2.3513e-05.\n",
      "Epoch 51/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.1306e-05 - accuracy: 0.9940 - val_loss: 8.8097e-05 - val_accuracy: 0.9941 - lr: 2.3513e-05\n",
      "232\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 2.3513e-05.\n",
      "Epoch 52/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.1042e-05 - accuracy: 0.9940 - val_loss: 8.1916e-05 - val_accuracy: 0.9936 - lr: 2.3513e-05\n",
      "233\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 2.3513e-05.\n",
      "Epoch 53/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 9.0510e-05 - accuracy: 0.9940 - val_loss: 8.3695e-05 - val_accuracy: 0.9935 - lr: 2.3513e-05\n",
      "234\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 2.3513e-05.\n",
      "Epoch 54/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.9847e-05 - accuracy: 0.9941 - val_loss: 8.9575e-05 - val_accuracy: 0.9929 - lr: 2.3513e-05\n",
      "235\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.9986e-05.\n",
      "Epoch 55/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.8143e-05 - accuracy: 0.9942 - val_loss: 1.4850e-04 - val_accuracy: 0.9876 - lr: 1.9986e-05\n",
      "236\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.9986e-05.\n",
      "Epoch 56/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.8898e-05 - accuracy: 0.9941 - val_loss: 8.3559e-05 - val_accuracy: 0.9933 - lr: 1.9986e-05\n",
      "237\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.9986e-05.\n",
      "Epoch 57/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.8502e-05 - accuracy: 0.9942 - val_loss: 8.8730e-05 - val_accuracy: 0.9937 - lr: 1.9986e-05\n",
      "238\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.9986e-05.\n",
      "Epoch 58/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.8659e-05 - accuracy: 0.9942 - val_loss: 8.3850e-05 - val_accuracy: 0.9933 - lr: 1.9986e-05\n",
      "239\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.9986e-05.\n",
      "Epoch 59/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.7846e-05 - accuracy: 0.9943 - val_loss: 8.6563e-05 - val_accuracy: 0.9931 - lr: 1.9986e-05\n",
      "240\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.6988e-05.\n",
      "Epoch 60/319\n",
      "7612/7658 [============================>.] - ETA: 0s - loss: 8.6271e-05 - accuracy: 0.9943\n",
      "Epoch 60: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 51s 7ms/step - loss: 8.6346e-05 - accuracy: 0.9943 - val_loss: 8.8845e-05 - val_accuracy: 0.9940 - lr: 1.6988e-05\n",
      "241\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.6988e-05.\n",
      "Epoch 61/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 8.6403e-05 - accuracy: 0.9942 - val_loss: 8.4713e-05 - val_accuracy: 0.9930 - lr: 1.6988e-05\n",
      "242\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.6988e-05.\n",
      "Epoch 62/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.6505e-05 - accuracy: 0.9943 - val_loss: 8.8445e-05 - val_accuracy: 0.9922 - lr: 1.6988e-05\n",
      "243\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.6988e-05.\n",
      "Epoch 63/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.6125e-05 - accuracy: 0.9943 - val_loss: 1.6761e-04 - val_accuracy: 0.9874 - lr: 1.6988e-05\n",
      "244\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.6988e-05.\n",
      "Epoch 64/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.5855e-05 - accuracy: 0.9943 - val_loss: 9.0521e-05 - val_accuracy: 0.9940 - lr: 1.6988e-05\n",
      "245\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.444e-05.\n",
      "Epoch 65/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.5058e-05 - accuracy: 0.9943 - val_loss: 8.6715e-05 - val_accuracy: 0.9940 - lr: 1.4440e-05\n",
      "246\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.444e-05.\n",
      "Epoch 66/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.3674e-05 - accuracy: 0.9944 - val_loss: 8.6636e-05 - val_accuracy: 0.9939 - lr: 1.4440e-05\n",
      "247\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.444e-05.\n",
      "Epoch 67/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.3729e-05 - accuracy: 0.9944 - val_loss: 1.2539e-04 - val_accuracy: 0.9891 - lr: 1.4440e-05\n",
      "248\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.444e-05.\n",
      "Epoch 68/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 8.4086e-05 - accuracy: 0.9944 - val_loss: 8.7377e-05 - val_accuracy: 0.9936 - lr: 1.4440e-05\n",
      "249\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.444e-05.\n",
      "Epoch 69/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 8.3688e-05 - accuracy: 0.9945 - val_loss: 8.0709e-05 - val_accuracy: 0.9929 - lr: 1.4440e-05\n",
      "250\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.2274e-05.\n",
      "Epoch 70/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 8.2744e-05 - accuracy: 0.9945 - val_loss: 7.9048e-05 - val_accuracy: 0.9937 - lr: 1.2274e-05\n",
      "251\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.2274e-05.\n",
      "Epoch 71/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.2950e-05 - accuracy: 0.9945 - val_loss: 8.2527e-05 - val_accuracy: 0.9938 - lr: 1.2274e-05\n",
      "252\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.2274e-05.\n",
      "Epoch 72/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.2088e-05 - accuracy: 0.9945 - val_loss: 8.8801e-05 - val_accuracy: 0.9944 - lr: 1.2274e-05\n",
      "253\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.2274e-05.\n",
      "Epoch 73/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.2743e-05 - accuracy: 0.9945 - val_loss: 8.1018e-05 - val_accuracy: 0.9932 - lr: 1.2274e-05\n",
      "254\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.2274e-05.\n",
      "Epoch 74/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.2847e-05 - accuracy: 0.9945 - val_loss: 8.4728e-05 - val_accuracy: 0.9918 - lr: 1.2274e-05\n",
      "255\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.0433e-05.\n",
      "Epoch 75/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.1200e-05 - accuracy: 0.9946 - val_loss: 7.8012e-05 - val_accuracy: 0.9938 - lr: 1.0433e-05\n",
      "256\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.0433e-05.\n",
      "Epoch 76/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 8.0826e-05 - accuracy: 0.9946 - val_loss: 7.7874e-05 - val_accuracy: 0.9933 - lr: 1.0433e-05\n",
      "257\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.0433e-05.\n",
      "Epoch 77/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.1204e-05 - accuracy: 0.9947 - val_loss: 7.9293e-05 - val_accuracy: 0.9928 - lr: 1.0433e-05\n",
      "258\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.0433e-05.\n",
      "Epoch 78/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.0950e-05 - accuracy: 0.9946 - val_loss: 8.1757e-05 - val_accuracy: 0.9945 - lr: 1.0433e-05\n",
      "259\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.0433e-05.\n",
      "Epoch 79/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.0991e-05 - accuracy: 0.9947 - val_loss: 8.7177e-05 - val_accuracy: 0.9916 - lr: 1.0433e-05\n",
      "260\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 8.868e-06.\n",
      "Epoch 80/319\n",
      "7590/7658 [============================>.] - ETA: 0s - loss: 7.9929e-05 - accuracy: 0.9947\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.9862e-05 - accuracy: 0.9947 - val_loss: 7.9101e-05 - val_accuracy: 0.9927 - lr: 8.8680e-06\n",
      "261\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 8.868e-06.\n",
      "Epoch 81/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.9873e-05 - accuracy: 0.9947 - val_loss: 7.8617e-05 - val_accuracy: 0.9940 - lr: 8.8680e-06\n",
      "262\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 8.868e-06.\n",
      "Epoch 82/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 8.0181e-05 - accuracy: 0.9947 - val_loss: 8.0940e-05 - val_accuracy: 0.9939 - lr: 8.8680e-06\n",
      "263\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 8.868e-06.\n",
      "Epoch 83/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.9731e-05 - accuracy: 0.9947 - val_loss: 7.9895e-05 - val_accuracy: 0.9943 - lr: 8.8680e-06\n",
      "264\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 8.868e-06.\n",
      "Epoch 84/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.9954e-05 - accuracy: 0.9947 - val_loss: 8.5265e-05 - val_accuracy: 0.9924 - lr: 8.8680e-06\n",
      "265\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 7.538e-06.\n",
      "Epoch 85/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.8848e-05 - accuracy: 0.9948 - val_loss: 7.9344e-05 - val_accuracy: 0.9939 - lr: 7.5380e-06\n",
      "266\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 7.538e-06.\n",
      "Epoch 86/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.8982e-05 - accuracy: 0.9947 - val_loss: 7.6864e-05 - val_accuracy: 0.9939 - lr: 7.5380e-06\n",
      "267\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 7.538e-06.\n",
      "Epoch 87/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.8739e-05 - accuracy: 0.9948 - val_loss: 7.7546e-05 - val_accuracy: 0.9941 - lr: 7.5380e-06\n",
      "268\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 7.538e-06.\n",
      "Epoch 88/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.9000e-05 - accuracy: 0.9947 - val_loss: 7.8242e-05 - val_accuracy: 0.9935 - lr: 7.5380e-06\n",
      "269\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.538e-06.\n",
      "Epoch 89/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.8703e-05 - accuracy: 0.9947 - val_loss: 7.7307e-05 - val_accuracy: 0.9940 - lr: 7.5380e-06\n",
      "270\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.407e-06.\n",
      "Epoch 90/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7938e-05 - accuracy: 0.9948 - val_loss: 7.6631e-05 - val_accuracy: 0.9940 - lr: 6.4070e-06\n",
      "271\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.407e-06.\n",
      "Epoch 91/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7913e-05 - accuracy: 0.9948 - val_loss: 9.3834e-05 - val_accuracy: 0.9906 - lr: 6.4070e-06\n",
      "272\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 6.407e-06.\n",
      "Epoch 92/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7953e-05 - accuracy: 0.9948 - val_loss: 7.7515e-05 - val_accuracy: 0.9936 - lr: 6.4070e-06\n",
      "273\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 6.407e-06.\n",
      "Epoch 93/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7679e-05 - accuracy: 0.9948 - val_loss: 7.8787e-05 - val_accuracy: 0.9930 - lr: 6.4070e-06\n",
      "274\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 6.407e-06.\n",
      "Epoch 94/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7383e-05 - accuracy: 0.9949 - val_loss: 7.6620e-05 - val_accuracy: 0.9936 - lr: 6.4070e-06\n",
      "275\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 5.446e-06.\n",
      "Epoch 95/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7102e-05 - accuracy: 0.9949 - val_loss: 7.7409e-05 - val_accuracy: 0.9932 - lr: 5.4460e-06\n",
      "276\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 5.446e-06.\n",
      "Epoch 96/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.7148e-05 - accuracy: 0.9949 - val_loss: 8.0748e-05 - val_accuracy: 0.9938 - lr: 5.4460e-06\n",
      "277\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 5.446e-06.\n",
      "Epoch 97/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.7132e-05 - accuracy: 0.9949 - val_loss: 7.7421e-05 - val_accuracy: 0.9932 - lr: 5.4460e-06\n",
      "278\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 5.446e-06.\n",
      "Epoch 98/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.6901e-05 - accuracy: 0.9949 - val_loss: 7.7079e-05 - val_accuracy: 0.9939 - lr: 5.4460e-06\n",
      "279\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 5.446e-06.\n",
      "Epoch 99/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.6983e-05 - accuracy: 0.9949 - val_loss: 7.5895e-05 - val_accuracy: 0.9936 - lr: 5.4460e-06\n",
      "280\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 4.629e-06.\n",
      "Epoch 100/319\n",
      "7581/7658 [============================>.] - ETA: 0s - loss: 7.6355e-05 - accuracy: 0.9949\n",
      "Epoch 100: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.6377e-05 - accuracy: 0.9949 - val_loss: 7.7844e-05 - val_accuracy: 0.9939 - lr: 4.6290e-06\n",
      "281\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 4.629e-06.\n",
      "Epoch 101/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.6560e-05 - accuracy: 0.9949 - val_loss: 7.9056e-05 - val_accuracy: 0.9942 - lr: 4.6290e-06\n",
      "282\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 4.629e-06.\n",
      "Epoch 102/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.6231e-05 - accuracy: 0.9949 - val_loss: 1.0055e-04 - val_accuracy: 0.9906 - lr: 4.6290e-06\n",
      "283\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 4.629e-06.\n",
      "Epoch 103/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.6438e-05 - accuracy: 0.9949 - val_loss: 7.5843e-05 - val_accuracy: 0.9934 - lr: 4.6290e-06\n",
      "284\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 4.629e-06.\n",
      "Epoch 104/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.6363e-05 - accuracy: 0.9949 - val_loss: 7.5538e-05 - val_accuracy: 0.9933 - lr: 4.6290e-06\n",
      "285\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 3.935e-06.\n",
      "Epoch 105/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.6054e-05 - accuracy: 0.9949 - val_loss: 7.5358e-05 - val_accuracy: 0.9938 - lr: 3.9350e-06\n",
      "286\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 3.935e-06.\n",
      "Epoch 106/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5752e-05 - accuracy: 0.9949 - val_loss: 7.5910e-05 - val_accuracy: 0.9932 - lr: 3.9350e-06\n",
      "287\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 3.935e-06.\n",
      "Epoch 107/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5830e-05 - accuracy: 0.9949 - val_loss: 7.7502e-05 - val_accuracy: 0.9931 - lr: 3.9350e-06\n",
      "288\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 3.935e-06.\n",
      "Epoch 108/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5796e-05 - accuracy: 0.9949 - val_loss: 7.5047e-05 - val_accuracy: 0.9936 - lr: 3.9350e-06\n",
      "289\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 3.935e-06.\n",
      "Epoch 109/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5775e-05 - accuracy: 0.9950 - val_loss: 7.5326e-05 - val_accuracy: 0.9936 - lr: 3.9350e-06\n",
      "290\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 3.345e-06.\n",
      "Epoch 110/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5412e-05 - accuracy: 0.9950 - val_loss: 7.5347e-05 - val_accuracy: 0.9934 - lr: 3.3450e-06\n",
      "291\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 3.345e-06.\n",
      "Epoch 111/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5402e-05 - accuracy: 0.9950 - val_loss: 7.5921e-05 - val_accuracy: 0.9929 - lr: 3.3450e-06\n",
      "292\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 3.345e-06.\n",
      "Epoch 112/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5247e-05 - accuracy: 0.9950 - val_loss: 7.6172e-05 - val_accuracy: 0.9936 - lr: 3.3450e-06\n",
      "293\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 3.345e-06.\n",
      "Epoch 113/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5183e-05 - accuracy: 0.9950 - val_loss: 7.4825e-05 - val_accuracy: 0.9935 - lr: 3.3450e-06\n",
      "294\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 3.345e-06.\n",
      "Epoch 114/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5227e-05 - accuracy: 0.9950 - val_loss: 7.5151e-05 - val_accuracy: 0.9938 - lr: 3.3450e-06\n",
      "295\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 2.843e-06.\n",
      "Epoch 115/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4892e-05 - accuracy: 0.9950 - val_loss: 7.5003e-05 - val_accuracy: 0.9936 - lr: 2.8430e-06\n",
      "296\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 2.843e-06.\n",
      "Epoch 116/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.5000e-05 - accuracy: 0.9950 - val_loss: 7.5756e-05 - val_accuracy: 0.9938 - lr: 2.8430e-06\n",
      "297\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 2.843e-06.\n",
      "Epoch 117/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4927e-05 - accuracy: 0.9950 - val_loss: 7.4679e-05 - val_accuracy: 0.9938 - lr: 2.8430e-06\n",
      "298\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 2.843e-06.\n",
      "Epoch 118/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4902e-05 - accuracy: 0.9950 - val_loss: 7.7599e-05 - val_accuracy: 0.9928 - lr: 2.8430e-06\n",
      "299\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 2.843e-06.\n",
      "Epoch 119/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4796e-05 - accuracy: 0.9950 - val_loss: 8.2030e-05 - val_accuracy: 0.9919 - lr: 2.8430e-06\n",
      "300\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 2.417e-06.\n",
      "Epoch 120/319\n",
      "7567/7658 [============================>.] - ETA: 0s - loss: 7.4604e-05 - accuracy: 0.9951\n",
      "Epoch 120: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.4567e-05 - accuracy: 0.9951 - val_loss: 7.5971e-05 - val_accuracy: 0.9932 - lr: 2.4170e-06\n",
      "301\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 2.417e-06.\n",
      "Epoch 121/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.4476e-05 - accuracy: 0.9950 - val_loss: 7.5256e-05 - val_accuracy: 0.9940 - lr: 2.4170e-06\n",
      "302\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 2.417e-06.\n",
      "Epoch 122/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4404e-05 - accuracy: 0.9950 - val_loss: 7.8787e-05 - val_accuracy: 0.9922 - lr: 2.4170e-06\n",
      "303\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 2.417e-06.\n",
      "Epoch 123/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4471e-05 - accuracy: 0.9950 - val_loss: 8.4451e-05 - val_accuracy: 0.9939 - lr: 2.4170e-06\n",
      "304\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 2.417e-06.\n",
      "Epoch 124/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4310e-05 - accuracy: 0.9951 - val_loss: 7.4244e-05 - val_accuracy: 0.9938 - lr: 2.4170e-06\n",
      "305\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 2.054e-06.\n",
      "Epoch 125/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4152e-05 - accuracy: 0.9950 - val_loss: 7.5365e-05 - val_accuracy: 0.9934 - lr: 2.0540e-06\n",
      "306\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 2.054e-06.\n",
      "Epoch 126/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4118e-05 - accuracy: 0.9951 - val_loss: 7.4385e-05 - val_accuracy: 0.9943 - lr: 2.0540e-06\n",
      "307\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 2.054e-06.\n",
      "Epoch 127/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4122e-05 - accuracy: 0.9951 - val_loss: 7.4777e-05 - val_accuracy: 0.9935 - lr: 2.0540e-06\n",
      "308\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 2.054e-06.\n",
      "Epoch 128/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4174e-05 - accuracy: 0.9951 - val_loss: 7.4717e-05 - val_accuracy: 0.9941 - lr: 2.0540e-06\n",
      "309\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 2.054e-06.\n",
      "Epoch 129/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.4089e-05 - accuracy: 0.9950 - val_loss: 7.4419e-05 - val_accuracy: 0.9937 - lr: 2.0540e-06\n",
      "310\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 1.746e-06.\n",
      "Epoch 130/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3876e-05 - accuracy: 0.9951 - val_loss: 7.5002e-05 - val_accuracy: 0.9942 - lr: 1.7460e-06\n",
      "311\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 1.746e-06.\n",
      "Epoch 131/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3957e-05 - accuracy: 0.9951 - val_loss: 7.3914e-05 - val_accuracy: 0.9941 - lr: 1.7460e-06\n",
      "312\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 1.746e-06.\n",
      "Epoch 132/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.3926e-05 - accuracy: 0.9951 - val_loss: 7.4515e-05 - val_accuracy: 0.9939 - lr: 1.7460e-06\n",
      "313\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 1.746e-06.\n",
      "Epoch 133/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3866e-05 - accuracy: 0.9951 - val_loss: 7.4246e-05 - val_accuracy: 0.9939 - lr: 1.7460e-06\n",
      "314\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 1.746e-06.\n",
      "Epoch 134/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3882e-05 - accuracy: 0.9951 - val_loss: 7.4434e-05 - val_accuracy: 0.9939 - lr: 1.7460e-06\n",
      "315\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 1.484e-06.\n",
      "Epoch 135/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3601e-05 - accuracy: 0.9951 - val_loss: 7.3986e-05 - val_accuracy: 0.9938 - lr: 1.4840e-06\n",
      "316\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 1.484e-06.\n",
      "Epoch 136/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3752e-05 - accuracy: 0.9951 - val_loss: 7.4199e-05 - val_accuracy: 0.9939 - lr: 1.4840e-06\n",
      "317\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 1.484e-06.\n",
      "Epoch 137/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3679e-05 - accuracy: 0.9951 - val_loss: 7.4236e-05 - val_accuracy: 0.9938 - lr: 1.4840e-06\n",
      "318\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 1.484e-06.\n",
      "Epoch 138/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.3656e-05 - accuracy: 0.9951 - val_loss: 7.4813e-05 - val_accuracy: 0.9938 - lr: 1.4840e-06\n",
      "319\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 1.484e-06.\n",
      "Epoch 139/319\n",
      "7658/7658 [==============================] - 51s 7ms/step - loss: 7.3597e-05 - accuracy: 0.9951 - val_loss: 7.4595e-05 - val_accuracy: 0.9941 - lr: 1.4840e-06\n",
      "320\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 1.261e-06.\n",
      "Epoch 140/319\n",
      "7549/7658 [============================>.] - ETA: 0s - loss: 7.3494e-05 - accuracy: 0.9951\n",
      "Epoch 140: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3495e-05 - accuracy: 0.9951 - val_loss: 8.0107e-05 - val_accuracy: 0.9923 - lr: 1.2610e-06\n",
      "321\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 1.261e-06.\n",
      "Epoch 141/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3461e-05 - accuracy: 0.9951 - val_loss: 7.3966e-05 - val_accuracy: 0.9939 - lr: 1.2610e-06\n",
      "322\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 1.261e-06.\n",
      "Epoch 142/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3468e-05 - accuracy: 0.9951 - val_loss: 7.5133e-05 - val_accuracy: 0.9936 - lr: 1.2610e-06\n",
      "323\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 1.261e-06.\n",
      "Epoch 143/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.3485e-05 - accuracy: 0.9951 - val_loss: 7.4126e-05 - val_accuracy: 0.9937 - lr: 1.2610e-06\n",
      "324\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 1.261e-06.\n",
      "Epoch 144/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.3387e-05 - accuracy: 0.9951 - val_loss: 7.5870e-05 - val_accuracy: 0.9935 - lr: 1.2610e-06\n",
      "325\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 1.072e-06.\n",
      "Epoch 145/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3278e-05 - accuracy: 0.9951 - val_loss: 7.7421e-05 - val_accuracy: 0.9928 - lr: 1.0720e-06\n",
      "326\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 1.072e-06.\n",
      "Epoch 146/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.3279e-05 - accuracy: 0.9951 - val_loss: 7.5305e-05 - val_accuracy: 0.9935 - lr: 1.0720e-06\n",
      "327\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 1.072e-06.\n",
      "Epoch 147/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3274e-05 - accuracy: 0.9951 - val_loss: 7.6173e-05 - val_accuracy: 0.9930 - lr: 1.0720e-06\n",
      "328\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 1.072e-06.\n",
      "Epoch 148/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.3275e-05 - accuracy: 0.9951 - val_loss: 7.4143e-05 - val_accuracy: 0.9941 - lr: 1.0720e-06\n",
      "329\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 1.072e-06.\n",
      "Epoch 149/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3264e-05 - accuracy: 0.9951 - val_loss: 7.4254e-05 - val_accuracy: 0.9940 - lr: 1.0720e-06\n",
      "330\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 9.11e-07.\n",
      "Epoch 150/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3221e-05 - accuracy: 0.9951 - val_loss: 7.4428e-05 - val_accuracy: 0.9942 - lr: 9.1100e-07\n",
      "331\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 9.11e-07.\n",
      "Epoch 151/319\n",
      "7658/7658 [==============================] - 50s 6ms/step - loss: 7.3146e-05 - accuracy: 0.9951 - val_loss: 7.4388e-05 - val_accuracy: 0.9938 - lr: 9.1100e-07\n",
      "332\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 9.11e-07.\n",
      "Epoch 152/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.3191e-05 - accuracy: 0.9951 - val_loss: 7.3727e-05 - val_accuracy: 0.9939 - lr: 9.1100e-07\n",
      "333\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 9.11e-07.\n",
      "Epoch 153/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3094e-05 - accuracy: 0.9951 - val_loss: 7.6886e-05 - val_accuracy: 0.9930 - lr: 9.1100e-07\n",
      "334\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 9.11e-07.\n",
      "Epoch 154/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3124e-05 - accuracy: 0.9951 - val_loss: 7.4407e-05 - val_accuracy: 0.9937 - lr: 9.1100e-07\n",
      "335\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 7.74e-07.\n",
      "Epoch 155/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3052e-05 - accuracy: 0.9951 - val_loss: 7.4166e-05 - val_accuracy: 0.9941 - lr: 7.7400e-07\n",
      "336\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 7.74e-07.\n",
      "Epoch 156/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3021e-05 - accuracy: 0.9951 - val_loss: 7.3840e-05 - val_accuracy: 0.9938 - lr: 7.7400e-07\n",
      "337\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 7.74e-07.\n",
      "Epoch 157/319\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3002e-05 - accuracy: 0.9951 - val_loss: 7.3991e-05 - val_accuracy: 0.9935 - lr: 7.7400e-07\n",
      "338\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 7.74e-07.\n",
      "Epoch 158/319\n",
      "7658/7658 [==============================] - 50s 7ms/step - loss: 7.2985e-05 - accuracy: 0.9951 - val_loss: 7.3777e-05 - val_accuracy: 0.9941 - lr: 7.7400e-07\n",
      "339\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 7.74e-07.\n",
      "Epoch 159/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.3022e-05 - accuracy: 0.9951 - val_loss: 7.3928e-05 - val_accuracy: 0.9940 - lr: 7.7400e-07\n",
      "340\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 6.58e-07.\n",
      "Epoch 160/319\n",
      "7531/7658 [============================>.] - ETA: 0s - loss: 7.3011e-05 - accuracy: 0.9951\n",
      "Epoch 160: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 49s 6ms/step - loss: 7.2936e-05 - accuracy: 0.9951 - val_loss: 7.3796e-05 - val_accuracy: 0.9940 - lr: 6.5800e-07\n",
      "341\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 6.58e-07.\n",
      "Epoch 161/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2866e-05 - accuracy: 0.9951 - val_loss: 7.4546e-05 - val_accuracy: 0.9936 - lr: 6.5800e-07\n",
      "342\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 6.58e-07.\n",
      "Epoch 162/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2903e-05 - accuracy: 0.9951 - val_loss: 7.3655e-05 - val_accuracy: 0.9937 - lr: 6.5800e-07\n",
      "343\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 6.58e-07.\n",
      "Epoch 163/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2919e-05 - accuracy: 0.9951 - val_loss: 7.3839e-05 - val_accuracy: 0.9940 - lr: 6.5800e-07\n",
      "344\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 6.58e-07.\n",
      "Epoch 164/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2942e-05 - accuracy: 0.9951 - val_loss: 7.3748e-05 - val_accuracy: 0.9940 - lr: 6.5800e-07\n",
      "345\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 5.59e-07.\n",
      "Epoch 165/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2816e-05 - accuracy: 0.9951 - val_loss: 7.3860e-05 - val_accuracy: 0.9937 - lr: 5.5900e-07\n",
      "346\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 5.59e-07.\n",
      "Epoch 166/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2821e-05 - accuracy: 0.9951 - val_loss: 7.3687e-05 - val_accuracy: 0.9939 - lr: 5.5900e-07\n",
      "347\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 5.59e-07.\n",
      "Epoch 167/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2794e-05 - accuracy: 0.9951 - val_loss: 7.3760e-05 - val_accuracy: 0.9940 - lr: 5.5900e-07\n",
      "348\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 5.59e-07.\n",
      "Epoch 168/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2816e-05 - accuracy: 0.9951 - val_loss: 7.3818e-05 - val_accuracy: 0.9936 - lr: 5.5900e-07\n",
      "349\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 5.59e-07.\n",
      "Epoch 169/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2808e-05 - accuracy: 0.9951 - val_loss: 7.3885e-05 - val_accuracy: 0.9942 - lr: 5.5900e-07\n",
      "350\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 4.75e-07.\n",
      "Epoch 170/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2740e-05 - accuracy: 0.9951 - val_loss: 7.3699e-05 - val_accuracy: 0.9939 - lr: 4.7500e-07\n",
      "351\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 4.75e-07.\n",
      "Epoch 171/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2758e-05 - accuracy: 0.9951 - val_loss: 7.3547e-05 - val_accuracy: 0.9937 - lr: 4.7500e-07\n",
      "352\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 4.75e-07.\n",
      "Epoch 172/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2747e-05 - accuracy: 0.9951 - val_loss: 7.4204e-05 - val_accuracy: 0.9936 - lr: 4.7500e-07\n",
      "353\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 4.75e-07.\n",
      "Epoch 173/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2703e-05 - accuracy: 0.9951 - val_loss: 7.3735e-05 - val_accuracy: 0.9941 - lr: 4.7500e-07\n",
      "354\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 4.75e-07.\n",
      "Epoch 174/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2715e-05 - accuracy: 0.9951 - val_loss: 7.3996e-05 - val_accuracy: 0.9936 - lr: 4.7500e-07\n",
      "355\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 4.04e-07.\n",
      "Epoch 175/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2674e-05 - accuracy: 0.9951 - val_loss: 7.4336e-05 - val_accuracy: 0.9936 - lr: 4.0400e-07\n",
      "356\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 4.04e-07.\n",
      "Epoch 176/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2659e-05 - accuracy: 0.9951 - val_loss: 7.3770e-05 - val_accuracy: 0.9943 - lr: 4.0400e-07\n",
      "357\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 4.04e-07.\n",
      "Epoch 177/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2648e-05 - accuracy: 0.9951 - val_loss: 7.3590e-05 - val_accuracy: 0.9939 - lr: 4.0400e-07\n",
      "358\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 4.04e-07.\n",
      "Epoch 178/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2637e-05 - accuracy: 0.9951 - val_loss: 7.4688e-05 - val_accuracy: 0.9935 - lr: 4.0400e-07\n",
      "359\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 4.04e-07.\n",
      "Epoch 179/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2652e-05 - accuracy: 0.9951 - val_loss: 7.3918e-05 - val_accuracy: 0.9940 - lr: 4.0400e-07\n",
      "360\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 3.43e-07.\n",
      "Epoch 180/319\n",
      "7520/7658 [============================>.] - ETA: 0s - loss: 7.2619e-05 - accuracy: 0.9951\n",
      "Epoch 180: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2607e-05 - accuracy: 0.9951 - val_loss: 7.4010e-05 - val_accuracy: 0.9937 - lr: 3.4300e-07\n",
      "361\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 3.43e-07.\n",
      "Epoch 181/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2612e-05 - accuracy: 0.9951 - val_loss: 7.3750e-05 - val_accuracy: 0.9942 - lr: 3.4300e-07\n",
      "362\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 3.43e-07.\n",
      "Epoch 182/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2590e-05 - accuracy: 0.9951 - val_loss: 7.3465e-05 - val_accuracy: 0.9940 - lr: 3.4300e-07\n",
      "363\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 3.43e-07.\n",
      "Epoch 183/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2594e-05 - accuracy: 0.9951 - val_loss: 7.3712e-05 - val_accuracy: 0.9939 - lr: 3.4300e-07\n",
      "364\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 3.43e-07.\n",
      "Epoch 184/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2624e-05 - accuracy: 0.9951 - val_loss: 7.4486e-05 - val_accuracy: 0.9936 - lr: 3.4300e-07\n",
      "365\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 2.92e-07.\n",
      "Epoch 185/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2562e-05 - accuracy: 0.9951 - val_loss: 7.3897e-05 - val_accuracy: 0.9939 - lr: 2.9200e-07\n",
      "366\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 2.92e-07.\n",
      "Epoch 186/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2562e-05 - accuracy: 0.9951 - val_loss: 7.3771e-05 - val_accuracy: 0.9939 - lr: 2.9200e-07\n",
      "367\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 2.92e-07.\n",
      "Epoch 187/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2572e-05 - accuracy: 0.9951 - val_loss: 7.4070e-05 - val_accuracy: 0.9936 - lr: 2.9200e-07\n",
      "368\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 2.92e-07.\n",
      "Epoch 188/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2550e-05 - accuracy: 0.9951 - val_loss: 7.3570e-05 - val_accuracy: 0.9940 - lr: 2.9200e-07\n",
      "369\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 2.92e-07.\n",
      "Epoch 189/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2551e-05 - accuracy: 0.9951 - val_loss: 7.4105e-05 - val_accuracy: 0.9937 - lr: 2.9200e-07\n",
      "370\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 2.48e-07.\n",
      "Epoch 190/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2521e-05 - accuracy: 0.9951 - val_loss: 7.3574e-05 - val_accuracy: 0.9938 - lr: 2.4800e-07\n",
      "371\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 2.48e-07.\n",
      "Epoch 191/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2535e-05 - accuracy: 0.9951 - val_loss: 7.3625e-05 - val_accuracy: 0.9938 - lr: 2.4800e-07\n",
      "372\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 2.48e-07.\n",
      "Epoch 192/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2537e-05 - accuracy: 0.9951 - val_loss: 7.3669e-05 - val_accuracy: 0.9942 - lr: 2.4800e-07\n",
      "373\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 2.48e-07.\n",
      "Epoch 193/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2503e-05 - accuracy: 0.9951 - val_loss: 7.3909e-05 - val_accuracy: 0.9935 - lr: 2.4800e-07\n",
      "374\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 2.48e-07.\n",
      "Epoch 194/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2498e-05 - accuracy: 0.9951 - val_loss: 7.3735e-05 - val_accuracy: 0.9938 - lr: 2.4800e-07\n",
      "375\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 2.11e-07.\n",
      "Epoch 195/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2498e-05 - accuracy: 0.9951 - val_loss: 7.3586e-05 - val_accuracy: 0.9939 - lr: 2.1100e-07\n",
      "376\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 2.11e-07.\n",
      "Epoch 196/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2467e-05 - accuracy: 0.9951 - val_loss: 7.3609e-05 - val_accuracy: 0.9938 - lr: 2.1100e-07\n",
      "377\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 2.11e-07.\n",
      "Epoch 197/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2472e-05 - accuracy: 0.9951 - val_loss: 7.3601e-05 - val_accuracy: 0.9938 - lr: 2.1100e-07\n",
      "378\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 2.11e-07.\n",
      "Epoch 198/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2470e-05 - accuracy: 0.9951 - val_loss: 7.3463e-05 - val_accuracy: 0.9936 - lr: 2.1100e-07\n",
      "379\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 2.11e-07.\n",
      "Epoch 199/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2487e-05 - accuracy: 0.9952 - val_loss: 7.3528e-05 - val_accuracy: 0.9937 - lr: 2.1100e-07\n",
      "380\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 1.79e-07.\n",
      "Epoch 200/319\n",
      "7503/7658 [============================>.] - ETA: 0s - loss: 7.2570e-05 - accuracy: 0.9951\n",
      "Epoch 200: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2455e-05 - accuracy: 0.9951 - val_loss: 7.3613e-05 - val_accuracy: 0.9938 - lr: 1.7900e-07\n",
      "381\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 1.79e-07.\n",
      "Epoch 201/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2453e-05 - accuracy: 0.9951 - val_loss: 7.3987e-05 - val_accuracy: 0.9936 - lr: 1.7900e-07\n",
      "382\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 1.79e-07.\n",
      "Epoch 202/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2449e-05 - accuracy: 0.9951 - val_loss: 7.3562e-05 - val_accuracy: 0.9938 - lr: 1.7900e-07\n",
      "383\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 1.79e-07.\n",
      "Epoch 203/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2468e-05 - accuracy: 0.9951 - val_loss: 7.3519e-05 - val_accuracy: 0.9938 - lr: 1.7900e-07\n",
      "384\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 1.79e-07.\n",
      "Epoch 204/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2449e-05 - accuracy: 0.9951 - val_loss: 7.3535e-05 - val_accuracy: 0.9938 - lr: 1.7900e-07\n",
      "385\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 1.52e-07.\n",
      "Epoch 205/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2423e-05 - accuracy: 0.9951 - val_loss: 7.3592e-05 - val_accuracy: 0.9938 - lr: 1.5200e-07\n",
      "386\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 1.52e-07.\n",
      "Epoch 206/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2436e-05 - accuracy: 0.9951 - val_loss: 7.3858e-05 - val_accuracy: 0.9938 - lr: 1.5200e-07\n",
      "387\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 1.52e-07.\n",
      "Epoch 207/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2413e-05 - accuracy: 0.9951 - val_loss: 7.3520e-05 - val_accuracy: 0.9939 - lr: 1.5200e-07\n",
      "388\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 1.52e-07.\n",
      "Epoch 208/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2428e-05 - accuracy: 0.9951 - val_loss: 7.3549e-05 - val_accuracy: 0.9936 - lr: 1.5200e-07\n",
      "389\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 1.52e-07.\n",
      "Epoch 209/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2427e-05 - accuracy: 0.9951 - val_loss: 7.3483e-05 - val_accuracy: 0.9939 - lr: 1.5200e-07\n",
      "390\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 1.29e-07.\n",
      "Epoch 210/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2433e-05 - accuracy: 0.9951 - val_loss: 7.3495e-05 - val_accuracy: 0.9938 - lr: 1.2900e-07\n",
      "391\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 1.29e-07.\n",
      "Epoch 211/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2394e-05 - accuracy: 0.9951 - val_loss: 7.3473e-05 - val_accuracy: 0.9937 - lr: 1.2900e-07\n",
      "392\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 1.29e-07.\n",
      "Epoch 212/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2401e-05 - accuracy: 0.9951 - val_loss: 7.3547e-05 - val_accuracy: 0.9939 - lr: 1.2900e-07\n",
      "393\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 1.29e-07.\n",
      "Epoch 213/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2403e-05 - accuracy: 0.9951 - val_loss: 7.3564e-05 - val_accuracy: 0.9938 - lr: 1.2900e-07\n",
      "394\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 1.29e-07.\n",
      "Epoch 214/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2398e-05 - accuracy: 0.9951 - val_loss: 7.3487e-05 - val_accuracy: 0.9937 - lr: 1.2900e-07\n",
      "395\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 1.1e-07.\n",
      "Epoch 215/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2382e-05 - accuracy: 0.9951 - val_loss: 7.3507e-05 - val_accuracy: 0.9937 - lr: 1.1000e-07\n",
      "396\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 1.1e-07.\n",
      "Epoch 216/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2383e-05 - accuracy: 0.9951 - val_loss: 7.3498e-05 - val_accuracy: 0.9938 - lr: 1.1000e-07\n",
      "397\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 1.1e-07.\n",
      "Epoch 217/319\n",
      "5821/7658 [=====================>........] - ETA: 11s - loss: 7.2117e-05 - accuracy: 0.9951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2356e-05 - accuracy: 0.9951 - val_loss: 7.3461e-05 - val_accuracy: 0.9939 - lr: 9.4000e-08\n",
      "404\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 9.4e-08.\n",
      "Epoch 224/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2350e-05 - accuracy: 0.9951 - val_loss: 7.3480e-05 - val_accuracy: 0.9938 - lr: 9.4000e-08\n",
      "405\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 8e-08.\n",
      "Epoch 225/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2358e-05 - accuracy: 0.9951 - val_loss: 7.3481e-05 - val_accuracy: 0.9938 - lr: 8.0000e-08\n",
      "406\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 8e-08.\n",
      "Epoch 226/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2360e-05 - accuracy: 0.9951 - val_loss: 7.3481e-05 - val_accuracy: 0.9937 - lr: 8.0000e-08\n",
      "407\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 8e-08.\n",
      "Epoch 227/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2347e-05 - accuracy: 0.9951 - val_loss: 7.3482e-05 - val_accuracy: 0.9938 - lr: 8.0000e-08\n",
      "408\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 8e-08.\n",
      "Epoch 228/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2362e-05 - accuracy: 0.9951 - val_loss: 7.3518e-05 - val_accuracy: 0.9938 - lr: 8.0000e-08\n",
      "409\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 8e-08.\n",
      "Epoch 229/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2365e-05 - accuracy: 0.9951 - val_loss: 7.3572e-05 - val_accuracy: 0.9937 - lr: 8.0000e-08\n",
      "410\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 6.8e-08.\n",
      "Epoch 230/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2354e-05 - accuracy: 0.9951 - val_loss: 7.3716e-05 - val_accuracy: 0.9938 - lr: 6.8000e-08\n",
      "411\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 6.8e-08.\n",
      "Epoch 231/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2340e-05 - accuracy: 0.9951 - val_loss: 7.3555e-05 - val_accuracy: 0.9936 - lr: 6.8000e-08\n",
      "412\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 6.8e-08.\n",
      "Epoch 232/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2339e-05 - accuracy: 0.9951 - val_loss: 7.3481e-05 - val_accuracy: 0.9937 - lr: 6.8000e-08\n",
      "413\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 6.8e-08.\n",
      "Epoch 233/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2343e-05 - accuracy: 0.9951 - val_loss: 7.3565e-05 - val_accuracy: 0.9937 - lr: 6.8000e-08\n",
      "414\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 6.8e-08.\n",
      "Epoch 234/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2336e-05 - accuracy: 0.9951 - val_loss: 7.3449e-05 - val_accuracy: 0.9937 - lr: 6.8000e-08\n",
      "415\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 5.8e-08.\n",
      "Epoch 235/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2334e-05 - accuracy: 0.9951 - val_loss: 7.3480e-05 - val_accuracy: 0.9938 - lr: 5.8000e-08\n",
      "416\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 5.8e-08.\n",
      "Epoch 236/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2341e-05 - accuracy: 0.9951 - val_loss: 7.3485e-05 - val_accuracy: 0.9937 - lr: 5.8000e-08\n",
      "417\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 5.8e-08.\n",
      "Epoch 237/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2333e-05 - accuracy: 0.9951 - val_loss: 7.3459e-05 - val_accuracy: 0.9937 - lr: 5.8000e-08\n",
      "418\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 5.8e-08.\n",
      "Epoch 238/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2339e-05 - accuracy: 0.9951 - val_loss: 7.3496e-05 - val_accuracy: 0.9939 - lr: 5.8000e-08\n",
      "419\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 5.8e-08.\n",
      "Epoch 239/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2329e-05 - accuracy: 0.9951 - val_loss: 7.3591e-05 - val_accuracy: 0.9938 - lr: 5.8000e-08\n",
      "420\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 4.9e-08.\n",
      "Epoch 240/319\n",
      "7469/7658 [============================>.] - ETA: 1s - loss: 7.2311e-05 - accuracy: 0.9951\n",
      "Epoch 240: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2326e-05 - accuracy: 0.9951 - val_loss: 7.3495e-05 - val_accuracy: 0.9937 - lr: 4.9000e-08\n",
      "421\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 4.9e-08.\n",
      "Epoch 241/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2325e-05 - accuracy: 0.9951 - val_loss: 7.3471e-05 - val_accuracy: 0.9938 - lr: 4.9000e-08\n",
      "422\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 4.9e-08.\n",
      "Epoch 242/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2330e-05 - accuracy: 0.9951 - val_loss: 7.3580e-05 - val_accuracy: 0.9937 - lr: 4.9000e-08\n",
      "423\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 4.9e-08.\n",
      "Epoch 243/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2328e-05 - accuracy: 0.9951 - val_loss: 7.3464e-05 - val_accuracy: 0.9938 - lr: 4.9000e-08\n",
      "424\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 4.9e-08.\n",
      "Epoch 244/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2330e-05 - accuracy: 0.9951 - val_loss: 7.3513e-05 - val_accuracy: 0.9937 - lr: 4.9000e-08\n",
      "425\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 4.2e-08.\n",
      "Epoch 245/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2321e-05 - accuracy: 0.9951 - val_loss: 7.3642e-05 - val_accuracy: 0.9938 - lr: 4.2000e-08\n",
      "426\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 4.2e-08.\n",
      "Epoch 246/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2320e-05 - accuracy: 0.9951 - val_loss: 7.3473e-05 - val_accuracy: 0.9937 - lr: 4.2000e-08\n",
      "427\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 4.2e-08.\n",
      "Epoch 247/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2321e-05 - accuracy: 0.9951 - val_loss: 7.3533e-05 - val_accuracy: 0.9938 - lr: 4.2000e-08\n",
      "428\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 4.2e-08.\n",
      "Epoch 248/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2326e-05 - accuracy: 0.9951 - val_loss: 7.3574e-05 - val_accuracy: 0.9938 - lr: 4.2000e-08\n",
      "429\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 4.2e-08.\n",
      "Epoch 249/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2325e-05 - accuracy: 0.9951 - val_loss: 7.3530e-05 - val_accuracy: 0.9937 - lr: 4.2000e-08\n",
      "430\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 3.6e-08.\n",
      "Epoch 250/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2314e-05 - accuracy: 0.9951 - val_loss: 7.3485e-05 - val_accuracy: 0.9937 - lr: 3.6000e-08\n",
      "431\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 3.6e-08.\n",
      "Epoch 251/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2317e-05 - accuracy: 0.9951 - val_loss: 7.3536e-05 - val_accuracy: 0.9937 - lr: 3.6000e-08\n",
      "432\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 3.6e-08.\n",
      "Epoch 252/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2322e-05 - accuracy: 0.9951 - val_loss: 7.3539e-05 - val_accuracy: 0.9937 - lr: 3.6000e-08\n",
      "433\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 3.6e-08.\n",
      "Epoch 253/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2317e-05 - accuracy: 0.9951 - val_loss: 7.3477e-05 - val_accuracy: 0.9938 - lr: 3.6000e-08\n",
      "434\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 3.6e-08.\n",
      "Epoch 254/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2319e-05 - accuracy: 0.9951 - val_loss: 7.3472e-05 - val_accuracy: 0.9938 - lr: 3.6000e-08\n",
      "435\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 3.1e-08.\n",
      "Epoch 255/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2315e-05 - accuracy: 0.9951 - val_loss: 7.3489e-05 - val_accuracy: 0.9937 - lr: 3.1000e-08\n",
      "436\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 3.1e-08.\n",
      "Epoch 256/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2316e-05 - accuracy: 0.9951 - val_loss: 7.3462e-05 - val_accuracy: 0.9938 - lr: 3.1000e-08\n",
      "437\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 3.1e-08.\n",
      "Epoch 257/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2313e-05 - accuracy: 0.9951 - val_loss: 7.3513e-05 - val_accuracy: 0.9937 - lr: 3.1000e-08\n",
      "438\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 3.1e-08.\n",
      "Epoch 258/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2313e-05 - accuracy: 0.9951 - val_loss: 7.3457e-05 - val_accuracy: 0.9938 - lr: 3.1000e-08\n",
      "439\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 3.1e-08.\n",
      "Epoch 259/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2307e-05 - accuracy: 0.9951 - val_loss: 7.3470e-05 - val_accuracy: 0.9937 - lr: 3.1000e-08\n",
      "440\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 2.6e-08.\n",
      "Epoch 260/319\n",
      "7462/7658 [============================>.] - ETA: 1s - loss: 7.2320e-05 - accuracy: 0.9951\n",
      "Epoch 260: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2311e-05 - accuracy: 0.9951 - val_loss: 7.3452e-05 - val_accuracy: 0.9938 - lr: 2.6000e-08\n",
      "441\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 2.6e-08.\n",
      "Epoch 261/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2310e-05 - accuracy: 0.9951 - val_loss: 7.3459e-05 - val_accuracy: 0.9937 - lr: 2.6000e-08\n",
      "442\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 2.6e-08.\n",
      "Epoch 262/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2306e-05 - accuracy: 0.9951 - val_loss: 7.3488e-05 - val_accuracy: 0.9937 - lr: 2.6000e-08\n",
      "443\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 2.6e-08.\n",
      "Epoch 263/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2310e-05 - accuracy: 0.9951 - val_loss: 7.3480e-05 - val_accuracy: 0.9937 - lr: 2.6000e-08\n",
      "444\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 2.6e-08.\n",
      "Epoch 264/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2312e-05 - accuracy: 0.9951 - val_loss: 7.3481e-05 - val_accuracy: 0.9937 - lr: 2.6000e-08\n",
      "445\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 2.2e-08.\n",
      "Epoch 265/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2306e-05 - accuracy: 0.9951 - val_loss: 7.3484e-05 - val_accuracy: 0.9938 - lr: 2.2000e-08\n",
      "446\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 2.2e-08.\n",
      "Epoch 266/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2304e-05 - accuracy: 0.9951 - val_loss: 7.3520e-05 - val_accuracy: 0.9937 - lr: 2.2000e-08\n",
      "447\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 2.2e-08.\n",
      "Epoch 267/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2307e-05 - accuracy: 0.9951 - val_loss: 7.3501e-05 - val_accuracy: 0.9937 - lr: 2.2000e-08\n",
      "448\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 2.2e-08.\n",
      "Epoch 268/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2306e-05 - accuracy: 0.9951 - val_loss: 7.3464e-05 - val_accuracy: 0.9939 - lr: 2.2000e-08\n",
      "449\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 2.2e-08.\n",
      "Epoch 269/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2310e-05 - accuracy: 0.9951 - val_loss: 7.3518e-05 - val_accuracy: 0.9937 - lr: 2.2000e-08\n",
      "450\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 1.9e-08.\n",
      "Epoch 270/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2304e-05 - accuracy: 0.9951 - val_loss: 7.3484e-05 - val_accuracy: 0.9937 - lr: 1.9000e-08\n",
      "451\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 1.9e-08.\n",
      "Epoch 271/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2307e-05 - accuracy: 0.9951 - val_loss: 7.3451e-05 - val_accuracy: 0.9939 - lr: 1.9000e-08\n",
      "452\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 1.9e-08.\n",
      "Epoch 272/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2304e-05 - accuracy: 0.9951 - val_loss: 7.3463e-05 - val_accuracy: 0.9938 - lr: 1.9000e-08\n",
      "453\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 1.9e-08.\n",
      "Epoch 273/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2305e-05 - accuracy: 0.9951 - val_loss: 7.3484e-05 - val_accuracy: 0.9938 - lr: 1.9000e-08\n",
      "454\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 1.9e-08.\n",
      "Epoch 274/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2300e-05 - accuracy: 0.9951 - val_loss: 7.3585e-05 - val_accuracy: 0.9939 - lr: 1.9000e-08\n",
      "455\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "Epoch 275/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2302e-05 - accuracy: 0.9951 - val_loss: 7.3455e-05 - val_accuracy: 0.9938 - lr: 1.6000e-08\n",
      "456\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "Epoch 276/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2299e-05 - accuracy: 0.9951 - val_loss: 7.3446e-05 - val_accuracy: 0.9939 - lr: 1.6000e-08\n",
      "457\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "Epoch 277/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2302e-05 - accuracy: 0.9951 - val_loss: 7.3450e-05 - val_accuracy: 0.9939 - lr: 1.6000e-08\n",
      "458\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "Epoch 278/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2299e-05 - accuracy: 0.9951 - val_loss: 7.3473e-05 - val_accuracy: 0.9938 - lr: 1.6000e-08\n",
      "459\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "Epoch 279/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2302e-05 - accuracy: 0.9951 - val_loss: 7.3464e-05 - val_accuracy: 0.9938 - lr: 1.6000e-08\n",
      "460\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 1.4e-08.\n",
      "Epoch 280/319\n",
      "7447/7658 [============================>.] - ETA: 1s - loss: 7.2311e-05 - accuracy: 0.9951\n",
      "Epoch 280: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/1000 points 7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2295e-05 - accuracy: 0.9951 - val_loss: 7.3459e-05 - val_accuracy: 0.9938 - lr: 1.4000e-08\n",
      "461\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 1.4e-08.\n",
      "Epoch 281/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2300e-05 - accuracy: 0.9951 - val_loss: 7.3465e-05 - val_accuracy: 0.9938 - lr: 1.4000e-08\n",
      "462\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 1.4e-08.\n",
      "Epoch 282/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2301e-05 - accuracy: 0.9951 - val_loss: 7.3499e-05 - val_accuracy: 0.9938 - lr: 1.4000e-08\n",
      "463\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 1.4e-08.\n",
      "Epoch 283/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2300e-05 - accuracy: 0.9951 - val_loss: 7.3453e-05 - val_accuracy: 0.9938 - lr: 1.4000e-08\n",
      "464\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 1.4e-08.\n",
      "Epoch 284/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2302e-05 - accuracy: 0.9951 - val_loss: 7.3457e-05 - val_accuracy: 0.9938 - lr: 1.4000e-08\n",
      "465\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 1.2e-08.\n",
      "Epoch 285/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2298e-05 - accuracy: 0.9951 - val_loss: 7.3454e-05 - val_accuracy: 0.9938 - lr: 1.2000e-08\n",
      "466\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 1.2e-08.\n",
      "Epoch 286/319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2300e-05 - accuracy: 0.9951 - val_loss: 7.3463e-05 - val_accuracy: 0.9938 - lr: 1.2000e-08\n",
      "467\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 1.2e-08.\n",
      "Epoch 287/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2298e-05 - accuracy: 0.9951 - val_loss: 7.3476e-05 - val_accuracy: 0.9938 - lr: 1.2000e-08\n",
      "468\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 1.2e-08.\n",
      "Epoch 288/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2299e-05 - accuracy: 0.9951 - val_loss: 7.3462e-05 - val_accuracy: 0.9938 - lr: 1.2000e-08\n",
      "469\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 1.2e-08.\n",
      "Epoch 289/319\n",
      "7658/7658 [==============================] - 47s 6ms/step - loss: 7.2299e-05 - accuracy: 0.9951 - val_loss: 7.3455e-05 - val_accuracy: 0.9938 - lr: 1.2000e-08\n",
      "470\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 1e-08.\n",
      "Epoch 290/319\n",
      "7658/7658 [==============================] - 48s 6ms/step - loss: 7.2294e-05 - accuracy: 0.9951 - val_loss: 7.3466e-05 - val_accuracy: 0.9939 - lr: 1.0000e-08\n",
      "471\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 1e-08.\n",
      "Epoch 291/319\n",
      "4167/7658 [===============>..............] - ETA: 21s - loss: 7.2393e-05 - accuracy: 0.9951"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mremaining_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/training.py:1376\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1374\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1376\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m         epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m         step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m         _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/data_adapter.py:1246\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1247\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1248\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   1251\u001b[0m     original_spe)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    675\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    676\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:749\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m the read operation.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle()\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    731\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    732\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    734\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    735\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    736\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:718\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_set_handle\u001b[39m():\n\u001b[0;32m--> 718\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m   _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    721\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:479\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    478\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = remaining_iterations,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler2,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6a10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a19be2a",
   "metadata": {},
   "source": [
    "# Observation that loss is constant after reaching the learning rate of <=1e-7 So its better to stop learning below this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61f45e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89360577, 0.46690145],\n",
       "       [0.2609251 , 0.5638199 ],\n",
       "       [0.2617634 , 0.65673465],\n",
       "       ...,\n",
       "       [0.25969714, 0.46219853],\n",
       "       [0.065283  , 0.0539636 ],\n",
       "       [0.08748144, 0.3154119 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b6bf3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88940617, 0.47311156],\n",
       "       [0.26437283, 0.55854691],\n",
       "       [0.2419437 , 0.66788639],\n",
       "       ...,\n",
       "       [0.26010524, 0.46431416],\n",
       "       [0.05720036, 0.06869787],\n",
       "       [0.08523072, 0.31442504]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4778f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
