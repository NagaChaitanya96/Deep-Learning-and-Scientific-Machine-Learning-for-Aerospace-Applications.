{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for 5 percent data variation\n",
    "1. Batch size = 64\n",
    "2. Neurons = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DVrymL7YtWo",
    "outputId": "6739e8e0-11b0-403f-ad08-0c603e88fb9d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "g2QhOkBkYzgE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/saichaitanya/Chaitanya/CSV files/May6rd5percent_RLV_data 100 points2 .csv',header = None,names = ['h','v','s','omega','gamma','m','theta','Thrust','beta','time'])\n",
    "input = output =df.values\n",
    "X = input[:,0:7]\n",
    "y = output[:,7:9]\n",
    "# Individual Data\n",
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.minmax_scale(X)\n",
    "y_norm = preprocessing.minmax_scale(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.1, random_state=42)\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qmMojsgZZL4J"
   },
   "outputs": [],
   "source": [
    "def create_model2(n):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n,input_shape=(7,),kernel_initializer='uniform'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu')) # since tanh has more nonlinearity we add it here, it also gives -ve values so , some layers which are not necessary will lead to 0 in next layer\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(n,kernel_initializer='uniform',activation = 'relu'))\n",
    "    model.add(Dense(2,kernel_initializer='uniform',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iDASMcALZLuU"
   },
   "outputs": [],
   "source": [
    "i = 7;\n",
    "model = create_model2(2**i)\n",
    "# model.load_weights(f\"/content/gdrive/My Drive/Last data /1percent model/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtOxXma1ZVEa",
    "outputId": "f9061dfc-f948-4d58-c0b7-e36ff541b702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50000703, 0.49999532],\n",
       "       [0.5000058 , 0.49999785],\n",
       "       [0.50001115, 0.49999538],\n",
       "       ...,\n",
       "       [0.50000584, 0.4999982 ],\n",
       "       [0.500006  , 0.49999794],\n",
       "       [0.50001043, 0.49999237]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fgzcli_dZYAy",
    "outputId": "78df5779-251e-4887-9dc9-7dd1fa2fa894"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06554793, 0.48950587],\n",
       "       [0.77689939, 0.47137161],\n",
       "       [0.13451512, 0.6880959 ],\n",
       "       ...,\n",
       "       [0.64493052, 0.48145433],\n",
       "       [0.91585227, 0.47448883],\n",
       "       [0.05393215, 0.6612795 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6AnPdtQZLru",
    "outputId": "ba21d3c2-2260-4183-f1d8-043147601c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Hidden units used is:  128\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def lr_sch3(epoch,lr):\n",
    "    if (epoch >0) &(epoch<300):\n",
    "      if epoch%50==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>300):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "print(\"The Number of Hidden units used is: \",2**i)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_sch3,verbose = 1)\n",
    "bs = 64;\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / bs\n",
    "save_period = 20\n",
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))\n",
    "model.compile(optimizer = opt, loss = loss, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iabK_vxVZcWj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0087 - accuracy: 0.8591 - val_loss: 0.0060 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0053 - accuracy: 0.8733 - val_loss: 0.0052 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0049 - accuracy: 0.8775 - val_loss: 0.0045 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0045 - accuracy: 0.8812 - val_loss: 0.0044 - val_accuracy: 0.8715 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0043 - accuracy: 0.8834 - val_loss: 0.0046 - val_accuracy: 0.8775 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0041 - accuracy: 0.8866 - val_loss: 0.0041 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0039 - accuracy: 0.8891 - val_loss: 0.0036 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0039 - accuracy: 0.8903 - val_loss: 0.0041 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0036 - accuracy: 0.8929 - val_loss: 0.0038 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0036 - accuracy: 0.8946 - val_loss: 0.0032 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0036 - accuracy: 0.8945 - val_loss: 0.0032 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.8979 - val_loss: 0.0033 - val_accuracy: 0.8996 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0033 - accuracy: 0.8990 - val_loss: 0.0028 - val_accuracy: 0.9064 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.8975 - val_loss: 0.0035 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0033 - accuracy: 0.8992 - val_loss: 0.0031 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0032 - accuracy: 0.9016 - val_loss: 0.0034 - val_accuracy: 0.8990 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0031 - accuracy: 0.9030 - val_loss: 0.0029 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0031 - accuracy: 0.9024 - val_loss: 0.0037 - val_accuracy: 0.8806 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0030 - accuracy: 0.9031 - val_loss: 0.0028 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/1000\n",
      "2942/2950 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9039\n",
      "Epoch 20: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0030 - accuracy: 0.9039 - val_loss: 0.0035 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9078 - val_loss: 0.0025 - val_accuracy: 0.9161 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0029 - accuracy: 0.9067 - val_loss: 0.0028 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0028 - accuracy: 0.9096 - val_loss: 0.0024 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0027 - accuracy: 0.9119 - val_loss: 0.0029 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0026 - accuracy: 0.9149 - val_loss: 0.0021 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 26/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0026 - accuracy: 0.9144 - val_loss: 0.0020 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 27/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0027 - accuracy: 0.9137 - val_loss: 0.0023 - val_accuracy: 0.9224 - lr: 0.0010\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 28/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0024 - accuracy: 0.9197 - val_loss: 0.0024 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 29/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0024 - accuracy: 0.9201 - val_loss: 0.0023 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 30/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0023 - accuracy: 0.9214 - val_loss: 0.0037 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 31/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0025 - accuracy: 0.9182 - val_loss: 0.0016 - val_accuracy: 0.9416 - lr: 0.0010\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 32/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0023 - accuracy: 0.9233 - val_loss: 0.0016 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 33/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0023 - accuracy: 0.9217 - val_loss: 0.0019 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 34/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9254 - val_loss: 0.0030 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 35/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9288 - val_loss: 0.0014 - val_accuracy: 0.9518 - lr: 0.0010\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9269 - val_loss: 0.0026 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 37/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9280 - val_loss: 0.0023 - val_accuracy: 0.9195 - lr: 0.0010\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 38/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0020 - accuracy: 0.9301 - val_loss: 0.0032 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 39/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0020 - accuracy: 0.9292 - val_loss: 0.0018 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 40/1000\n",
      "2935/2950 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9282\n",
      "Epoch 40: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9282 - val_loss: 0.0057 - val_accuracy: 0.8806 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 41/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0021 - accuracy: 0.9283 - val_loss: 0.0023 - val_accuracy: 0.9183 - lr: 0.0010\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 42/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0020 - accuracy: 0.9304 - val_loss: 0.0019 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 43/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0019 - accuracy: 0.9326 - val_loss: 0.0018 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 44/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0020 - accuracy: 0.9321 - val_loss: 0.0017 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 45/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0019 - accuracy: 0.9320 - val_loss: 0.0027 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 46/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0019 - accuracy: 0.9340 - val_loss: 0.0015 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 47/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0018 - accuracy: 0.9350 - val_loss: 0.0021 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 48/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0018 - accuracy: 0.9351 - val_loss: 0.0015 - val_accuracy: 0.9399 - lr: 0.0010\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 49/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0019 - accuracy: 0.9334 - val_loss: 0.0018 - val_accuracy: 0.9315 - lr: 0.0010\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 50/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0018 - accuracy: 0.9342 - val_loss: 0.0014 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 51/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0014 - accuracy: 0.9467 - val_loss: 0.0018 - val_accuracy: 0.9290 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 52/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9486 - val_loss: 0.0016 - val_accuracy: 0.9349 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 53/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9495 - val_loss: 9.4568e-04 - val_accuracy: 0.9619 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 54/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9491 - val_loss: 0.0019 - val_accuracy: 0.9300 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 55/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0014 - accuracy: 0.9480 - val_loss: 0.0017 - val_accuracy: 0.9345 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 56/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0014 - accuracy: 0.9494 - val_loss: 8.8863e-04 - val_accuracy: 0.9667 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 57/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9498 - val_loss: 9.6400e-04 - val_accuracy: 0.9651 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 58/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9507 - val_loss: 0.0011 - val_accuracy: 0.9599 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 59/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9500 - val_loss: 0.0010 - val_accuracy: 0.9555 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 60/1000\n",
      "2946/2950 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9497\n",
      "Epoch 60: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9496 - val_loss: 0.0010 - val_accuracy: 0.9606 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 61/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9527 - val_loss: 0.0014 - val_accuracy: 0.9446 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 62/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0013 - accuracy: 0.9493 - val_loss: 0.0018 - val_accuracy: 0.9307 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 63/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9501 - val_loss: 9.0527e-04 - val_accuracy: 0.9678 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 64/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9518 - val_loss: 9.3237e-04 - val_accuracy: 0.9649 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 65/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9511 - val_loss: 0.0013 - val_accuracy: 0.9403 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 66/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9491 - val_loss: 0.0019 - val_accuracy: 0.9308 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 67/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9503 - val_loss: 7.5755e-04 - val_accuracy: 0.9701 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 68/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9518 - val_loss: 8.1022e-04 - val_accuracy: 0.9693 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 69/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9553 - val_loss: 7.8723e-04 - val_accuracy: 0.9662 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 70/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9526 - val_loss: 0.0017 - val_accuracy: 0.9337 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 71/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9549 - val_loss: 7.9744e-04 - val_accuracy: 0.9630 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 72/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9521 - val_loss: 8.7794e-04 - val_accuracy: 0.9553 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 73/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9514 - val_loss: 8.8575e-04 - val_accuracy: 0.9574 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 74/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9540 - val_loss: 7.2880e-04 - val_accuracy: 0.9677 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 75/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9532 - val_loss: 8.9506e-04 - val_accuracy: 0.9583 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 76/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9527 - val_loss: 9.1158e-04 - val_accuracy: 0.9562 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 77/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0012 - accuracy: 0.9531 - val_loss: 0.0018 - val_accuracy: 0.9288 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 78/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9524 - val_loss: 0.0017 - val_accuracy: 0.9313 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 79/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9528 - val_loss: 8.2799e-04 - val_accuracy: 0.9631 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 80/1000\n",
      "2941/2950 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9574\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9574 - val_loss: 0.0014 - val_accuracy: 0.9396 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 81/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9559 - val_loss: 0.0011 - val_accuracy: 0.9519 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 82/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9540 - val_loss: 8.8788e-04 - val_accuracy: 0.9627 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 83/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9563 - val_loss: 9.9351e-04 - val_accuracy: 0.9523 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 84/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9568 - val_loss: 7.4301e-04 - val_accuracy: 0.9672 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 85/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9548 - val_loss: 9.1820e-04 - val_accuracy: 0.9678 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 86/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9550 - val_loss: 8.6883e-04 - val_accuracy: 0.9687 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 87/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9552 - val_loss: 8.4584e-04 - val_accuracy: 0.9622 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 88/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9553 - val_loss: 8.1842e-04 - val_accuracy: 0.9691 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 89/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9571 - val_loss: 9.1447e-04 - val_accuracy: 0.9625 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 90/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9558 - val_loss: 0.0011 - val_accuracy: 0.9445 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 91/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9535 - val_loss: 0.0012 - val_accuracy: 0.9484 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 92/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9576 - val_loss: 0.0010 - val_accuracy: 0.9523 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 93/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9543 - val_loss: 0.0019 - val_accuracy: 0.9309 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 94/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9533 - val_loss: 0.0016 - val_accuracy: 0.9365 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 95/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0013 - accuracy: 0.9511 - val_loss: 0.0014 - val_accuracy: 0.9395 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 96/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9539 - val_loss: 0.0010 - val_accuracy: 0.9563 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 97/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9584 - val_loss: 0.0010 - val_accuracy: 0.9548 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 98/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9569 - val_loss: 0.0015 - val_accuracy: 0.9346 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 99/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0010 - accuracy: 0.9589 - val_loss: 0.0014 - val_accuracy: 0.9470 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0006376.\n",
      "Epoch 100/1000\n",
      "2935/2950 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9579\n",
      "Epoch 100: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 0.0011 - accuracy: 0.9580 - val_loss: 7.4862e-04 - val_accuracy: 0.9701 - lr: 6.3760e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 101/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 8.5917e-04 - accuracy: 0.9644 - val_loss: 6.9235e-04 - val_accuracy: 0.9678 - lr: 4.0660e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 102/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 8.3464e-04 - accuracy: 0.9650 - val_loss: 5.7373e-04 - val_accuracy: 0.9742 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 103/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 8.5473e-04 - accuracy: 0.9653 - val_loss: 9.9144e-04 - val_accuracy: 0.9508 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 104/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 8.2594e-04 - accuracy: 0.9645 - val_loss: 8.4706e-04 - val_accuracy: 0.9640 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 105/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 8.2697e-04 - accuracy: 0.9656 - val_loss: 0.0011 - val_accuracy: 0.9522 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 106/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 8.2862e-04 - accuracy: 0.9652 - val_loss: 5.7365e-04 - val_accuracy: 0.9701 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 107/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 8.2324e-04 - accuracy: 0.9654 - val_loss: 0.0014 - val_accuracy: 0.9459 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 108/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 8.3078e-04 - accuracy: 0.9648 - val_loss: 6.9802e-04 - val_accuracy: 0.9716 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 109/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7560e-04 - accuracy: 0.9669 - val_loss: 5.0618e-04 - val_accuracy: 0.9765 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 110/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7984e-04 - accuracy: 0.9670 - val_loss: 6.1876e-04 - val_accuracy: 0.9749 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 111/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.9236e-04 - accuracy: 0.9664 - val_loss: 7.4781e-04 - val_accuracy: 0.9659 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 112/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.8809e-04 - accuracy: 0.9667 - val_loss: 6.5959e-04 - val_accuracy: 0.9686 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 113/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 8.1637e-04 - accuracy: 0.9648 - val_loss: 6.0213e-04 - val_accuracy: 0.9771 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 114/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.5838e-04 - accuracy: 0.9673 - val_loss: 6.0586e-04 - val_accuracy: 0.9766 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 115/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.8215e-04 - accuracy: 0.9666 - val_loss: 7.3825e-04 - val_accuracy: 0.9712 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 116/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7455e-04 - accuracy: 0.9675 - val_loss: 6.2486e-04 - val_accuracy: 0.9772 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 117/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3282e-04 - accuracy: 0.9688 - val_loss: 7.0305e-04 - val_accuracy: 0.9667 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 118/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.8990e-04 - accuracy: 0.9665 - val_loss: 6.6468e-04 - val_accuracy: 0.9736 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 119/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.6050e-04 - accuracy: 0.9676 - val_loss: 5.0217e-04 - val_accuracy: 0.9776 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 120/1000\n",
      "2932/2950 [============================>.] - ETA: 0s - loss: 7.6721e-04 - accuracy: 0.9670\n",
      "Epoch 120: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.6641e-04 - accuracy: 0.9671 - val_loss: 4.6895e-04 - val_accuracy: 0.9764 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 121/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.9676e-04 - accuracy: 0.9659 - val_loss: 7.5014e-04 - val_accuracy: 0.9717 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 122/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.9560e-04 - accuracy: 0.9663 - val_loss: 6.2730e-04 - val_accuracy: 0.9713 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 123/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.5209e-04 - accuracy: 0.9678 - val_loss: 7.5110e-04 - val_accuracy: 0.9689 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 124/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3313e-04 - accuracy: 0.9676 - val_loss: 0.0014 - val_accuracy: 0.9372 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 125/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5843e-04 - accuracy: 0.9674 - val_loss: 5.0096e-04 - val_accuracy: 0.9734 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 126/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.9593e-04 - accuracy: 0.9660 - val_loss: 6.3912e-04 - val_accuracy: 0.9750 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 127/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.4137e-04 - accuracy: 0.9684 - val_loss: 5.8912e-04 - val_accuracy: 0.9719 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 128/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3077e-04 - accuracy: 0.9684 - val_loss: 8.1047e-04 - val_accuracy: 0.9660 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 129/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7136e-04 - accuracy: 0.9670 - val_loss: 5.7773e-04 - val_accuracy: 0.9762 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 130/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5446e-04 - accuracy: 0.9675 - val_loss: 8.8163e-04 - val_accuracy: 0.9663 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 131/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5515e-04 - accuracy: 0.9676 - val_loss: 5.2206e-04 - val_accuracy: 0.9749 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 132/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7292e-04 - accuracy: 0.9671 - val_loss: 6.5110e-04 - val_accuracy: 0.9699 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 133/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.4806e-04 - accuracy: 0.9684 - val_loss: 8.5250e-04 - val_accuracy: 0.9592 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 134/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5003e-04 - accuracy: 0.9676 - val_loss: 6.5667e-04 - val_accuracy: 0.9679 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 135/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3449e-04 - accuracy: 0.9682 - val_loss: 6.6739e-04 - val_accuracy: 0.9624 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 136/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3071e-04 - accuracy: 0.9683 - val_loss: 6.0968e-04 - val_accuracy: 0.9730 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 137/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.6263e-04 - accuracy: 0.9675 - val_loss: 5.7397e-04 - val_accuracy: 0.9774 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 138/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.2492e-04 - accuracy: 0.9687 - val_loss: 5.1278e-04 - val_accuracy: 0.9790 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 139/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.7349e-04 - accuracy: 0.9675 - val_loss: 0.0011 - val_accuracy: 0.9505 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 140/1000\n",
      "2939/2950 [============================>.] - ETA: 0s - loss: 7.5409e-04 - accuracy: 0.9677\n",
      "Epoch 140: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5441e-04 - accuracy: 0.9677 - val_loss: 5.9277e-04 - val_accuracy: 0.9694 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 141/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5202e-04 - accuracy: 0.9677 - val_loss: 7.8706e-04 - val_accuracy: 0.9719 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 142/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.1531e-04 - accuracy: 0.9692 - val_loss: 7.8791e-04 - val_accuracy: 0.9700 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 143/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.3247e-04 - accuracy: 0.9685 - val_loss: 7.7927e-04 - val_accuracy: 0.9583 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 144/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.1370e-04 - accuracy: 0.9693 - val_loss: 7.8610e-04 - val_accuracy: 0.9707 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 145/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 7.1434e-04 - accuracy: 0.9690 - val_loss: 5.6978e-04 - val_accuracy: 0.9729 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 146/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3794e-04 - accuracy: 0.9678 - val_loss: 9.3195e-04 - val_accuracy: 0.9534 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 147/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3888e-04 - accuracy: 0.9687 - val_loss: 9.2214e-04 - val_accuracy: 0.9596 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 148/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3497e-04 - accuracy: 0.9682 - val_loss: 4.7470e-04 - val_accuracy: 0.9778 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 149/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.3620e-04 - accuracy: 0.9681 - val_loss: 9.4083e-04 - val_accuracy: 0.9540 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.0004066.\n",
      "Epoch 150/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 7.5313e-04 - accuracy: 0.9681 - val_loss: 4.6207e-04 - val_accuracy: 0.9807 - lr: 4.0660e-04\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 151/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.7993e-04 - accuracy: 0.9740 - val_loss: 4.9244e-04 - val_accuracy: 0.9733 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 152/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.6745e-04 - accuracy: 0.9741 - val_loss: 5.6268e-04 - val_accuracy: 0.9752 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 153/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.8224e-04 - accuracy: 0.9743 - val_loss: 5.1745e-04 - val_accuracy: 0.9701 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 154/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.6950e-04 - accuracy: 0.9748 - val_loss: 9.9985e-04 - val_accuracy: 0.9548 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 155/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.7141e-04 - accuracy: 0.9743 - val_loss: 4.1646e-04 - val_accuracy: 0.9825 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 156/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.7719e-04 - accuracy: 0.9742 - val_loss: 4.2689e-04 - val_accuracy: 0.9767 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 157/1000\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.7232e-04 - accuracy: 0.9741 - val_loss: 4.4488e-04 - val_accuracy: 0.9791 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 158/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.2841e-04 - accuracy: 0.9761 - val_loss: 3.9763e-04 - val_accuracy: 0.9817 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 159/1000\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.6865e-04 - accuracy: 0.9746 - val_loss: 5.3502e-04 - val_accuracy: 0.9769 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 160/1000\n",
      "2938/2950 [============================>.] - ETA: 0s - loss: 5.7724e-04 - accuracy: 0.9738\n",
      "Epoch 160: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.7848e-04 - accuracy: 0.9738 - val_loss: 0.0011 - val_accuracy: 0.9502 - lr: 2.5930e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.0002593.\n",
      "Epoch 161/1000\n",
      " 523/2950 [====>.........................] - ETA: 10s - loss: 5.6700e-04 - accuracy: 0.9736"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/saiaero/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 1000,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZTif_ciZcTu"
   },
   "source": [
    "model.save(f\"/content/gdrive/My Drive/Last data /5percent model/best models/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_sch160(epoch,lr):\n",
    "    epoch = epoch+160\n",
    "    if (epoch >0) &(epoch<150):\n",
    "      if epoch%50==0: # for every 100 epochs the learning rate varies as metioned. \n",
    "        return round(lr*np.exp(-0.45),7)\n",
    "      else:\n",
    "        return round(lr,7)\n",
    "    elif(epoch>150):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "        return round(lr,9)\n",
    "lr_scheduler2 = tf.keras.callbacks.LearningRateScheduler(lr_sch160,verbose = 1)\n",
    "cp_callback2 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1,\n",
    "                                            save_freq=int(save_period*STEPS_PER_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0ac003f880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = f\"/home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 1/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.4931e-04 - accuracy: 0.9748 - val_loss: 4.7260e-04 - val_accuracy: 0.9801 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 2/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0078e-04 - accuracy: 0.9770 - val_loss: 3.8616e-04 - val_accuracy: 0.9800 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 3/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0977e-04 - accuracy: 0.9767 - val_loss: 6.9960e-04 - val_accuracy: 0.9596 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 4/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.1399e-04 - accuracy: 0.9769 - val_loss: 5.4020e-04 - val_accuracy: 0.9744 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 5/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 5.2769e-04 - accuracy: 0.9761 - val_loss: 4.7084e-04 - val_accuracy: 0.9798 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 6/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0182e-04 - accuracy: 0.9768 - val_loss: 4.0803e-04 - val_accuracy: 0.9784 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 7/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.8315e-04 - accuracy: 0.9777 - val_loss: 4.9330e-04 - val_accuracy: 0.9741 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 8/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.9347e-04 - accuracy: 0.9773 - val_loss: 3.7683e-04 - val_accuracy: 0.9839 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 9/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.1004e-04 - accuracy: 0.9764 - val_loss: 4.2275e-04 - val_accuracy: 0.9818 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 10/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0925e-04 - accuracy: 0.9765 - val_loss: 6.2793e-04 - val_accuracy: 0.9643 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 11/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.2704e-04 - accuracy: 0.9763 - val_loss: 3.8388e-04 - val_accuracy: 0.9795 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 12/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.2661e-04 - accuracy: 0.9762 - val_loss: 4.4368e-04 - val_accuracy: 0.9752 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 13/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0405e-04 - accuracy: 0.9771 - val_loss: 8.4363e-04 - val_accuracy: 0.9567 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 14/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.1894e-04 - accuracy: 0.9764 - val_loss: 4.7951e-04 - val_accuracy: 0.9806 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 15/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.2589e-04 - accuracy: 0.9765 - val_loss: 3.8709e-04 - val_accuracy: 0.9842 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 16/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.0963e-04 - accuracy: 0.9766 - val_loss: 4.2087e-04 - val_accuracy: 0.9823 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 17/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.2109e-04 - accuracy: 0.9761 - val_loss: 3.9814e-04 - val_accuracy: 0.9796 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 18/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 5.1189e-04 - accuracy: 0.9763 - val_loss: 6.7571e-04 - val_accuracy: 0.9666 - lr: 2.2040e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000220405.\n",
      "Epoch 19/600\n",
      "2553/2950 [========================>.....] - ETA: 1s - loss: 4.9532e-04 - accuracy: 0.9768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.2232e-04 - accuracy: 0.9802 - val_loss: 4.1046e-04 - val_accuracy: 0.9832 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 43/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.2147e-04 - accuracy: 0.9803 - val_loss: 3.6745e-04 - val_accuracy: 0.9821 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 44/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.1814e-04 - accuracy: 0.9801 - val_loss: 6.7283e-04 - val_accuracy: 0.9628 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 45/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.1163e-04 - accuracy: 0.9806 - val_loss: 4.6713e-04 - val_accuracy: 0.9720 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 46/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.3528e-04 - accuracy: 0.9798 - val_loss: 4.1419e-04 - val_accuracy: 0.9823 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 47/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.1140e-04 - accuracy: 0.9805 - val_loss: 4.5244e-04 - val_accuracy: 0.9801 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 48/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.2781e-04 - accuracy: 0.9799 - val_loss: 3.6857e-04 - val_accuracy: 0.9829 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 49/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.2588e-04 - accuracy: 0.9797 - val_loss: 3.6557e-04 - val_accuracy: 0.9797 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 50/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.1007e-04 - accuracy: 0.9804 - val_loss: 3.5767e-04 - val_accuracy: 0.9842 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 51/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.2254e-04 - accuracy: 0.9802 - val_loss: 3.3140e-04 - val_accuracy: 0.9857 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 52/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.2613e-04 - accuracy: 0.9796 - val_loss: 8.1388e-04 - val_accuracy: 0.9591 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 53/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 4.2295e-04 - accuracy: 0.9797 - val_loss: 4.5486e-04 - val_accuracy: 0.9811 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 54/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 4.3860e-04 - accuracy: 0.9799 - val_loss: 5.0839e-04 - val_accuracy: 0.9767 - lr: 1.5924e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.000159242.\n",
      "Epoch 55/600\n",
      "1580/2950 [===============>..............] - ETA: 5s - loss: 3.9247e-04 - accuracy: 0.9809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934/2950 [============================>.] - ETA: 0s - loss: 3.8149e-04 - accuracy: 0.9816\n",
      "Epoch 80: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.8132e-04 - accuracy: 0.9816 - val_loss: 3.2272e-04 - val_accuracy: 0.9858 - lr: 1.3536e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 81/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6728e-04 - accuracy: 0.9823 - val_loss: 2.8667e-04 - val_accuracy: 0.9869 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 82/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.6302e-04 - accuracy: 0.9821 - val_loss: 3.2733e-04 - val_accuracy: 0.9849 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 83/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.7587e-04 - accuracy: 0.9819 - val_loss: 2.9430e-04 - val_accuracy: 0.9847 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 84/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6230e-04 - accuracy: 0.9825 - val_loss: 3.0465e-04 - val_accuracy: 0.9869 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 85/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.5388e-04 - accuracy: 0.9828 - val_loss: 3.7724e-04 - val_accuracy: 0.9833 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 86/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6397e-04 - accuracy: 0.9831 - val_loss: 3.1870e-04 - val_accuracy: 0.9846 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 87/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6033e-04 - accuracy: 0.9830 - val_loss: 3.1012e-04 - val_accuracy: 0.9863 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 88/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.4725e-04 - accuracy: 0.9834 - val_loss: 4.0634e-04 - val_accuracy: 0.9782 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 89/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.4870e-04 - accuracy: 0.9827 - val_loss: 3.3058e-04 - val_accuracy: 0.9853 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 90/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6277e-04 - accuracy: 0.9824 - val_loss: 2.8227e-04 - val_accuracy: 0.9853 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 91/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.6370e-04 - accuracy: 0.9822 - val_loss: 3.8098e-04 - val_accuracy: 0.9848 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 92/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.5604e-04 - accuracy: 0.9826 - val_loss: 3.8247e-04 - val_accuracy: 0.9824 - lr: 1.1505e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.000115053.\n",
      "Epoch 93/600\n",
      " 612/2950 [=====>........................] - ETA: 9s - loss: 3.7958e-04 - accuracy: 0.9831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.2868e-04 - accuracy: 0.9840 - val_loss: 4.7744e-04 - val_accuracy: 0.9757 - lr: 9.7795e-05\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 9.7795e-05.\n",
      "Epoch 119/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.2362e-04 - accuracy: 0.9841 - val_loss: 2.7264e-04 - val_accuracy: 0.9857 - lr: 9.7795e-05\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 9.7795e-05.\n",
      "Epoch 120/600\n",
      "2943/2950 [============================>.] - ETA: 0s - loss: 3.2578e-04 - accuracy: 0.9843\n",
      "Epoch 120: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.2555e-04 - accuracy: 0.9843 - val_loss: 2.8801e-04 - val_accuracy: 0.9862 - lr: 9.7795e-05\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 121/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.1423e-04 - accuracy: 0.9844 - val_loss: 3.5949e-04 - val_accuracy: 0.9839 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 122/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.1892e-04 - accuracy: 0.9843 - val_loss: 3.9462e-04 - val_accuracy: 0.9827 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 123/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.0887e-04 - accuracy: 0.9846 - val_loss: 3.1313e-04 - val_accuracy: 0.9857 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 124/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.0899e-04 - accuracy: 0.9849 - val_loss: 2.9518e-04 - val_accuracy: 0.9867 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 125/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.1691e-04 - accuracy: 0.9843 - val_loss: 2.8517e-04 - val_accuracy: 0.9874 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 126/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.1536e-04 - accuracy: 0.9846 - val_loss: 2.8135e-04 - val_accuracy: 0.9873 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 127/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.1970e-04 - accuracy: 0.9842 - val_loss: 2.7287e-04 - val_accuracy: 0.9866 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 128/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.0508e-04 - accuracy: 0.9846 - val_loss: 2.8577e-04 - val_accuracy: 0.9839 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 129/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 3.0615e-04 - accuracy: 0.9850 - val_loss: 2.7602e-04 - val_accuracy: 0.9852 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 130/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 3.0675e-04 - accuracy: 0.9848 - val_loss: 2.6786e-04 - val_accuracy: 0.9879 - lr: 8.3126e-05\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 8.3126e-05.\n",
      "Epoch 131/600\n",
      "  52/2950 [..............................] - ETA: 11s - loss: 2.9789e-04 - accuracy: 0.9850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.9479e-04 - accuracy: 0.9857 - val_loss: 3.0969e-04 - val_accuracy: 0.9853 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 7.0657e-05.\n",
      "Epoch 156/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.9946e-04 - accuracy: 0.9852 - val_loss: 3.5066e-04 - val_accuracy: 0.9803 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 7.0657e-05.\n",
      "Epoch 157/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.9096e-04 - accuracy: 0.9857 - val_loss: 3.1635e-04 - val_accuracy: 0.9805 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 7.0657e-05.\n",
      "Epoch 158/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.9146e-04 - accuracy: 0.9855 - val_loss: 2.5551e-04 - val_accuracy: 0.9861 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 7.0657e-05.\n",
      "Epoch 159/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.8746e-04 - accuracy: 0.9859 - val_loss: 2.9133e-04 - val_accuracy: 0.9871 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 7.0657e-05.\n",
      "Epoch 160/600\n",
      "2932/2950 [============================>.] - ETA: 0s - loss: 2.8650e-04 - accuracy: 0.9861\n",
      "Epoch 160: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.8615e-04 - accuracy: 0.9860 - val_loss: 2.5975e-04 - val_accuracy: 0.9858 - lr: 7.0657e-05\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 161/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7787e-04 - accuracy: 0.9863 - val_loss: 2.9617e-04 - val_accuracy: 0.9863 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 162/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7690e-04 - accuracy: 0.9861 - val_loss: 2.5074e-04 - val_accuracy: 0.9883 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 163/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7335e-04 - accuracy: 0.9862 - val_loss: 2.4542e-04 - val_accuracy: 0.9887 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 164/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.7838e-04 - accuracy: 0.9860 - val_loss: 2.7094e-04 - val_accuracy: 0.9875 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 165/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7225e-04 - accuracy: 0.9865 - val_loss: 2.7664e-04 - val_accuracy: 0.9869 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 166/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.7572e-04 - accuracy: 0.9864 - val_loss: 3.3899e-04 - val_accuracy: 0.9843 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 167/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7552e-04 - accuracy: 0.9860 - val_loss: 2.4710e-04 - val_accuracy: 0.9883 - lr: 6.0058e-05\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 6.0058e-05.\n",
      "Epoch 168/600\n",
      "1495/2950 [==============>...............] - ETA: 6s - loss: 2.6981e-04 - accuracy: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.5405e-04 - accuracy: 0.9870 - val_loss: 2.3732e-04 - val_accuracy: 0.9894 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 194/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.5438e-04 - accuracy: 0.9873 - val_loss: 2.3089e-04 - val_accuracy: 0.9883 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 195/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.6241e-04 - accuracy: 0.9867 - val_loss: 2.4089e-04 - val_accuracy: 0.9865 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 196/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5730e-04 - accuracy: 0.9872 - val_loss: 2.5588e-04 - val_accuracy: 0.9899 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 197/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.7147e-04 - accuracy: 0.9864 - val_loss: 2.5785e-04 - val_accuracy: 0.9865 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 198/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5687e-04 - accuracy: 0.9871 - val_loss: 2.4323e-04 - val_accuracy: 0.9880 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 199/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.5727e-04 - accuracy: 0.9869 - val_loss: 3.2360e-04 - val_accuracy: 0.9857 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 5.1049e-05.\n",
      "Epoch 200/600\n",
      "2939/2950 [============================>.] - ETA: 0s - loss: 2.5469e-04 - accuracy: 0.9870\n",
      "Epoch 200: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5450e-04 - accuracy: 0.9871 - val_loss: 2.3455e-04 - val_accuracy: 0.9890 - lr: 5.1049e-05\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 4.3392e-05.\n",
      "Epoch 201/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5562e-04 - accuracy: 0.9873 - val_loss: 2.2876e-04 - val_accuracy: 0.9883 - lr: 4.3392e-05\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 4.3392e-05.\n",
      "Epoch 202/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5194e-04 - accuracy: 0.9873 - val_loss: 2.3326e-04 - val_accuracy: 0.9904 - lr: 4.3392e-05\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 4.3392e-05.\n",
      "Epoch 203/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.5159e-04 - accuracy: 0.9874 - val_loss: 2.2744e-04 - val_accuracy: 0.9901 - lr: 4.3392e-05\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 4.3392e-05.\n",
      "Epoch 204/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.4309e-04 - accuracy: 0.9877 - val_loss: 2.4918e-04 - val_accuracy: 0.9898 - lr: 4.3392e-05\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 4.3392e-05.\n",
      "Epoch 205/600\n",
      "2476/2950 [========================>.....] - ETA: 1s - loss: 2.5481e-04 - accuracy: 0.9871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3553e-04 - accuracy: 0.9883 - val_loss: 2.3872e-04 - val_accuracy: 0.9891 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 234/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3732e-04 - accuracy: 0.9878 - val_loss: 6.4644e-04 - val_accuracy: 0.9725 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 235/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3833e-04 - accuracy: 0.9881 - val_loss: 2.9989e-04 - val_accuracy: 0.9821 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 236/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3230e-04 - accuracy: 0.9881 - val_loss: 2.3374e-04 - val_accuracy: 0.9889 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 237/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.4004e-04 - accuracy: 0.9878 - val_loss: 2.2639e-04 - val_accuracy: 0.9903 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 238/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3441e-04 - accuracy: 0.9884 - val_loss: 2.2865e-04 - val_accuracy: 0.9899 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 239/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3287e-04 - accuracy: 0.9883 - val_loss: 2.4256e-04 - val_accuracy: 0.9858 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 3.6883e-05.\n",
      "Epoch 240/600\n",
      "2928/2950 [============================>.] - ETA: 0s - loss: 2.3621e-04 - accuracy: 0.9879\n",
      "Epoch 240: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.3602e-04 - accuracy: 0.9880 - val_loss: 2.2301e-04 - val_accuracy: 0.9898 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 241/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.2695e-04 - accuracy: 0.9883 - val_loss: 2.2630e-04 - val_accuracy: 0.9890 - lr: 3.1351e-05\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 242/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.2974e-04 - accuracy: 0.9884 - val_loss: 2.2277e-04 - val_accuracy: 0.9881 - lr: 3.1351e-05\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 243/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.2935e-04 - accuracy: 0.9884 - val_loss: 3.4872e-04 - val_accuracy: 0.9794 - lr: 3.1351e-05\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 244/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.2812e-04 - accuracy: 0.9887 - val_loss: 2.3278e-04 - val_accuracy: 0.9890 - lr: 3.1351e-05\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 245/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.2508e-04 - accuracy: 0.9885 - val_loss: 2.5887e-04 - val_accuracy: 0.9845 - lr: 3.1351e-05\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 3.1351e-05.\n",
      "Epoch 246/600\n",
      " 146/2950 [>.............................] - ETA: 12s - loss: 2.1667e-04 - accuracy: 0.9885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.2100e-04 - accuracy: 0.9888 - val_loss: 2.1603e-04 - val_accuracy: 0.9901 - lr: 2.6648e-05\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 2.6648e-05.\n",
      "Epoch 278/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.1394e-04 - accuracy: 0.9890 - val_loss: 2.2708e-04 - val_accuracy: 0.9896 - lr: 2.6648e-05\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 2.6648e-05.\n",
      "Epoch 279/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.2029e-04 - accuracy: 0.9886 - val_loss: 2.1267e-04 - val_accuracy: 0.9895 - lr: 2.6648e-05\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 2.6648e-05.\n",
      "Epoch 280/600\n",
      "2924/2950 [============================>.] - ETA: 0s - loss: 2.1480e-04 - accuracy: 0.9893\n",
      "Epoch 280: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1476e-04 - accuracy: 0.9893 - val_loss: 2.3026e-04 - val_accuracy: 0.9897 - lr: 2.6648e-05\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 281/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.1336e-04 - accuracy: 0.9892 - val_loss: 2.1807e-04 - val_accuracy: 0.9894 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 282/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1190e-04 - accuracy: 0.9891 - val_loss: 2.2181e-04 - val_accuracy: 0.9886 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 283/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.1590e-04 - accuracy: 0.9890 - val_loss: 2.1834e-04 - val_accuracy: 0.9895 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 284/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1573e-04 - accuracy: 0.9890 - val_loss: 2.2523e-04 - val_accuracy: 0.9898 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 285/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1439e-04 - accuracy: 0.9891 - val_loss: 2.3905e-04 - val_accuracy: 0.9898 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 286/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1239e-04 - accuracy: 0.9891 - val_loss: 2.1432e-04 - val_accuracy: 0.9901 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 287/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1074e-04 - accuracy: 0.9895 - val_loss: 2.2428e-04 - val_accuracy: 0.9880 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 288/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1316e-04 - accuracy: 0.9892 - val_loss: 2.3087e-04 - val_accuracy: 0.9901 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 289/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.1234e-04 - accuracy: 0.9890 - val_loss: 2.1472e-04 - val_accuracy: 0.9898 - lr: 2.2651e-05\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 2.2651e-05.\n",
      "Epoch 290/600\n",
      " 150/2950 [>.............................] - ETA: 11s - loss: 2.2657e-04 - accuracy: 0.9882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0521e-04 - accuracy: 0.9895 - val_loss: 2.1036e-04 - val_accuracy: 0.9900 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 314: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 314/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0719e-04 - accuracy: 0.9894 - val_loss: 2.3145e-04 - val_accuracy: 0.9899 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 315: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 315/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0899e-04 - accuracy: 0.9894 - val_loss: 2.1360e-04 - val_accuracy: 0.9902 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 316: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 316/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.0556e-04 - accuracy: 0.9895 - val_loss: 2.1041e-04 - val_accuracy: 0.9895 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 317: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 317/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.0424e-04 - accuracy: 0.9896 - val_loss: 2.1754e-04 - val_accuracy: 0.9897 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 318: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 318/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0453e-04 - accuracy: 0.9896 - val_loss: 2.3683e-04 - val_accuracy: 0.9893 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 319: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 319/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0780e-04 - accuracy: 0.9895 - val_loss: 2.1665e-04 - val_accuracy: 0.9887 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 320: LearningRateScheduler setting learning rate to 1.9253e-05.\n",
      "Epoch 320/600\n",
      "2932/2950 [============================>.] - ETA: 0s - loss: 2.0405e-04 - accuracy: 0.9896\n",
      "Epoch 320: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0429e-04 - accuracy: 0.9896 - val_loss: 2.2935e-04 - val_accuracy: 0.9882 - lr: 1.9253e-05\n",
      "\n",
      "Epoch 321: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 321/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9977e-04 - accuracy: 0.9898 - val_loss: 2.1285e-04 - val_accuracy: 0.9894 - lr: 1.6365e-05\n",
      "\n",
      "Epoch 322: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 322/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.9931e-04 - accuracy: 0.9897 - val_loss: 2.1185e-04 - val_accuracy: 0.9910 - lr: 1.6365e-05\n",
      "\n",
      "Epoch 323: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 323/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9920e-04 - accuracy: 0.9897 - val_loss: 2.1662e-04 - val_accuracy: 0.9889 - lr: 1.6365e-05\n",
      "\n",
      "Epoch 324: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 324/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 2.0357e-04 - accuracy: 0.9900 - val_loss: 2.1776e-04 - val_accuracy: 0.9884 - lr: 1.6365e-05\n",
      "\n",
      "Epoch 325: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 325/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 2.0188e-04 - accuracy: 0.9899 - val_loss: 2.5999e-04 - val_accuracy: 0.9858 - lr: 1.6365e-05\n",
      "\n",
      "Epoch 326: LearningRateScheduler setting learning rate to 1.6365e-05.\n",
      "Epoch 326/600\n",
      "1359/2950 [============>.................] - ETA: 6s - loss: 2.0078e-04 - accuracy: 0.9897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9768e-04 - accuracy: 0.9902 - val_loss: 2.0844e-04 - val_accuracy: 0.9901 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 352: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 352/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9797e-04 - accuracy: 0.9898 - val_loss: 2.3464e-04 - val_accuracy: 0.9877 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 353: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 353/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9467e-04 - accuracy: 0.9900 - val_loss: 2.0864e-04 - val_accuracy: 0.9903 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 354: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 354/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.9522e-04 - accuracy: 0.9900 - val_loss: 2.9251e-04 - val_accuracy: 0.9851 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 355: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 355/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9957e-04 - accuracy: 0.9900 - val_loss: 2.3176e-04 - val_accuracy: 0.9900 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 356: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 356/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9506e-04 - accuracy: 0.9903 - val_loss: 2.0809e-04 - val_accuracy: 0.9901 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 357: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 357/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9466e-04 - accuracy: 0.9902 - val_loss: 2.0569e-04 - val_accuracy: 0.9901 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 358: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 358/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9715e-04 - accuracy: 0.9898 - val_loss: 2.3752e-04 - val_accuracy: 0.9898 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 359: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 359/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9466e-04 - accuracy: 0.9902 - val_loss: 2.2639e-04 - val_accuracy: 0.9883 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 360: LearningRateScheduler setting learning rate to 1.391e-05.\n",
      "Epoch 360/600\n",
      "2928/2950 [============================>.] - ETA: 0s - loss: 1.9486e-04 - accuracy: 0.9901\n",
      "Epoch 360: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9587e-04 - accuracy: 0.9901 - val_loss: 2.0759e-04 - val_accuracy: 0.9903 - lr: 1.3910e-05\n",
      "\n",
      "Epoch 361: LearningRateScheduler setting learning rate to 1.1824e-05.\n",
      "Epoch 361/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.9180e-04 - accuracy: 0.9902 - val_loss: 2.3806e-04 - val_accuracy: 0.9889 - lr: 1.1824e-05\n",
      "\n",
      "Epoch 362: LearningRateScheduler setting learning rate to 1.1824e-05.\n",
      "Epoch 362/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9278e-04 - accuracy: 0.9903 - val_loss: 2.0778e-04 - val_accuracy: 0.9903 - lr: 1.1824e-05\n",
      "\n",
      "Epoch 363: LearningRateScheduler setting learning rate to 1.1824e-05.\n",
      "Epoch 363/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.9424e-04 - accuracy: 0.9901 - val_loss: 2.1937e-04 - val_accuracy: 0.9883 - lr: 1.1824e-05\n",
      "\n",
      "Epoch 364: LearningRateScheduler setting learning rate to 1.1824e-05.\n",
      "Epoch 364/600\n",
      " 151/2950 [>.............................] - ETA: 11s - loss: 1.9235e-04 - accuracy: 0.9889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8989e-04 - accuracy: 0.9905 - val_loss: 2.0407e-04 - val_accuracy: 0.9904 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 388: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 388/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8845e-04 - accuracy: 0.9905 - val_loss: 2.0892e-04 - val_accuracy: 0.9892 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 389: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 389/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9028e-04 - accuracy: 0.9903 - val_loss: 2.0656e-04 - val_accuracy: 0.9906 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 390: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 390/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8823e-04 - accuracy: 0.9906 - val_loss: 2.1254e-04 - val_accuracy: 0.9903 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 391: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 391/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8898e-04 - accuracy: 0.9906 - val_loss: 2.6510e-04 - val_accuracy: 0.9869 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 392: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 392/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9058e-04 - accuracy: 0.9904 - val_loss: 2.0501e-04 - val_accuracy: 0.9906 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 393: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 393/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8811e-04 - accuracy: 0.9904 - val_loss: 2.5590e-04 - val_accuracy: 0.9890 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 394: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 394/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9046e-04 - accuracy: 0.9905 - val_loss: 2.1599e-04 - val_accuracy: 0.9883 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 395: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 395/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8781e-04 - accuracy: 0.9905 - val_loss: 2.0661e-04 - val_accuracy: 0.9899 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 396: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 396/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8820e-04 - accuracy: 0.9904 - val_loss: 2.0463e-04 - val_accuracy: 0.9903 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 397: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 397/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8858e-04 - accuracy: 0.9902 - val_loss: 2.0767e-04 - val_accuracy: 0.9894 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 398: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 398/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8937e-04 - accuracy: 0.9904 - val_loss: 2.4936e-04 - val_accuracy: 0.9889 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 399: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 399/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.9113e-04 - accuracy: 0.9902 - val_loss: 2.1086e-04 - val_accuracy: 0.9889 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 400: LearningRateScheduler setting learning rate to 1.005e-05.\n",
      "Epoch 400/600\n",
      "2927/2950 [============================>.] - ETA: 0s - loss: 1.8645e-04 - accuracy: 0.9906\n",
      "Epoch 400: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8676e-04 - accuracy: 0.9906 - val_loss: 2.2716e-04 - val_accuracy: 0.9873 - lr: 1.0050e-05\n",
      "\n",
      "Epoch 401: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 401/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8810e-04 - accuracy: 0.9904 - val_loss: 2.0591e-04 - val_accuracy: 0.9904 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 402: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 402/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8629e-04 - accuracy: 0.9906 - val_loss: 2.0364e-04 - val_accuracy: 0.9899 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 403: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 403/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8621e-04 - accuracy: 0.9906 - val_loss: 2.0294e-04 - val_accuracy: 0.9912 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 404: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 404/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8628e-04 - accuracy: 0.9908 - val_loss: 2.0578e-04 - val_accuracy: 0.9905 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 405: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 405/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8764e-04 - accuracy: 0.9906 - val_loss: 2.0238e-04 - val_accuracy: 0.9908 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 406: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 406/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8733e-04 - accuracy: 0.9907 - val_loss: 2.0455e-04 - val_accuracy: 0.9904 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 407: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 407/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8778e-04 - accuracy: 0.9904 - val_loss: 2.0511e-04 - val_accuracy: 0.9904 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 408: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 408/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8553e-04 - accuracy: 0.9905 - val_loss: 2.0137e-04 - val_accuracy: 0.9912 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 409: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 409/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8741e-04 - accuracy: 0.9905 - val_loss: 2.1075e-04 - val_accuracy: 0.9907 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 410: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 410/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8452e-04 - accuracy: 0.9908 - val_loss: 2.6249e-04 - val_accuracy: 0.9888 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 411: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 411/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8771e-04 - accuracy: 0.9905 - val_loss: 2.0329e-04 - val_accuracy: 0.9906 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 412: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 412/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8732e-04 - accuracy: 0.9906 - val_loss: 2.2254e-04 - val_accuracy: 0.9875 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 413: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 413/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8819e-04 - accuracy: 0.9903 - val_loss: 2.0723e-04 - val_accuracy: 0.9899 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 414: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 414/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8575e-04 - accuracy: 0.9907 - val_loss: 2.3103e-04 - val_accuracy: 0.9877 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 415: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 415/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8621e-04 - accuracy: 0.9909 - val_loss: 2.0947e-04 - val_accuracy: 0.9891 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 416: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 416/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8470e-04 - accuracy: 0.9907 - val_loss: 2.0266e-04 - val_accuracy: 0.9904 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 417: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 417/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8471e-04 - accuracy: 0.9907 - val_loss: 2.0367e-04 - val_accuracy: 0.9907 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 418: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 418/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8541e-04 - accuracy: 0.9908 - val_loss: 2.0626e-04 - val_accuracy: 0.9898 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 419: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 419/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8610e-04 - accuracy: 0.9906 - val_loss: 2.0369e-04 - val_accuracy: 0.9900 - lr: 8.5430e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 420: LearningRateScheduler setting learning rate to 8.543e-06.\n",
      "Epoch 420/600\n",
      "2917/2950 [============================>.] - ETA: 0s - loss: 1.8549e-04 - accuracy: 0.9907\n",
      "Epoch 420: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8518e-04 - accuracy: 0.9907 - val_loss: 2.0625e-04 - val_accuracy: 0.9895 - lr: 8.5430e-06\n",
      "\n",
      "Epoch 421: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 421/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8392e-04 - accuracy: 0.9909 - val_loss: 2.0194e-04 - val_accuracy: 0.9902 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 422: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 422/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8425e-04 - accuracy: 0.9908 - val_loss: 2.0205e-04 - val_accuracy: 0.9909 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 423: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 423/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8434e-04 - accuracy: 0.9906 - val_loss: 2.0111e-04 - val_accuracy: 0.9906 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 424: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 424/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8281e-04 - accuracy: 0.9909 - val_loss: 2.0111e-04 - val_accuracy: 0.9907 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 425: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 425/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8407e-04 - accuracy: 0.9909 - val_loss: 2.0544e-04 - val_accuracy: 0.9893 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 426: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 426/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8441e-04 - accuracy: 0.9906 - val_loss: 2.0946e-04 - val_accuracy: 0.9910 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 427: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 427/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8619e-04 - accuracy: 0.9905 - val_loss: 2.0296e-04 - val_accuracy: 0.9906 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 428: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 428/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8218e-04 - accuracy: 0.9908 - val_loss: 2.2358e-04 - val_accuracy: 0.9881 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 429: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 429/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8269e-04 - accuracy: 0.9907 - val_loss: 2.0486e-04 - val_accuracy: 0.9909 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 430: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 430/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8324e-04 - accuracy: 0.9907 - val_loss: 2.0280e-04 - val_accuracy: 0.9904 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 431: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 431/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8362e-04 - accuracy: 0.9909 - val_loss: 2.0023e-04 - val_accuracy: 0.9907 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 432: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 432/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8402e-04 - accuracy: 0.9907 - val_loss: 2.1385e-04 - val_accuracy: 0.9902 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 433: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 433/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8388e-04 - accuracy: 0.9907 - val_loss: 2.0309e-04 - val_accuracy: 0.9906 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 434: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 434/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8221e-04 - accuracy: 0.9909 - val_loss: 2.0085e-04 - val_accuracy: 0.9901 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 435: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 435/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8362e-04 - accuracy: 0.9905 - val_loss: 2.0284e-04 - val_accuracy: 0.9908 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 436: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 436/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8297e-04 - accuracy: 0.9907 - val_loss: 2.0316e-04 - val_accuracy: 0.9905 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 437: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 437/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8212e-04 - accuracy: 0.9907 - val_loss: 2.1106e-04 - val_accuracy: 0.9891 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 438: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 438/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8335e-04 - accuracy: 0.9907 - val_loss: 2.0089e-04 - val_accuracy: 0.9908 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 439: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 439/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8342e-04 - accuracy: 0.9910 - val_loss: 2.1116e-04 - val_accuracy: 0.9904 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 440: LearningRateScheduler setting learning rate to 7.262e-06.\n",
      "Epoch 440/600\n",
      "2924/2950 [============================>.] - ETA: 0s - loss: 1.8413e-04 - accuracy: 0.9907\n",
      "Epoch 440: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8363e-04 - accuracy: 0.9907 - val_loss: 2.0121e-04 - val_accuracy: 0.9905 - lr: 7.2620e-06\n",
      "\n",
      "Epoch 441: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 441/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8168e-04 - accuracy: 0.9909 - val_loss: 2.1045e-04 - val_accuracy: 0.9905 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 442: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 442/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8240e-04 - accuracy: 0.9909 - val_loss: 2.0714e-04 - val_accuracy: 0.9903 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 443: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 443/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8131e-04 - accuracy: 0.9911 - val_loss: 2.0209e-04 - val_accuracy: 0.9901 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 444: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 444/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8058e-04 - accuracy: 0.9910 - val_loss: 2.0044e-04 - val_accuracy: 0.9906 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 445: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 445/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8205e-04 - accuracy: 0.9907 - val_loss: 2.0387e-04 - val_accuracy: 0.9906 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 446: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 446/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8269e-04 - accuracy: 0.9909 - val_loss: 2.0329e-04 - val_accuracy: 0.9907 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 447: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 447/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8150e-04 - accuracy: 0.9908 - val_loss: 2.1094e-04 - val_accuracy: 0.9888 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 448: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 448/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8199e-04 - accuracy: 0.9909 - val_loss: 2.0206e-04 - val_accuracy: 0.9908 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 449: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 449/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8093e-04 - accuracy: 0.9910 - val_loss: 2.0100e-04 - val_accuracy: 0.9901 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 450: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 450/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8290e-04 - accuracy: 0.9908 - val_loss: 2.1780e-04 - val_accuracy: 0.9879 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 451: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 451/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8209e-04 - accuracy: 0.9908 - val_loss: 2.0629e-04 - val_accuracy: 0.9897 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 452: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 452/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8064e-04 - accuracy: 0.9909 - val_loss: 2.2644e-04 - val_accuracy: 0.9880 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 453: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 453/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8196e-04 - accuracy: 0.9911 - val_loss: 2.0985e-04 - val_accuracy: 0.9887 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 454: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 454/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8055e-04 - accuracy: 0.9909 - val_loss: 2.0243e-04 - val_accuracy: 0.9903 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 455: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 455/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8098e-04 - accuracy: 0.9910 - val_loss: 2.1161e-04 - val_accuracy: 0.9893 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 456: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 456/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8096e-04 - accuracy: 0.9909 - val_loss: 2.0361e-04 - val_accuracy: 0.9905 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 457: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 457/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8210e-04 - accuracy: 0.9909 - val_loss: 2.0642e-04 - val_accuracy: 0.9900 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 458: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 458/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8235e-04 - accuracy: 0.9909 - val_loss: 2.0331e-04 - val_accuracy: 0.9910 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 459: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 459/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.8031e-04 - accuracy: 0.9909 - val_loss: 1.9950e-04 - val_accuracy: 0.9909 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 460: LearningRateScheduler setting learning rate to 6.173e-06.\n",
      "Epoch 460/600\n",
      "2924/2950 [============================>.] - ETA: 0s - loss: 1.8036e-04 - accuracy: 0.9910\n",
      "Epoch 460: saving model to /home/saichaitanya/Chaitanya/GOOGLE COLAB  DOCS/5 percent variation/7 states and 2 op with val_set having 128 neurons and batchsize 64/cp.ckpt\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.8074e-04 - accuracy: 0.9910 - val_loss: 2.0537e-04 - val_accuracy: 0.9901 - lr: 6.1730e-06\n",
      "\n",
      "Epoch 461: LearningRateScheduler setting learning rate to 5.247e-06.\n",
      "Epoch 461/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.7993e-04 - accuracy: 0.9910 - val_loss: 2.0247e-04 - val_accuracy: 0.9898 - lr: 5.2470e-06\n",
      "\n",
      "Epoch 462: LearningRateScheduler setting learning rate to 5.247e-06.\n",
      "Epoch 462/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.7921e-04 - accuracy: 0.9911 - val_loss: 2.0023e-04 - val_accuracy: 0.9906 - lr: 5.2470e-06\n",
      "\n",
      "Epoch 463: LearningRateScheduler setting learning rate to 5.247e-06.\n",
      "Epoch 463/600\n",
      "2950/2950 [==============================] - 13s 4ms/step - loss: 1.7912e-04 - accuracy: 0.9910 - val_loss: 2.0288e-04 - val_accuracy: 0.9899 - lr: 5.2470e-06\n",
      "\n",
      "Epoch 464: LearningRateScheduler setting learning rate to 5.247e-06.\n",
      "Epoch 464/600\n",
      "2950/2950 [==============================] - 12s 4ms/step - loss: 1.7918e-04 - accuracy: 0.9909 - val_loss: 2.0011e-04 - val_accuracy: 0.9906 - lr: 5.2470e-06\n",
      "\n",
      "Epoch 465: LearningRateScheduler setting learning rate to 5.247e-06.\n",
      "Epoch 465/600\n",
      "1522/2950 [==============>...............] - ETA: 5s - loss: 1.7685e-04 - accuracy: 0.9909"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 600,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler2,cp_callback2],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TIhxCgSZcRf"
   },
   "outputs": [],
   "source": [
    "lr =hist.history.get('lr')[-1] # It takes the last used learning rate.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.mean_squared_error\n",
    "def ModelsWith99PercentAccuracy(epoch,lr):\n",
    "    if(epoch>0):\n",
    "        if epoch%20==0:\n",
    "            return round(lr*0.85,9)\n",
    "        else:\n",
    "            return round(lr,9)\n",
    "    else:\n",
    "      return round(lr,9)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(ModelsWith99PercentAccuracy,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iSnNGEKZcPT"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train,y_train,epochs = 20,batch_size = bs,shuffle = True,use_multiprocessing = True,callbacks=[lr_scheduler,cp_callback],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfR_MxjOueej"
   },
   "source": [
    "## Antinormalizing all the input and output features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUAtpuawuL-m"
   },
   "outputs": [],
   "source": [
    "def AntiNorm(Norm_value,actual):\n",
    "  return (max(actual)-min(actual))*Norm_value+min(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0ymQqeKuL8Z"
   },
   "outputs": [],
   "source": [
    "h_norm = X_norm[:,0]\n",
    "v_norm = X_norm[:,1]\n",
    "s_norm = X_norm[:,2]\n",
    "omega_norm = X_norm[:,3]\n",
    "gamma_norm = X_norm[:,4]\n",
    "m_norm = X_norm[:,5]\n",
    "theta_norm = X_norm[:,6]\n",
    "Thrust_norm = y_norm[:,0]\n",
    "beta_norm = y_norm[:,1]\n",
    "h = X[:,0]\n",
    "v = X[:,1]\n",
    "s = X[:,2]\n",
    "omega = X[:,3]\n",
    "gamma = X[:,4]\n",
    "m = X[:,5]\n",
    "theta = X[:,6]\n",
    "Thrust = y[:,0]\n",
    "beta = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vxoUvvEuL5q"
   },
   "outputs": [],
   "source": [
    "# predicted outputs\n",
    "y_pred = model.predict(X_norm)\n",
    "Thrust_p = AntiNorm(y_pred[:,0],Thrust)\n",
    "beta_p = AntiNorm(y_pred[:,1],beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tyRZnz3ZcMV"
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_p[0:3030])\n",
    "plt.plot(beta[0:3030])\n",
    "plt.legend([\"Predicted\",\"Actual\"])\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Nozzle Gamble\")\n",
    "\n",
    "plt.plot(Thrust_p[0:3030])\n",
    "plt.plot(Thrust[0:3030])\n",
    "plt.legend([\"Predicted\",\"Actual\"])\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Thrust\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "All states 5percent data with 303p.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
